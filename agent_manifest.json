{
  "name": "Euro-BioImaging Finder",
  "description": "An Agent to Navigate the Euro-BioImaging services.",
  "version": "0.1.0",
  "license": "CC-BY-4.0",
  "lang": "python",
  "type": "agent",
  "created_at": "2025-07-10T14:27:33.564Z",
  "startup_script": "import micropip\nawait micropip.install([\"httpx\", \"pydantic\", \"bm25s\"])\n\nimport httpx\nfrom typing import Dict, List, Any, Optional, Tuple\nfrom pydantic import BaseModel\nimport bm25s\nfrom pathlib import Path\nimport tempfile\nimport micropip\nimport pickle\n\nclass TechDetail(BaseModel):\n    \"\"\"Details of a specific technology\"\"\"\n    id: str\n    name: str\n    original_id: str\n    description: str\n    documentation: str\n    category: Dict[str, Any]\n    provider_node_ids: List[str]\n    abbr: str\n\nclass NodeDetail(BaseModel):\n    \"\"\"Details of a specific node\"\"\"\n    id: str\n    name: str\n    original_id: str\n    description: str\n    documentation: str\n    country: Dict[str, Any]\n    offer_technology_ids: List[str]\n\nclass WebsitePageDetail(BaseModel):\n    \"\"\"Details of a Euro-BioImaging website page\"\"\"\n    id: str\n    url: str\n    title: str\n    description: str\n    documentation: str\n    headings: List[str]\n    page_type: str\n\nclass SearchResponse(BaseModel):\n    \"\"\"Structured search response\"\"\"\n    answer: str\n    relevant_technologies: List[str] = []\n    relevant_nodes: List[str] = []\n    relevant_pages: List[str] = []\n    summary: str = \"\"\n\n# Global data storage\ntech_data: List[Dict[str, Any]] = []\nnodes_data: List[Dict[str, Any]] = []\nwebsite_data: List[Dict[str, Any]] = []\nbm25_retriever = None\nbm25_metadata = None\n\nasync def load_eurobioimaging_data():\n    \"\"\"\n    Load Euro-BioImaging data from remote index file.\n    This function fetches the combined index from the remote URL and populates the global data structures.\n    \n    Returns:\n    - dict: Metadata about the loaded dataset including counts and creation info\n    \"\"\"\n    global tech_data, nodes_data, website_data, bm25_retriever, bm25_metadata\n    \n    base_url = \"https://aicell-lab.github.io/euro-bioimaging-finder\"\n    \n    try:\n        async with httpx.AsyncClient(timeout=30.0) as client:\n            # Load main index\n            response = await client.get(f\"{base_url}/eurobioimaging_index.json\")\n            response.raise_for_status()\n            combined_data = response.json()\n            \n            # Extract data from combined index\n            tech_data = combined_data.get('technologies', [])\n            nodes_data = combined_data.get('nodes', [])\n            website_data = combined_data.get('website_pages', [])\n            bm25_metadata = combined_data.get('bm25_metadata', [])\n            \n            # Download and load BM25 pickle file\n            bm25_response = await client.get(f\"{base_url}/eurobioimaging_bm25_index.pkl\")\n            bm25_response.raise_for_status()\n            \n            # Save to temp file and load\n            with tempfile.NamedTemporaryFile(suffix='.pkl', delete=False) as temp_file:\n                temp_file.write(bm25_response.content)\n                temp_file.flush()\n                \n                with open(temp_file.name, 'rb') as f:\n                    bm25_retriever = pickle.load(f)\n            \n            # Get metadata\n            metadata = combined_data.get('metadata', {})\n            dataset_info = {\n                'dataset_type': metadata.get('dataset_type', 'unknown'),\n                'created_at': metadata.get('created_at', 'unknown'),\n                'technologies_count': len(tech_data),\n                'nodes_count': len(nodes_data),\n                'website_pages_count': len(website_data),\n                'total_entries': len(tech_data) + len(nodes_data) + len(website_data),\n                'bm25_documents': len(bm25_metadata) if bm25_metadata else 0\n            }\n            \n            return dataset_info\n            \n    except Exception as e:\n        print(f\"Error loading data: {e}\")\n        tech_data = []\n        nodes_data = []\n        website_data = []\n        bm25_retriever = None\n        bm25_metadata = None\n        raise e\n\ndef read_tech_details(tech_id: str):\n    \"\"\"\n    Read details of a specific technology by ID.\n    \n    Parameters:\n    - tech_id (str): The technology ID\n    \n    Returns:\n    - Optional[TechDetail]: Technology details or None if not found\n    \"\"\"\n    for tech in tech_data:\n        if tech['id'] == tech_id:\n            return TechDetail(**tech)\n    raise Exception(f\"Technology with ID {tech_id} not found\")\n\ndef read_node_details(node_id: str):\n    \"\"\"\n    Read details of a specific node by ID.\n    \n    Parameters:\n    - node_id (str): The node ID\n    \n    Returns:\n    - Optional[NodeDetail]: Node details or None if not found\n    \"\"\"\n    for node in nodes_data:\n        if node['id'] == node_id:\n            return NodeDetail(**node)\n    raise Exception(f\"Node with ID {node_id} not found\")\n\ndef read_nodes_by_country(country_code: str):\n    \"\"\"\n    Read all nodes in a specific country by ISO country code.\n    \n    Parameters:\n    - country_code (str): ISO country code (e.g., 'PL', 'SE', 'DE')\n    \n    Returns:\n    - List[NodeDetail]: List of all nodes in the specified country\n    \"\"\"\n    country_nodes = []\n    for node in nodes_data:\n        node_country = node.get('country', {})\n        if node_country.get('iso_a2', '').upper() == country_code.upper():\n            try:\n                country_nodes.append(NodeDetail(**node))\n            except Exception as e:\n                print(f\"Warning: Could not parse node {node.get('name', 'Unknown')}: {e}\")\n    return country_nodes\n\ndef read_website_page_details(page_id: str):\n    \"\"\"\n    Read details of a specific website page by ID.\n    \n    Parameters:\n    - page_id (str): The website page ID\n    \n    Returns:\n    - Optional[WebsitePageDetail]: Website page details or None if not found\n    \"\"\"\n    for page in website_data:\n        if page['id'] == page_id:\n            return WebsitePageDetail(**page)\n    raise Exception(f\"Website page with ID {page_id} not found\")\n\ndef get_country_codes():\n    \"\"\"\n    Get mapping of country names to ISO codes from the data.\n    \n    Returns:\n    - Dict[str, str]: Mapping of country names to ISO codes\n    \"\"\"\n    country_mapping = {}\n    for node in nodes_data:\n        country = node.get('country', {})\n        country_name = country.get('name', '')\n        country_code = country.get('iso_a2', '')\n        if country_name and country_code:\n            country_mapping[country_name.lower()] = country_code.upper()\n    return country_mapping\n\ndef create_search_prompt():\n    \"\"\"Create the search prompt with all available data indexes\"\"\"\n    \n    def truncate_line(line: str, max_length: int = 256) -> str:\n        \"\"\"Truncate line to max_length, preserving the format\"\"\"\n        if len(line) <= max_length:\n            return line\n        return line[:max_length-3] + \"...\"\n    \n    # Create technology index with \"- id: name / description\" format\n    tech_index = []\n    for tech in tech_data:\n        name = tech.get('name', '')\n        description = tech.get('description', '').replace('\\n', ' ').strip()\n        line = f\"- {tech['id']}:{name}/{description}\"\n        tech_index.append(truncate_line(line))\n    \n    # Create nodes index with \"- id:name/description\" format, grouped by country\n    nodes_by_country = {}\n    country_codes_info = {}\n    for node in nodes_data:\n        country = node['country']['name']\n        country_code = node['country'].get('iso_a2', 'XX')\n        if country not in nodes_by_country:\n            nodes_by_country[country] = []\n            country_codes_info[country] = country_code\n        \n        name = node.get('name', '')\n        description = node.get('description', '').replace('\\n', ' ').strip()\n        line = f\"- {node['id']}:{name}/{description}\"\n        nodes_by_country[country].append(truncate_line(line))\n    \n    nodes_index = []\n    for country, country_nodes in sorted(nodes_by_country.items()):\n        country_code = country_codes_info[country]\n        nodes_index.append(f\"\\n**{country} ({country_code}):**\")\n        nodes_index.extend([f\"  {node}\" for node in country_nodes])\n    \n    # Create website pages index with \"- id: title / description\" format\n    website_index = []\n    for page in website_data:\n        title = page.get('title', '')\n        description = page.get('description', '').replace('\\n', ' ').strip()\n        line = f\"- {page['id']}:{title}/{description}\"\n        website_index.append(truncate_line(line))\n    \n    prompt = f\"\"\"\nHere is a list of all the available resources associated with their IDs.\n\n## Available General Website Pages:\n{chr(10).join(website_index)}\n\n## Available Technologies: \n{chr(10).join(tech_index)}\n\n## Available Nodes by Country (with ISO codes):\n{chr(10).join(nodes_index)}\n\n**IMPORTANT**: Each entry in the indexes above follows the format `- ID: Name / Description`\n\n- For **Technologies**: `- tech_id: Technology Name/Brief description`\n- For **Nodes**: `- node_id: Node Name/Brief description` \n- For **Website Pages**: `- page_id: Page Title/Brief description`\n\nFor any matched topics, you can call the utility functions to get more details by the ID.\n\n**To use the utility functions**: Extract the ID (the part after the dash and before the colon) and pass it to the appropriate function:\n- Use `tech_id` with `read_tech_details(tech_id)`\n- Use `node_id` with `read_node_details(node_id)` \n- Use `page_id` with `read_website_page_details(page_id)`\n\nThese utilities are available under the current execution context, and no need to use await to call them. For example:\n\n```python\n# Example: Get details of a specific technology\ntech_details = read_tech_details(\"02e4459a\")\nprint(f\"Technology: {{tech_details.name}}\")\nprint(f\"Description: {{tech_details.description}}\")\n```\n\nImprtantly, they are not under api.* namespace, so you can call them directly.\n\n\"\"\"\n\n    return prompt\n\ndef fulltext_search(query: str, k: int = 5) -> List[Dict[str, Any]]:\n    \"\"\"\n    Perform full-text search using BM25 index\n    \n    Parameters:\n    - query (str): The search query\n    - k (int): Number of results to return (default: 5)\n    \n    Returns:\n    - List[Dict]: List of matching documents with metadata\n    \"\"\"\n    if not bm25_retriever or not bm25_metadata:\n        raise Exception(\"Error: BM25 index not loaded\")\n    \n    # Tokenize query\n    query_tokens = bm25s.tokenize(query)\n    \n    # Get results\n    results, scores = bm25_retriever.retrieve(query_tokens, k=k)\n    \n    # Format results\n    search_results = []\n    for i in range(results.shape[1]):\n        doc_idx = results[0, i]\n        score = scores[0, i]\n        \n        # Get metadata for the document\n        metadata = bm25_metadata[doc_idx]\n        doc_type = metadata['type']\n        doc_id = metadata['id']\n        \n        # Get full details based on type\n        if doc_type == 'tech':\n            details = read_tech_details(doc_id)\n            if details:\n                search_results.append({\n                    'type': doc_type,\n                    'id': doc_id,\n                    'name': details.name,\n                    'description': details.description,\n                    'score': float(score),\n                    'documentation': details.documentation,\n                    'category': details.category,\n                    'provider_node_ids': details.provider_node_ids,\n                })\n        elif doc_type == 'node':\n            details = read_node_details(doc_id)\n            if details:\n                search_results.append({\n                    'type': doc_type,\n                    'id': doc_id,\n                    'name': details.name,\n                    'description': details.description,\n                    'score': float(score),\n                    'documentation': details.documentation,\n                    'country': details.country,\n                    'offer_technology_ids': details.offer_technology_ids,\n                })\n        elif doc_type == 'page':\n            details = read_website_page_details(doc_id)\n            if details:\n                search_results.append({\n                    'type': doc_type,\n                    'id': doc_id,\n                    'name': details.title,\n                    'description': details.description,\n                    'score': float(score),\n                    'url': details.url,\n                    'documentation': details.documentation,\n                    'headings': details.headings,\n                    'page_type': details.page_type,\n                })\n    \n    return search_results\n\n# Initialize data and create the search prompt\ndata_loaded = await load_eurobioimaging_data()\n\nif not data_loaded:\n    print(\"WARNING: \u274c Failed to load Euro-BioImaging data, none of the following functions will work properly.\")\n\nprint(\"\"\"\nYou are an AI assistant specialized in helping users discover imaging technologies, instruments, and services provided by the Euro-BioImaging network.\nYou have access to several utility functions for retrieving specific information about Euro-BioImaging facilities. Below are all the available resources in the Euro-BioImaging network:\n\"\"\")\n\n# Print the search context with all available data\nsearch_context = create_search_prompt()\nprint(search_context)\n\n# The printed text will be used for the LLM agent as prompt.\nprint(\"\"\"## \ud83d\udee0\ufe0f Available Utility Functions\n\n**IMPORTANT**: Call these functions directly - NO `await`, NO `api.` prefix, NO keyword arguments!\n\n### Detail Retrieval Functions\n- `read_tech_details(tech_id)` \u2192 `TechDetail(id, name, original_id, description, documentation, category, provider_node_ids, abbr)` or `None`\n- `read_node_details(node_id)` \u2192 `NodeDetail(id, name, original_id, description, documentation, country, offer_technology_ids)` or `None`  \n- `read_nodes_by_country(country_code)` \u2192 `List[NodeDetail(id, name, original_id, description, documentation, country, offer_technology_ids)]`\n- `read_website_page_details(page_id)` \u2192 `WebsitePageDetail(id, url, title, description, documentation, headings, page_type)` or `None`\nThe returned objects are pydantic models, so you can access the attributes directly. For example: tech_details.name, node_details.country['name'], etc.\n\n### Search Functions\n- `fulltext_search(query, k=5)` \u2192 `List[Dict]` (full-text search across all content types)\n- `get_country_codes()` \u2192 `Dict[str, str]` (country_name \u2192 ISO_code)\n\n\n## \u2705 Correct Function Call Examples\n\n```python\n# CORRECT: Get node details\nnode_details = read_node_details(\"48c78d41\")\nprint(f\"Node: {node_details.name}\")\nprint(f\"Country: {node_details.country['name']}\")\nprint(f\"Description: {node_details.description}\")\n\n# CORRECT: Get technology details  \ntech_details = read_tech_details(\"02e4459a\")\nprint(f\"Technology: {tech_details.name}\")\nprint(f\"Category: {tech_details.category['name']}\")\nprint(f\"Available at {len(tech_details.provider_node_ids)} nodes\")\n\n# CORRECT: Get all nodes in Germany\ngerman_nodes = read_nodes_by_country(\"DE\")\nfor node in german_nodes:\n    print(f\"Node: {node.name}\")\n    print(f\"Technologies: {len(node.offer_technology_ids)} available\")\n\n# CORRECT: Full-text search across all content\nresults = fulltext_search(\"super resolution microscopy\", k=5)\nfor result in results:\n    print(f\"Score: {result['score']:.2f} - Type: {result['type']} - Name: {result['name']}\")\n    print(f\"Description: {result['description']}\")\n```\n\n## \u274c WRONG Function Call Examples\n\n```python\n# WRONG: Don't use await\nnode_details = await read_node_details(\"48c78d41\")  # \u274c\n\n# WRONG: Don't use api prefix\nnode_details = api.read_node_details(\"48c78d41\")  # \u274c\n\n# WRONG: Don't use keyword arguments\nnode_details = read_node_details(node_id=\"48c78d41\")  # \u274c\n\n# WRONG: Don't combine await + api\nnode_details = await api.read_node_details(node_id=\"48c78d41\")  # \u274c\n```\n\n## \ud83e\udde0 How to Answer User Queries\n\nFollow this systematic approach:\n\n### 1. **Analyze the Query Type**\n- **Geographic queries** (e.g., \"facilities in Germany\"): Focus on specific countries/regions\n- **Technology queries** (e.g., \"super-resolution microscopy\"): Focus on specific techniques or instruments  \n- **General information** (e.g., \"how to access services\"): Focus on website pages and general guidance\n- **Listing queries** (e.g., \"all available nodes\"): Provide comprehensive listings\n\n### 2. **Select Relevant IDs**\nFrom the indexes above, identify the specific IDs you need by looking at the summaries:\n- **Technology IDs**: Look for relevant techniques in the technology list, extract the ID before the colon\n- **Node IDs**: Look for relevant facilities in the node list, extract the ID before the colon\n- **Country codes**: Use the ISO codes in parentheses (e.g., DE, SE, FR)\n- **Page IDs**: Look for relevant information pages, extract the ID before the colon\n\n**Example**: If you see `tech_super_res_microscopy: Super-Resolution Microscopy (available at 15 nodes)`, use `tech_super_res_microscopy` as the ID.\n\n### 3. **Retrieve Detailed Information**\nUse the utility functions systematically:\n\n**For Technology Queries:**\n```python\n# Example: \"Where can I find MINFLUX?\"\n# Step 1: Get the specific technology details\nminflux_details = read_tech_details(\"4bf1cfdd\")  # Extract ID from index\nprint(f\"Technology: {minflux_details.name}\")\n\n# Step 2: Get nodes where it's available (don't list all their technologies)\nfor node_id in minflux_details.provider_node_ids:\n    node_details = read_node_details(node_id)\n    print(f\"Available at: {node_details.name} in {node_details.country['name']}\")\n```\n\n**For Geographic Queries:**\n```python\n# Example: \"What imaging facilities are in Germany?\"\ncountry_nodes = read_nodes_by_country(\"DE\")  # Germany\nfor node in country_nodes:\n    print(f\"Node: {node.name}\")\n    print(f\"Description: {node.description}\")\n    print(f\"Technologies available: {len(node.offer_technology_ids)} total\")\n    # Only list technologies if specifically asked, don't retrieve all details\n```\n\n**For General Full-text Search:**\n```python\n# Use full-text search to find relevant content\nresults = fulltext_search(\"access services application\", k=5)\nfor result in results:\n    if result['type'] == 'page':\n        page_details = read_website_page_details(result['id'])\n        print(f\"Page: {page_details.title}\")\n        print(f\"URL: {page_details.url}\")\n        print(f\"Description: {page_details.description}\")\n```\n\n```python\n# Example: \"Find super-resolution microscopy techniques\"\nresults = fulltext_search(\"super resolution microscopy\", k=3)\nfor result in results:\n    if result['type'] == 'tech':\n        print(f\"Technology: {result['name']} (Score: {result['score']:.2f})\")\n        print(f\"Description: {result['description']}\")\n        # Get provider nodes if needed\n        tech_details = read_tech_details(result['id'])\n        for node_id in tech_details.provider_node_ids:\n            node_details = read_node_details(node_id)\n            print(f\"  Available at: {node_details.name} in {node_details.country['name']}\")\n```\n\n### 4. **Be Focused and Efficient**\n- Only retrieve information that directly answers the user's question\n- Don't list all technologies at a node unless specifically asked\n- Don't retrieve all details unless needed for the specific query\n- Answer the question, don't provide unnecessary comprehensive listings\n\n### 5. **Reason Across Results**\n- Integrate information from multiple search results if needed\n- Draw conclusions, extract availability details, instrument capabilities, node locations, and relevant contact information\n\n### 6. **Handle AI-Enhanced Content Transparently**\n- **Check for AI enhancement markers** in technology documentation:\n  - Look for \"## AI Generated Documentation\" sections\n  - Look for \"## References\" sections with sources\n- **When using AI-enhanced content**:\n  - Mention that information is AI-enhanced: \"Based on AI-enhanced documentation...\"\n  - Cite sources from References sections: \"According to sources including [source name](url)...\"\n\n### 7. **Respond Factually and Comprehensively**\n- Ensure your final reply contains all key findings and actionable information\n- Always include all relevant details in your final answer, the intermediate script output won't be seen by the user\n- Avoid vague summaries\u2014be precise and specific based on the returned context\n- **Be transparent about information sources** throughout your response\n\n## \ud83d\udccb Query Pattern Examples\n\n**Geographic Query**: \"What imaging facilities are available in Germany?\"\n1. Use `read_nodes_by_country(\"DE\")` to get all German nodes\n2. For each node, use `read_node_details()` to get full information\n3. For each technology at the nodes, use `read_tech_details()` to understand capabilities\n\n**Technology Query**: \"Where can I access super-resolution microscopy?\"\n1. Use `fulltext_search(\"super resolution microscopy\", k=3)` to find relevant technologies and nodes\n2. Filter results by type to focus on technologies and nodes\n3. Use `read_tech_details()` and `read_node_details()` to get detailed information\n\n**General Information**: \"How do I access Euro-BioImaging services?\"\n1. Use `fulltext_search(\"access services application procedures\", k=3)` to find relevant content\n2. Filter results for website pages that contain access information\n3. Use `read_website_page_details()` for each relevant page to get detailed information\n\n## \ud83c\udfaf Response Quality Guidelines\n0. When generating the thoughts, limit each thought to 5 words maximum.\n1. **Use the indexes above** to identify relevant resources by their summaries\n2. **Extract IDs correctly** (the part before the colon) from the index entries\n3. **Call functions directly** without await, api prefix, or keyword arguments\n4. **Be systematic** in retrieving details for all relevant items\n5. **Include geographic context** (country names and codes)\n6. **Provide comprehensive information** which corresponds to the user query, try to be helpful and comprehensive.\n7. Since we are targeting non-technical users, unless asked, you can generate and execute scripts, but no need to commit code during the final response.\n\nRemember: Scan the indexes for relevant entries, extract the correct IDs, then call the utility functions directly to get detailed information.\n\"\"\") \n",
  "welcomeMessage": "",
  "modelConfig": {
    "baseURL": "http://localhost:11434/v1/",
    "model": "qwen2.5-coder:7b",
    "temperature": 0.7
  },
  "chat_template": {
    "metadata": {
      "modified": "2025-07-10T14:26:14.237Z",
      "kernelspec": {
        "name": "python3",
        "display_name": "Python 3"
      },
      "language_info": {
        "name": "python",
        "version": "3.9"
      },
      "title": "Euro-BioImaging Finder",
      "created": "2025-07-10T14:26:14.216Z",
      "filePath": "Euro-BioImaging Finder_2025-07-10T14-26-14-215Z.ipynb",
      "projectId": "in-browser",
      "description": null,
      "agentArtifact": {
        "id": "hypha-agents/leisure-scrimmage-disliked-more",
        "version": null,
        "name": "Euro-BioImaging Finder",
        "description": "An Agent to Navigate the Euro-BioImaging services.",
        "manifest": {
          "name": "Euro-BioImaging Finder",
          "description": "An Agent to Navigate the Euro-BioImaging services.",
          "version": "0.1.0",
          "license": "CC-BY-4.0",
          "lang": "python",
          "type": "agent",
          "created_at": "2025-06-30T19:40:34.618Z",
          "startup_script": "import micropip\nawait micropip.install([\"httpx\", \"pydantic\", \"bm25s\"])\n\nimport httpx\nfrom typing import Dict, List, Any, Optional, Tuple\nfrom pydantic import BaseModel\nimport bm25s\nfrom pathlib import Path\nimport tempfile\nimport micropip\nimport pickle\n\nclass TechDetail(BaseModel):\n    \"\"\"Details of a specific technology\"\"\"\n    id: str\n    name: str\n    original_id: str\n    description: str\n    documentation: str\n    category: Dict[str, Any]\n    provider_node_ids: List[str]\n    abbr: str\n\nclass NodeDetail(BaseModel):\n    \"\"\"Details of a specific node\"\"\"\n    id: str\n    name: str\n    original_id: str\n    description: str\n    documentation: str\n    country: Dict[str, Any]\n    offer_technology_ids: List[str]\n\nclass WebsitePageDetail(BaseModel):\n    \"\"\"Details of a Euro-BioImaging website page\"\"\"\n    id: str\n    url: str\n    title: str\n    description: str\n    documentation: str\n    headings: List[str]\n    page_type: str\n\nclass SearchResponse(BaseModel):\n    \"\"\"Structured search response\"\"\"\n    answer: str\n    relevant_technologies: List[str] = []\n    relevant_nodes: List[str] = []\n    relevant_pages: List[str] = []\n    summary: str = \"\"\n\n# Global data storage\ntech_data: List[Dict[str, Any]] = []\nnodes_data: List[Dict[str, Any]] = []\nwebsite_data: List[Dict[str, Any]] = []\nbm25_retriever = None\nbm25_metadata = None\n\nasync def load_eurobioimaging_data():\n    \"\"\"\n    Load Euro-BioImaging data from remote index file.\n    This function fetches the combined index from the remote URL and populates the global data structures.\n    \n    Returns:\n    - dict: Metadata about the loaded dataset including counts and creation info\n    \"\"\"\n    global tech_data, nodes_data, website_data, bm25_retriever, bm25_metadata\n    \n    base_url = \"https://oeway.github.io/euro-bioimaging-finder\"\n    \n    try:\n        async with httpx.AsyncClient(timeout=30.0) as client:\n            # Load main index\n            response = await client.get(f\"{base_url}/eurobioimaging_index.json\")\n            response.raise_for_status()\n            combined_data = response.json()\n            \n            # Extract data from combined index\n            tech_data = combined_data.get('technologies', [])\n            nodes_data = combined_data.get('nodes', [])\n            website_data = combined_data.get('website_pages', [])\n            bm25_metadata = combined_data.get('bm25_metadata', [])\n            \n            # Download and load BM25 pickle file\n            bm25_response = await client.get(f\"{base_url}/eurobioimaging_bm25_index.pkl\")\n            bm25_response.raise_for_status()\n            \n            # Save to temp file and load\n            with tempfile.NamedTemporaryFile(suffix='.pkl', delete=False) as temp_file:\n                temp_file.write(bm25_response.content)\n                temp_file.flush()\n                \n                with open(temp_file.name, 'rb') as f:\n                    bm25_retriever = pickle.load(f)\n            \n            # Get metadata\n            metadata = combined_data.get('metadata', {})\n            dataset_info = {\n                'dataset_type': metadata.get('dataset_type', 'unknown'),\n                'created_at': metadata.get('created_at', 'unknown'),\n                'technologies_count': len(tech_data),\n                'nodes_count': len(nodes_data),\n                'website_pages_count': len(website_data),\n                'total_entries': len(tech_data) + len(nodes_data) + len(website_data),\n                'bm25_documents': len(bm25_metadata) if bm25_metadata else 0\n            }\n            \n            return dataset_info\n            \n    except Exception as e:\n        print(f\"Error loading data: {e}\")\n        tech_data = []\n        nodes_data = []\n        website_data = []\n        bm25_retriever = None\n        bm25_metadata = None\n        raise e\n\ndef read_tech_details(tech_id: str):\n    \"\"\"\n    Read details of a specific technology by ID.\n    \n    Parameters:\n    - tech_id (str): The technology ID\n    \n    Returns:\n    - Optional[TechDetail]: Technology details or None if not found\n    \"\"\"\n    for tech in tech_data:\n        if tech['id'] == tech_id:\n            return TechDetail(**tech)\n    raise Exception(f\"Technology with ID {tech_id} not found\")\n\ndef read_node_details(node_id: str):\n    \"\"\"\n    Read details of a specific node by ID.\n    \n    Parameters:\n    - node_id (str): The node ID\n    \n    Returns:\n    - Optional[NodeDetail]: Node details or None if not found\n    \"\"\"\n    for node in nodes_data:\n        if node['id'] == node_id:\n            return NodeDetail(**node)\n    raise Exception(f\"Node with ID {node_id} not found\")\n\ndef read_nodes_by_country(country_code: str):\n    \"\"\"\n    Read all nodes in a specific country by ISO country code.\n    \n    Parameters:\n    - country_code (str): ISO country code (e.g., 'PL', 'SE', 'DE')\n    \n    Returns:\n    - List[NodeDetail]: List of all nodes in the specified country\n    \"\"\"\n    country_nodes = []\n    for node in nodes_data:\n        node_country = node.get('country', {})\n        if node_country.get('iso_a2', '').upper() == country_code.upper():\n            try:\n                country_nodes.append(NodeDetail(**node))\n            except Exception as e:\n                print(f\"Warning: Could not parse node {node.get('name', 'Unknown')}: {e}\")\n    return country_nodes\n\ndef read_website_page_details(page_id: str):\n    \"\"\"\n    Read details of a specific website page by ID.\n    \n    Parameters:\n    - page_id (str): The website page ID\n    \n    Returns:\n    - Optional[WebsitePageDetail]: Website page details or None if not found\n    \"\"\"\n    for page in website_data:\n        if page['id'] == page_id:\n            return WebsitePageDetail(**page)\n    raise Exception(f\"Website page with ID {page_id} not found\")\n\ndef get_country_codes():\n    \"\"\"\n    Get mapping of country names to ISO codes from the data.\n    \n    Returns:\n    - Dict[str, str]: Mapping of country names to ISO codes\n    \"\"\"\n    country_mapping = {}\n    for node in nodes_data:\n        country = node.get('country', {})\n        country_name = country.get('name', '')\n        country_code = country.get('iso_a2', '')\n        if country_name and country_code:\n            country_mapping[country_name.lower()] = country_code.upper()\n    return country_mapping\n\ndef create_search_prompt():\n    \"\"\"Create the search prompt with all available data indexes\"\"\"\n    \n    def truncate_line(line: str, max_length: int = 256) -> str:\n        \"\"\"Truncate line to max_length, preserving the format\"\"\"\n        if len(line) <= max_length:\n            return line\n        return line[:max_length-3] + \"...\"\n    \n    # Create technology index with \"- id: name / description\" format\n    tech_index = []\n    for tech in tech_data:\n        name = tech.get('name', '')\n        description = tech.get('description', '').replace('\\n', ' ').strip()\n        line = f\"- {tech['id']}:{name}/{description}\"\n        tech_index.append(truncate_line(line))\n    \n    # Create nodes index with \"- id:name/description\" format, grouped by country\n    nodes_by_country = {}\n    country_codes_info = {}\n    for node in nodes_data:\n        country = node['country']['name']\n        country_code = node['country'].get('iso_a2', 'XX')\n        if country not in nodes_by_country:\n            nodes_by_country[country] = []\n            country_codes_info[country] = country_code\n        \n        name = node.get('name', '')\n        description = node.get('description', '').replace('\\n', ' ').strip()\n        line = f\"- {node['id']}:{name}/{description}\"\n        nodes_by_country[country].append(truncate_line(line))\n    \n    nodes_index = []\n    for country, country_nodes in sorted(nodes_by_country.items()):\n        country_code = country_codes_info[country]\n        nodes_index.append(f\"\\n**{country} ({country_code}):**\")\n        nodes_index.extend([f\"  {node}\" for node in country_nodes])\n    \n    # Create website pages index with \"- id: title / description\" format\n    website_index = []\n    for page in website_data:\n        title = page.get('title', '')\n        description = page.get('description', '').replace('\\n', ' ').strip()\n        line = f\"- {page['id']}:{title}/{description}\"\n        website_index.append(truncate_line(line))\n    \n    prompt = f\"\"\"\nHere is a list of all the available resources associated with their IDs.\n\n## Available General Website Pages:\n{chr(10).join(website_index)}\n\n## Available Technologies: \n{chr(10).join(tech_index)}\n\n## Available Nodes by Country (with ISO codes):\n{chr(10).join(nodes_index)}\n\n**IMPORTANT**: Each entry in the indexes above follows the format `- ID: Name / Description`\n\n- For **Technologies**: `- tech_id: Technology Name/Brief description`\n- For **Nodes**: `- node_id: Node Name/Brief description` \n- For **Website Pages**: `- page_id: Page Title/Brief description`\n\nFor any matched topics, you can call the utility functions to get more details by the ID.\n\n**To use the utility functions**: Extract the ID (the part after the dash and before the colon) and pass it to the appropriate function:\n- Use `tech_id` with `read_tech_details(tech_id)`\n- Use `node_id` with `read_node_details(node_id)` \n- Use `page_id` with `read_website_page_details(page_id)`\n\nThese utilities are available under the current execution context, and no need to use await to call them. For example:\n\n```python\n# Example: Get details of a specific technology\ntech_details = read_tech_details(\"02e4459a\")\nprint(f\"Technology: {{tech_details.name}}\")\nprint(f\"Description: {{tech_details.description}}\")\n```\n\nImprtantly, they are not under api.* namespace, so you can call them directly.\n\n\"\"\"\n\n    return prompt\n\ndef fulltext_search(query: str, k: int = 5) -> List[Dict[str, Any]]:\n    \"\"\"\n    Perform full-text search using BM25 index\n    \n    Parameters:\n    - query (str): The search query\n    - k (int): Number of results to return (default: 5)\n    \n    Returns:\n    - List[Dict]: List of matching documents with metadata\n    \"\"\"\n    if not bm25_retriever or not bm25_metadata:\n        raise Exception(\"Error: BM25 index not loaded\")\n    \n    # Tokenize query\n    query_tokens = bm25s.tokenize(query)\n    \n    # Get results\n    results, scores = bm25_retriever.retrieve(query_tokens, k=k)\n    \n    # Format results\n    search_results = []\n    for i in range(results.shape[1]):\n        doc_idx = results[0, i]\n        score = scores[0, i]\n        \n        # Get metadata for the document\n        metadata = bm25_metadata[doc_idx]\n        doc_type = metadata['type']\n        doc_id = metadata['id']\n        \n        # Get full details based on type\n        if doc_type == 'tech':\n            details = read_tech_details(doc_id)\n            if details:\n                search_results.append({\n                    'type': doc_type,\n                    'id': doc_id,\n                    'name': details.name,\n                    'description': details.description,\n                    'score': float(score),\n                    'documentation': details.documentation,\n                    'category': details.category,\n                    'provider_node_ids': details.provider_node_ids,\n                })\n        elif doc_type == 'node':\n            details = read_node_details(doc_id)\n            if details:\n                search_results.append({\n                    'type': doc_type,\n                    'id': doc_id,\n                    'name': details.name,\n                    'description': details.description,\n                    'score': float(score),\n                    'documentation': details.documentation,\n                    'country': details.country,\n                    'offer_technology_ids': details.offer_technology_ids,\n                })\n        elif doc_type == 'page':\n            details = read_website_page_details(doc_id)\n            if details:\n                search_results.append({\n                    'type': doc_type,\n                    'id': doc_id,\n                    'name': details.title,\n                    'description': details.description,\n                    'score': float(score),\n                    'url': details.url,\n                    'documentation': details.documentation,\n                    'headings': details.headings,\n                    'page_type': details.page_type,\n                })\n    \n    return search_results\n\n# Initialize data and create the search prompt\ndata_loaded = await load_eurobioimaging_data()\n\nif not data_loaded:\n    print(\"WARNING: \u274c Failed to load Euro-BioImaging data, none of the following functions will work properly.\")\n\nprint(\"\"\"\nYou are an AI assistant specialized in helping users discover imaging technologies, instruments, and services provided by the Euro-BioImaging network.\nYou have access to several utility functions for retrieving specific information about Euro-BioImaging facilities. Below are all the available resources in the Euro-BioImaging network:\n\"\"\")\n\n# Print the search context with all available data\nsearch_context = create_search_prompt()\nprint(search_context)\n\n# The printed text will be used for the LLM agent as prompt.\nprint(\"\"\"## \ud83d\udee0\ufe0f Available Utility Functions\n\n**IMPORTANT**: Call these functions directly - NO `await`, NO `api.` prefix, NO keyword arguments!\n\n### Detail Retrieval Functions\n- `read_tech_details(tech_id)` \u2192 `TechDetail(id, name, original_id, description, documentation, category, provider_node_ids, abbr)` or `None`\n- `read_node_details(node_id)` \u2192 `NodeDetail(id, name, original_id, description, documentation, country, offer_technology_ids)` or `None`  \n- `read_nodes_by_country(country_code)` \u2192 `List[NodeDetail(id, name, original_id, description, documentation, country, offer_technology_ids)]`\n- `read_website_page_details(page_id)` \u2192 `WebsitePageDetail(id, url, title, description, documentation, headings, page_type)` or `None`\nThe returned objects are pydantic models, so you can access the attributes directly. For example: tech_details.name, node_details.country['name'], etc.\n\n### Search Functions\n- `fulltext_search(query, k=5)` \u2192 `List[Dict]` (full-text search across all content types)\n- `get_country_codes()` \u2192 `Dict[str, str]` (country_name \u2192 ISO_code)\n\n\n## \u2705 Correct Function Call Examples\n\n```python\n# CORRECT: Get node details\nnode_details = read_node_details(\"48c78d41\")\nprint(f\"Node: {node_details.name}\")\nprint(f\"Country: {node_details.country['name']}\")\nprint(f\"Description: {node_details.description}\")\n\n# CORRECT: Get technology details  \ntech_details = read_tech_details(\"02e4459a\")\nprint(f\"Technology: {tech_details.name}\")\nprint(f\"Category: {tech_details.category['name']}\")\nprint(f\"Available at {len(tech_details.provider_node_ids)} nodes\")\n\n# CORRECT: Get all nodes in Germany\ngerman_nodes = read_nodes_by_country(\"DE\")\nfor node in german_nodes:\n    print(f\"Node: {node.name}\")\n    print(f\"Technologies: {len(node.offer_technology_ids)} available\")\n\n# CORRECT: Full-text search across all content\nresults = fulltext_search(\"super resolution microscopy\", k=5)\nfor result in results:\n    print(f\"Score: {result['score']:.2f} - Type: {result['type']} - Name: {result['name']}\")\n    print(f\"Description: {result['description']}\")\n```\n\n## \u274c WRONG Function Call Examples\n\n```python\n# WRONG: Don't use await\nnode_details = await read_node_details(\"48c78d41\")  # \u274c\n\n# WRONG: Don't use api prefix\nnode_details = api.read_node_details(\"48c78d41\")  # \u274c\n\n# WRONG: Don't use keyword arguments\nnode_details = read_node_details(node_id=\"48c78d41\")  # \u274c\n\n# WRONG: Don't combine await + api\nnode_details = await api.read_node_details(node_id=\"48c78d41\")  # \u274c\n```\n\n## \ud83e\udde0 How to Answer User Queries\n\nFollow this systematic approach:\n\n### 1. **Analyze the Query Type**\n- **Geographic queries** (e.g., \"facilities in Germany\"): Focus on specific countries/regions\n- **Technology queries** (e.g., \"super-resolution microscopy\"): Focus on specific techniques or instruments  \n- **General information** (e.g., \"how to access services\"): Focus on website pages and general guidance\n- **Listing queries** (e.g., \"all available nodes\"): Provide comprehensive listings\n\n### 2. **Select Relevant IDs**\nFrom the indexes above, identify the specific IDs you need by looking at the summaries:\n- **Technology IDs**: Look for relevant techniques in the technology list, extract the ID before the colon\n- **Node IDs**: Look for relevant facilities in the node list, extract the ID before the colon\n- **Country codes**: Use the ISO codes in parentheses (e.g., DE, SE, FR)\n- **Page IDs**: Look for relevant information pages, extract the ID before the colon\n\n**Example**: If you see `tech_super_res_microscopy: Super-Resolution Microscopy (available at 15 nodes)`, use `tech_super_res_microscopy` as the ID.\n\n### 3. **Retrieve Detailed Information**\nUse the utility functions systematically:\n\n**For Technology Queries:**\n```python\n# Example: \"Where can I find MINFLUX?\"\n# Step 1: Get the specific technology details\nminflux_details = read_tech_details(\"4bf1cfdd\")  # Extract ID from index\nprint(f\"Technology: {minflux_details.name}\")\n\n# Step 2: Get nodes where it's available (don't list all their technologies)\nfor node_id in minflux_details.provider_node_ids:\n    node_details = read_node_details(node_id)\n    print(f\"Available at: {node_details.name} in {node_details.country['name']}\")\n```\n\n**For Geographic Queries:**\n```python\n# Example: \"What imaging facilities are in Germany?\"\ncountry_nodes = read_nodes_by_country(\"DE\")  # Germany\nfor node in country_nodes:\n    print(f\"Node: {node.name}\")\n    print(f\"Description: {node.description}\")\n    print(f\"Technologies available: {len(node.offer_technology_ids)} total\")\n    # Only list technologies if specifically asked, don't retrieve all details\n```\n\n**For General Full-text Search:**\n```python\n# Use full-text search to find relevant content\nresults = fulltext_search(\"access services application\", k=5)\nfor result in results:\n    if result['type'] == 'page':\n        page_details = read_website_page_details(result['id'])\n        print(f\"Page: {page_details.title}\")\n        print(f\"URL: {page_details.url}\")\n        print(f\"Description: {page_details.description}\")\n```\n\n```python\n# Example: \"Find super-resolution microscopy techniques\"\nresults = fulltext_search(\"super resolution microscopy\", k=3)\nfor result in results:\n    if result['type'] == 'tech':\n        print(f\"Technology: {result['name']} (Score: {result['score']:.2f})\")\n        print(f\"Description: {result['description']}\")\n        # Get provider nodes if needed\n        tech_details = read_tech_details(result['id'])\n        for node_id in tech_details.provider_node_ids:\n            node_details = read_node_details(node_id)\n            print(f\"  Available at: {node_details.name} in {node_details.country['name']}\")\n```\n\n### 4. **Be Focused and Efficient**\n- Only retrieve information that directly answers the user's question\n- Don't list all technologies at a node unless specifically asked\n- Don't retrieve all details unless needed for the specific query\n- Answer the question, don't provide unnecessary comprehensive listings\n\n### 5. **Reason Across Results**\n- Integrate information from multiple search results if needed\n- Draw conclusions, extract availability details, instrument capabilities, node locations, and relevant contact information\n\n### 6. **Handle AI-Enhanced Content Transparently**\n- **Check for AI enhancement markers** in technology documentation:\n  - Look for \"## AI Generated Documentation\" sections\n  - Look for \"## References\" sections with sources\n- **When using AI-enhanced content**:\n  - Mention that information is AI-enhanced: \"Based on AI-enhanced documentation...\"\n  - Cite sources from References sections: \"According to sources including [source name](url)...\"\n\n### 7. **Respond Factually and Comprehensively**\n- Ensure your final reply contains all key findings and actionable information\n- Always include all relevant details in your final answer, the intermediate script output won't be seen by the user\n- Avoid vague summaries\u2014be precise and specific based on the returned context\n- **Be transparent about information sources** throughout your response\n\n## \ud83d\udccb Query Pattern Examples\n\n**Geographic Query**: \"What imaging facilities are available in Germany?\"\n1. Use `read_nodes_by_country(\"DE\")` to get all German nodes\n2. For each node, use `read_node_details()` to get full information\n3. For each technology at the nodes, use `read_tech_details()` to understand capabilities\n\n**Technology Query**: \"Where can I access super-resolution microscopy?\"\n1. Use `fulltext_search(\"super resolution microscopy\", k=3)` to find relevant technologies and nodes\n2. Filter results by type to focus on technologies and nodes\n3. Use `read_tech_details()` and `read_node_details()` to get detailed information\n\n**General Information**: \"How do I access Euro-BioImaging services?\"\n1. Use `fulltext_search(\"access services application procedures\", k=3)` to find relevant content\n2. Filter results for website pages that contain access information\n3. Use `read_website_page_details()` for each relevant page to get detailed information\n\n## \ud83c\udfaf Response Quality Guidelines\n0. When generating the thoughts, limit each thought to 5 words maximum.\n1. **Use the indexes above** to identify relevant resources by their summaries\n2. **Extract IDs correctly** (the part before the colon) from the index entries\n3. **Call functions directly** without await, api prefix, or keyword arguments\n4. **Be systematic** in retrieving details for all relevant items\n5. **Include geographic context** (country names and codes)\n6. **Provide comprehensive information** which corresponds to the user query, try to be helpful and comprehensive.\n7. Since we are targeting non-technical users, unless asked, you can generate and execute scripts, but no need to commit code during the final response.\n\nRemember: Scan the indexes for relevant entries, extract the correct IDs, then call the utility functions directly to get detailed information.\n\"\"\") \n",
          "welcomeMessage": "",
          "modelConfig": {
            "baseURL": "https://api.openai.com/v1/",
            "model": "gpt-4o",
            "temperature": 0.7
          },
          "chat_template": {
            "metadata": {
              "modified": "2025-06-30T19:40:28.937Z",
              "kernelspec": {
                "name": "python3",
                "display_name": "Python 3"
              },
              "language_info": {
                "name": "python",
                "version": "3.9"
              },
              "title": "Euro-BioImaging Finder",
              "created": "2025-06-30T19:36:37.655Z",
              "filePath": "Euro-BioImaging Finder_2025-06-30T19-36-37-655Z.ipynb",
              "projectId": "in-browser",
              "description": null,
              "agentArtifact": {
                "id": "hypha-agents/leisure-scrimmage-disliked-more",
                "version": null,
                "name": "Euro-BioImaging Finder",
                "description": "An Agent to Navigate the Euro-BioImaging services.",
                "manifest": {
                  "name": "Euro-BioImaging Finder",
                  "description": "An Agent to Navigate the Euro-BioImaging services.",
                  "version": "0.1.0",
                  "license": "CC-BY-4.0",
                  "lang": "python",
                  "type": "agent",
                  "created_at": "2025-06-29T18:56:59.703Z",
                  "startup_script": "import micropip\nawait micropip.install([\"httpx\", \"pydantic\", \"bm25s\"])\n\nimport httpx\nfrom typing import Dict, List, Any, Optional, Tuple\nfrom pydantic import BaseModel\nimport bm25s\nfrom pathlib import Path\nimport tempfile\nimport micropip\nimport pickle\n\nclass TechDetail(BaseModel):\n    \"\"\"Details of a specific technology\"\"\"\n    id: str\n    name: str\n    original_id: str\n    description: str\n    keywords: List[str]\n    documentation: str\n    category: Dict[str, Any]\n    provider_node_ids: List[str]\n    abbr: str\n\nclass NodeDetail(BaseModel):\n    \"\"\"Details of a specific node\"\"\"\n    id: str\n    name: str\n    original_id: str\n    description: str\n    keywords: List[str]\n    documentation: str\n    country: Dict[str, Any]\n    offer_technology_ids: List[str]\n\nclass WebsitePageDetail(BaseModel):\n    \"\"\"Details of a Euro-BioImaging website page\"\"\"\n    id: str\n    url: str\n    title: str\n    description: str\n    keywords: List[str]\n    documentation: str\n    headings: List[str]\n    page_type: str\n\nclass SearchResponse(BaseModel):\n    \"\"\"Structured search response\"\"\"\n    answer: str\n    relevant_technologies: List[str] = []\n    relevant_nodes: List[str] = []\n    relevant_pages: List[str] = []\n    summary: str = \"\"\n\n# Global data storage\ntech_data: List[Dict[str, Any]] = []\nnodes_data: List[Dict[str, Any]] = []\nwebsite_data: List[Dict[str, Any]] = []\nbm25_retriever = None\nbm25_metadata = None\n\nasync def load_eurobioimaging_data():\n    \"\"\"\n    Load Euro-BioImaging data from remote index file.\n    This function fetches the combined index from the remote URL and populates the global data structures.\n    \n    Returns:\n    - dict: Metadata about the loaded dataset including counts and creation info\n    \"\"\"\n    global tech_data, nodes_data, website_data, bm25_retriever, bm25_metadata\n    \n    base_url = \"https://oeway.github.io/euro-bioimaging-finder\"\n    \n    try:\n        async with httpx.AsyncClient(timeout=30.0) as client:\n            # Load main index\n            response = await client.get(f\"{base_url}/eurobioimaging_index.json\")\n            response.raise_for_status()\n            combined_data = response.json()\n            \n            # Extract data from combined index\n            tech_data = combined_data.get('technologies', [])\n            nodes_data = combined_data.get('nodes', [])\n            website_data = combined_data.get('website_pages', [])\n            bm25_metadata = combined_data.get('bm25_metadata', [])\n            \n            # Download and load BM25 pickle file\n            bm25_response = await client.get(f\"{base_url}/eurobioimaging_bm25_index.pkl\")\n            bm25_response.raise_for_status()\n            \n            # Save to temp file and load\n            with tempfile.NamedTemporaryFile(suffix='.pkl', delete=False) as temp_file:\n                temp_file.write(bm25_response.content)\n                temp_file.flush()\n                \n                with open(temp_file.name, 'rb') as f:\n                    bm25_retriever = pickle.load(f)\n            \n            # Get metadata\n            metadata = combined_data.get('metadata', {})\n            dataset_info = {\n                'dataset_type': metadata.get('dataset_type', 'unknown'),\n                'created_at': metadata.get('created_at', 'unknown'),\n                'technologies_count': len(tech_data),\n                'nodes_count': len(nodes_data),\n                'website_pages_count': len(website_data),\n                'total_entries': len(tech_data) + len(nodes_data) + len(website_data),\n                'bm25_documents': len(bm25_metadata) if bm25_metadata else 0\n            }\n            \n            return dataset_info\n            \n    except Exception as e:\n        print(f\"Error loading data: {e}\")\n        tech_data = []\n        nodes_data = []\n        website_data = []\n        bm25_retriever = None\n        bm25_metadata = None\n        raise e\n\ndef read_tech_details(tech_id: str):\n    \"\"\"\n    Read details of a specific technology by ID.\n    \n    Parameters:\n    - tech_id (str): The technology ID\n    \n    Returns:\n    - Optional[TechDetail]: Technology details or None if not found\n    \"\"\"\n    for tech in tech_data:\n        if tech['id'] == tech_id:\n            return TechDetail(**tech)\n    raise Exception(f\"Technology with ID {tech_id} not found\")\n\ndef read_node_details(node_id: str):\n    \"\"\"\n    Read details of a specific node by ID.\n    \n    Parameters:\n    - node_id (str): The node ID\n    \n    Returns:\n    - Optional[NodeDetail]: Node details or None if not found\n    \"\"\"\n    for node in nodes_data:\n        if node['id'] == node_id:\n            return NodeDetail(**node)\n    raise Exception(f\"Node with ID {node_id} not found\")\n\ndef read_nodes_by_country(country_code: str):\n    \"\"\"\n    Read all nodes in a specific country by ISO country code.\n    \n    Parameters:\n    - country_code (str): ISO country code (e.g., 'PL', 'SE', 'DE')\n    \n    Returns:\n    - List[NodeDetail]: List of all nodes in the specified country\n    \"\"\"\n    country_nodes = []\n    for node in nodes_data:\n        node_country = node.get('country', {})\n        if node_country.get('iso_a2', '').upper() == country_code.upper():\n            try:\n                country_nodes.append(NodeDetail(**node))\n            except Exception as e:\n                print(f\"Warning: Could not parse node {node.get('name', 'Unknown')}: {e}\")\n    return country_nodes\n\ndef read_website_page_details(page_id: str):\n    \"\"\"\n    Read details of a specific website page by ID.\n    \n    Parameters:\n    - page_id (str): The website page ID\n    \n    Returns:\n    - Optional[WebsitePageDetail]: Website page details or None if not found\n    \"\"\"\n    for page in website_data:\n        if page['id'] == page_id:\n            return WebsitePageDetail(**page)\n    raise Exception(f\"Website page with ID {page_id} not found\")\n\ndef get_country_codes():\n    \"\"\"\n    Get mapping of country names to ISO codes from the data.\n    \n    Returns:\n    - Dict[str, str]: Mapping of country names to ISO codes\n    \"\"\"\n    country_mapping = {}\n    for node in nodes_data:\n        country = node.get('country', {})\n        country_name = country.get('name', '')\n        country_code = country.get('iso_a2', '')\n        if country_name and country_code:\n            country_mapping[country_name.lower()] = country_code.upper()\n    return country_mapping\n\ndef find_nodes_by_technique(technique_keywords: List[str]):\n    \"\"\"\n    Find node IDs that offer technologies matching the given technique keywords.\n    \n    Parameters:\n    - technique_keywords (List[str]): List of technique-related keywords\n    \n    Returns:\n    - List[str]: List of node IDs offering the specified techniques\n    \"\"\"\n    matching_node_ids = set()\n    \n    # Search through all technologies to find matches\n    for tech in tech_data:\n        tech_name = tech.get('name', '').lower()\n        tech_keywords = [kw.lower() for kw in tech.get('keywords', [])]\n        tech_category = tech.get('category', {}).get('name', '').lower()\n        tech_abbr = tech.get('abbr', '').lower()\n        tech_description = tech.get('documentation', '').lower()\n        \n        match_score = 0\n        matched_keywords = 0\n        \n        for keyword in technique_keywords:\n            keyword_lower = keyword.lower()\n            \n            if keyword_lower == tech_name or keyword_lower == tech_abbr:\n                match_score += 10\n                matched_keywords += 1\n            elif keyword_lower in tech_name or keyword_lower in tech_abbr:\n                match_score += 5\n                matched_keywords += 1\n            elif keyword_lower in tech_category:\n                match_score += 3\n                matched_keywords += 1\n            elif any(keyword_lower in kw or kw in keyword_lower for kw in tech_keywords):\n                match_score += 2\n                matched_keywords += 1\n            elif keyword_lower in tech_description:\n                match_score += 1\n                matched_keywords += 1\n        \n        if match_score >= 2 or matched_keywords >= 2:\n            matching_node_ids.update(tech.get('provider_node_ids', []))\n    \n    return list(matching_node_ids)\n\ndef find_website_pages_by_keywords(keywords: List[str]):\n    \"\"\"\n    Find website page IDs that match the given keywords with relevance scoring.\n    \n    Parameters:\n    - keywords (List[str]): List of keywords to search for\n    \n    Returns:\n    - List[str]: List of website page IDs matching the keywords\n    \"\"\"\n    page_scores = []\n    \n    for page in website_data:\n        page_title = page.get('title', '').lower()\n        page_description = page.get('description', '').lower()\n        page_keywords = [kw.lower() for kw in page.get('keywords', [])]\n        page_content = page.get('documentation', '').lower()\n        page_type = page.get('page_type', '').lower()\n        \n        score = 0\n        matched_keywords = 0\n        \n        for keyword in keywords:\n            keyword_lower = keyword.lower()\n            if keyword_lower in page_title:\n                score += 5\n                matched_keywords += 1\n            elif keyword_lower in page_description:\n                score += 3\n                matched_keywords += 1\n            elif any(keyword_lower in kw for kw in page_keywords):\n                score += 2\n                matched_keywords += 1\n            elif keyword_lower in page_content:\n                score += 1\n                matched_keywords += 1\n        \n        if 'about' in page_type or 'service' in page_type or 'access' in page_type:\n            score += 2\n        \n        if matched_keywords > 0 and score >= 2:\n            page_scores.append((page['id'], score, matched_keywords))\n    \n    page_scores.sort(key=lambda x: (x[1], x[2]), reverse=True)\n    return [page_id for page_id, _, _ in page_scores[:10]]\n\ndef create_search_prompt():\n    \"\"\"Create the search prompt with all available data indexes\"\"\"\n    \n    def truncate_line(line: str, max_length: int = 256) -> str:\n        \"\"\"Truncate line to max_length, preserving the format\"\"\"\n        if len(line) <= max_length:\n            return line\n        return line[:max_length-3] + \"...\"\n    \n    # Create technology index with \"- id: name / description\" format\n    tech_index = []\n    for tech in tech_data:\n        name = tech.get('name', '')\n        description = tech.get('description', '').replace('\\n', ' ').strip()\n        line = f\"- {tech['id']}:{name}/{description}\"\n        tech_index.append(truncate_line(line))\n    \n    # Create nodes index with \"- id:name/description\" format, grouped by country\n    nodes_by_country = {}\n    country_codes_info = {}\n    for node in nodes_data:\n        country = node['country']['name']\n        country_code = node['country'].get('iso_a2', 'XX')\n        if country not in nodes_by_country:\n            nodes_by_country[country] = []\n            country_codes_info[country] = country_code\n        \n        name = node.get('name', '')\n        description = node.get('description', '').replace('\\n', ' ').strip()\n        line = f\"- {node['id']}:{name}/{description}\"\n        nodes_by_country[country].append(truncate_line(line))\n    \n    nodes_index = []\n    for country, country_nodes in sorted(nodes_by_country.items()):\n        country_code = country_codes_info[country]\n        nodes_index.append(f\"\\n**{country} ({country_code}):**\")\n        nodes_index.extend([f\"  {node}\" for node in country_nodes])\n    \n    # Create website pages index with \"- id: title / description\" format\n    website_index = []\n    for page in website_data:\n        title = page.get('title', '')\n        description = page.get('description', '').replace('\\n', ' ').strip()\n        line = f\"- {page['id']}:{title}/{description}\"\n        website_index.append(truncate_line(line))\n    \n    prompt = f\"\"\"\nHere is a list of all the available resources associated with their IDs.\n\n## Available General Website Pages:\n{chr(10).join(website_index)}\n\n## Available Technologies: \n{chr(10).join(tech_index)}\n\n## Available Nodes by Country (with ISO codes):\n{chr(10).join(nodes_index)}\n\n**IMPORTANT**: Each entry in the indexes above follows the format `- ID: Name / Description`\n\n- For **Technologies**: `- tech_id: Technology Name/Brief description`\n- For **Nodes**: `- node_id: Node Name/Brief description` \n- For **Website Pages**: `- page_id: Page Title/Brief description`\n\nFor any matched topics, you can call the utility functions to get more details by the ID.\n\n**To use the utility functions**: Extract the ID (the part after the dash and before the colon) and pass it to the appropriate function:\n- Use `tech_id` with `read_tech_details(tech_id)`\n- Use `node_id` with `read_node_details(node_id)` \n- Use `page_id` with `read_website_page_details(page_id)`\n\nThese utilities are available under the current execution context, and no need to use await to call them. For example:\n\n```python\n# Example: Get details of a specific technology\ntech_details = read_tech_details(\"02e4459a\")\nprint(f\"Technology: {{tech_details.name}}\")\nprint(f\"Description: {{tech_details.description}}\")\n```\n\nImprtantly, they are not under api.* namespace, so you can call them directly.\n\n\"\"\"\n\n    return prompt\n\ndef fulltext_search(query: str, k: int = 5) -> List[Dict[str, Any]]:\n    \"\"\"\n    Perform full-text search using BM25 index\n    \n    Parameters:\n    - query (str): The search query\n    - k (int): Number of results to return (default: 5)\n    \n    Returns:\n    - List[Dict]: List of matching documents with metadata\n    \"\"\"\n    if not bm25_retriever or not bm25_metadata:\n        raise Exception(\"Error: BM25 index not loaded\")\n    \n    # Tokenize query\n    query_tokens = bm25s.tokenize(query)\n    \n    # Get results\n    results, scores = bm25_retriever.retrieve(query_tokens, k=k)\n    \n    # Format results\n    search_results = []\n    for i in range(results.shape[1]):\n        doc_idx = results[0, i]\n        score = scores[0, i]\n        \n        # Get metadata for the document\n        metadata = bm25_metadata[doc_idx]\n        doc_type = metadata['type']\n        doc_id = metadata['id']\n        \n        # Get full details based on type\n        if doc_type == 'tech':\n            details = read_tech_details(doc_id)\n            if details:\n                search_results.append({\n                    'type': doc_type,\n                    'id': doc_id,\n                    'name': details.name,\n                    'description': details.description,\n                    'score': float(score),\n                    'documentation': details.documentation,\n                    'category': details.category,\n                    'provider_node_ids': details.provider_node_ids,\n                })\n        elif doc_type == 'node':\n            details = read_node_details(doc_id)\n            if details:\n                search_results.append({\n                    'type': doc_type,\n                    'id': doc_id,\n                    'name': details.name,\n                    'description': details.description,\n                    'score': float(score),\n                    'documentation': details.documentation,\n                    'country': details.country,\n                    'offer_technology_ids': details.offer_technology_ids,\n                })\n        elif doc_type == 'page':\n            details = read_website_page_details(doc_id)\n            if details:\n                search_results.append({\n                    'type': doc_type,\n                    'id': doc_id,\n                    'name': details.title,\n                    'description': details.description,\n                    'score': float(score),\n                    'url': details.url,\n                    'documentation': details.documentation,\n                    'headings': details.headings,\n                    'page_type': details.page_type,\n                })\n    \n    return search_results\n\n# Initialize data and create the search prompt\ndata_loaded = await load_eurobioimaging_data()\n\nif not data_loaded:\n    print(\"WARNING: \u274c Failed to load Euro-BioImaging data, none of the following functions will work properly.\")\n\nprint(\"\"\"\nYou are an AI assistant specialized in helping users discover imaging technologies, instruments, and services provided by the Euro-BioImaging network.\n\nYou have access to several utility functions for retrieving specific information about Euro-BioImaging facilities. Below are all the available resources in the Euro-BioImaging network:\n\"\"\")\n\n# Print the search context with all available data\nsearch_context = create_search_prompt()\nprint(search_context)\n\n# The printed text will be used for the LLM agent as prompt.\nprint(\"\"\"## \ud83d\udee0\ufe0f Available Utility Functions\n\n**IMPORTANT**: Call these functions directly - NO `await`, NO `api.` prefix, NO keyword arguments!\n\n### Detail Retrieval Functions\n- `read_tech_details(tech_id)` \u2192 `TechDetail(id, name, original_id, description, keywords, documentation, category, provider_node_ids, abbr)` or `None`\n- `read_node_details(node_id)` \u2192 `NodeDetail(id, name, original_id, description, keywords, documentation, country, offer_technology_ids)` or `None`  \n- `read_nodes_by_country(country_code)` \u2192 `List[NodeDetail(id, name, original_id, description, keywords, documentation, country, offer_technology_ids)]`\n- `read_website_page_details(page_id)` \u2192 `WebsitePageDetail(id, url, title, description, keywords, documentation, headings, page_type)` or `None`\nThe returned objects are pydantic models, so you can access the attributes directly. For example: tech_details.name, node_details.country['name'], etc.\n\n### Search Functions\n- `fulltext_search(query, k=5)` \u2192 `List[Dict]` (full-text search across all content types)\n- `get_country_codes()` \u2192 `Dict[str, str]` (country_name \u2192 ISO_code)\n\n\n## \u2705 Correct Function Call Examples\n\n```python\n# CORRECT: Get node details\nnode_details = read_node_details(\"48c78d41\")\nprint(f\"Node: {node_details.name}\")\nprint(f\"Country: {node_details.country['name']}\")\nprint(f\"Description: {node_details.description}\")\n\n# CORRECT: Get technology details  \ntech_details = read_tech_details(\"02e4459a\")\nprint(f\"Technology: {tech_details.name}\")\nprint(f\"Category: {tech_details.category['name']}\")\nprint(f\"Available at {len(tech_details.provider_node_ids)} nodes\")\n\n# CORRECT: Get all nodes in Germany\ngerman_nodes = read_nodes_by_country(\"DE\")\nfor node in german_nodes:\n    print(f\"Node: {node.name}\")\n    print(f\"Technologies: {len(node.offer_technology_ids)} available\")\n\n# CORRECT: Full-text search across all content\nresults = fulltext_search(\"super resolution microscopy\", k=5)\nfor result in results:\n    print(f\"Score: {result['score']:.2f} - Type: {result['type']} - Name: {result['name']}\")\n    print(f\"Description: {result['description']}\")\n```\n\n## \u274c WRONG Function Call Examples\n\n```python\n# WRONG: Don't use await\nnode_details = await read_node_details(\"48c78d41\")  # \u274c\n\n# WRONG: Don't use api prefix\nnode_details = api.read_node_details(\"48c78d41\")  # \u274c\n\n# WRONG: Don't use keyword arguments\nnode_details = read_node_details(node_id=\"48c78d41\")  # \u274c\n\n# WRONG: Don't combine await + api\nnode_details = await api.read_node_details(node_id=\"48c78d41\")  # \u274c\n```\n\n## \ud83e\udde0 How to Answer User Queries\n\nFollow this systematic approach:\n\n### 1. **Analyze the Query Type**\n- **Geographic queries** (e.g., \"facilities in Germany\"): Focus on specific countries/regions\n- **Technology queries** (e.g., \"super-resolution microscopy\"): Focus on specific techniques or instruments  \n- **General information** (e.g., \"how to access services\"): Focus on website pages and general guidance\n- **Listing queries** (e.g., \"all available nodes\"): Provide comprehensive listings\n\n### 2. **Select Relevant IDs**\nFrom the indexes above, identify the specific IDs you need by looking at the summaries:\n- **Technology IDs**: Look for relevant techniques in the technology list, extract the ID before the colon\n- **Node IDs**: Look for relevant facilities in the node list, extract the ID before the colon\n- **Country codes**: Use the ISO codes in parentheses (e.g., DE, SE, FR)\n- **Page IDs**: Look for relevant information pages, extract the ID before the colon\n\n**Example**: If you see `tech_super_res_microscopy: Super-Resolution Microscopy (available at 15 nodes)`, use `tech_super_res_microscopy` as the ID.\n\n### 3. **Retrieve Detailed Information**\nUse the utility functions systematically:\n\n**For Technology Queries:**\n```python\n# Example: \"Where can I find MINFLUX?\"\n# Step 1: Get the specific technology details\nminflux_details = read_tech_details(\"4bf1cfdd\")  # Extract ID from index\nprint(f\"Technology: {minflux_details.name}\")\n\n# Step 2: Get nodes where it's available (don't list all their technologies)\nfor node_id in minflux_details.provider_node_ids:\n    node_details = read_node_details(node_id)\n    print(f\"Available at: {node_details.name} in {node_details.country['name']}\")\n```\n\n**For Geographic Queries:**\n```python\n# Example: \"What imaging facilities are in Germany?\"\ncountry_nodes = read_nodes_by_country(\"DE\")  # Germany\nfor node in country_nodes:\n    print(f\"Node: {node.name}\")\n    print(f\"Description: {node.description}\")\n    print(f\"Technologies available: {len(node.offer_technology_ids)} total\")\n    # Only list technologies if specifically asked, don't retrieve all details\n```\n\n**For General Full-text Search:**\n```python\n# Use full-text search to find relevant content\nresults = fulltext_search(\"access services application\", k=5)\nfor result in results:\n    if result['type'] == 'page':\n        page_details = read_website_page_details(result['id'])\n        print(f\"Page: {page_details.title}\")\n        print(f\"URL: {page_details.url}\")\n        print(f\"Description: {page_details.description}\")\n```\n\n```python\n# Example: \"Find super-resolution microscopy techniques\"\nresults = fulltext_search(\"super resolution microscopy\", k=3)\nfor result in results:\n    if result['type'] == 'tech':\n        print(f\"Technology: {result['name']} (Score: {result['score']:.2f})\")\n        print(f\"Description: {result['description']}\")\n        # Get provider nodes if needed\n        tech_details = read_tech_details(result['id'])\n        for node_id in tech_details.provider_node_ids:\n            node_details = read_node_details(node_id)\n            print(f\"  Available at: {node_details.name} in {node_details.country['name']}\")\n```\n\n### 4. **Be Focused and Efficient**\n- Only retrieve information that directly answers the user's question\n- Don't list all technologies at a node unless specifically asked\n- Don't retrieve all details unless needed for the specific query\n- Answer the question, don't provide unnecessary comprehensive listings\n\n### 5. **Reason Across Results**\n- Integrate information from multiple search results if needed\n- Draw conclusions, extract availability details, instrument capabilities, node locations, and relevant contact information\n\n### 6. **Respond Factually and Comprehensively**\n- Ensure your final reply contains all key findings and actionable information\n- Always include all relevant details in your final answer, the intermediate script output won't be seen by the user\n- Avoid vague summaries\u2014be precise and specific based on the returned context\n\n## \ud83d\udccb Query Pattern Examples\n\n**Geographic Query**: \"What imaging facilities are available in Germany?\"\n1. Use `read_nodes_by_country(\"DE\")` to get all German nodes\n2. For each node, use `read_node_details()` to get full information\n3. For each technology at the nodes, use `read_tech_details()` to understand capabilities\n\n**Technology Query**: \"Where can I access super-resolution microscopy?\"\n1. Use `fulltext_search(\"super resolution microscopy\", k=3)` to find relevant technologies and nodes\n2. Filter results by type to focus on technologies and nodes\n3. Use `read_tech_details()` and `read_node_details()` to get detailed information\n\n**General Information**: \"How do I access Euro-BioImaging services?\"\n1. Use `fulltext_search(\"access services application procedures\", k=3)` to find relevant content\n2. Filter results for website pages that contain access information\n3. Use `read_website_page_details()` for each relevant page to get detailed information\n\n## \ud83c\udfaf Response Quality Guidelines\n0. When generating the thoughts, limit each thought to 5 words maximum.\n1. **Use the indexes above** to identify relevant resources by their summaries\n2. **Extract IDs correctly** (the part before the colon) from the index entries\n3. **Call functions directly** without await, api prefix, or keyword arguments\n4. **Be systematic** in retrieving details for all relevant items\n5. **Include geographic context** (country names and codes)\n6. **Provide comprehensive information** which corresponds to the user query, try to be helpful and comprehensive.\n7. Since we are targeting non-technical users, unless asked, you can generate and execute scripts, but no need to commit code during the final response.\n\nRemember: Scan the indexes for relevant entries, extract the correct IDs, then call the utility functions directly to get detailed information.\n\"\"\") \n",
                  "welcomeMessage": "",
                  "modelConfig": {
                    "baseURL": "https://api.openai.com/v1/",
                    "model": "gpt-4o",
                    "temperature": 0.7
                  },
                  "chat_template": {
                    "metadata": {
                      "modified": "2025-06-29T18:56:55.588Z",
                      "kernelspec": {
                        "name": "python3",
                        "display_name": "Python 3"
                      },
                      "language_info": {
                        "name": "python",
                        "version": "3.9"
                      },
                      "title": "Euro-BioImaging Finder",
                      "created": "2025-06-26T16:14:29.088Z",
                      "filePath": "Euro-BioImaging Finder_2025-06-26T16-14-29-087Z.ipynb",
                      "projectId": "in-browser",
                      "description": null,
                      "agentArtifact": {
                        "id": "hypha-agents/leisure-scrimmage-disliked-more",
                        "version": null,
                        "name": "Euro-BioImaging Finder",
                        "description": "An Agent to Navigate the Euro-BioImaging services.",
                        "manifest": {
                          "name": "Euro-BioImaging Finder",
                          "description": "An Agent to Navigate the Euro-BioImaging services.",
                          "version": "0.1.0",
                          "license": "CC-BY-4.0",
                          "lang": "python",
                          "type": "agent",
                          "created_at": "2025-06-26T14:49:01.885Z",
                          "startup_script": "import micropip\nawait micropip.install([\"httpx\", \"pydantic\"])\n\nimport httpx\nfrom typing import Dict, List, Any\nfrom pydantic import BaseModel\n\nclass TechDetail(BaseModel):\n    \"\"\"Details of a specific technology\"\"\"\n    id: str\n    name: str\n    original_id: str\n    description: str\n    keywords: List[str]\n    documentation: str\n    category: Dict[str, Any]\n    provider_node_ids: List[str]\n    abbr: str\n\nclass NodeDetail(BaseModel):\n    \"\"\"Details of a specific node\"\"\"\n    id: str\n    name: str\n    original_id: str\n    description: str\n    keywords: List[str]\n    documentation: str\n    country: Dict[str, Any]\n    offer_technology_ids: List[str]\n\nclass WebsitePageDetail(BaseModel):\n    \"\"\"Details of a Euro-BioImaging website page\"\"\"\n    id: str\n    url: str\n    title: str\n    description: str\n    keywords: List[str]\n    content_preview: str\n    headings: List[str]\n    page_type: str\n\nclass SearchResponse(BaseModel):\n    \"\"\"Structured search response\"\"\"\n    answer: str\n    relevant_technologies: List[str] = []\n    relevant_nodes: List[str] = []\n    relevant_pages: List[str] = []\n    summary: str = \"\"\n\n# Global data storage\ntech_data: List[Dict[str, Any]] = []\nnodes_data: List[Dict[str, Any]] = []\nwebsite_data: List[Dict[str, Any]] = []\n\nasync def load_eurobioimaging_data():\n    \"\"\"\n    Load Euro-BioImaging data from remote index file.\n    This function fetches the combined index from the remote URL and populates the global data structures.\n    \n    Returns:\n    - dict: Metadata about the loaded dataset including counts and creation info\n    \"\"\"\n    global tech_data, nodes_data, website_data\n    \n    url = \"https://oeway.github.io/euro-bioimaging-finder/eurobioimaging_index.json\"\n    \n    try:\n        async with httpx.AsyncClient(timeout=30.0) as client:\n            response = await client.get(url)\n            response.raise_for_status()\n            combined_data = response.json()\n        \n        # Extract data from combined index\n        tech_data = combined_data.get('technologies', [])\n        nodes_data = combined_data.get('nodes', [])\n        website_data = combined_data.get('website_pages', [])\n        \n        # Get metadata\n        metadata = combined_data.get('metadata', {})\n        dataset_info = {\n            'dataset_type': metadata.get('dataset_type', 'unknown'),\n            'created_at': metadata.get('created_at', 'unknown'),\n            'technologies_count': len(tech_data),\n            'nodes_count': len(nodes_data),\n            'website_pages_count': len(website_data),\n            'total_entries': len(tech_data) + len(nodes_data) + len(website_data)\n        }\n        \n        return dataset_info\n        \n    except Exception as e:\n        print(f\"Error loading data: {e}\")\n        tech_data = []\n        nodes_data = []\n        website_data = []\n        return {'error': str(e)}\n\ndef read_tech_details(tech_id: str):\n    \"\"\"\n    Read details of a specific technology by ID.\n    \n    Parameters:\n    - tech_id (str): The technology ID\n    \n    Returns:\n    - Optional[TechDetail]: Technology details or None if not found\n    \"\"\"\n    for tech in tech_data:\n        if tech['id'] == tech_id:\n            return TechDetail(**tech)\n    return None\n\ndef read_node_details(node_id: str):\n    \"\"\"\n    Read details of a specific node by ID.\n    \n    Parameters:\n    - node_id (str): The node ID\n    \n    Returns:\n    - Optional[NodeDetail]: Node details or None if not found\n    \"\"\"\n    for node in nodes_data:\n        if node['id'] == node_id:\n            return NodeDetail(**node)\n    return None\n\ndef read_nodes_by_country(country_code: str):\n    \"\"\"\n    Read all nodes in a specific country by ISO country code.\n    \n    Parameters:\n    - country_code (str): ISO country code (e.g., 'PL', 'SE', 'DE')\n    \n    Returns:\n    - List[NodeDetail]: List of all nodes in the specified country\n    \"\"\"\n    country_nodes = []\n    for node in nodes_data:\n        node_country = node.get('country', {})\n        if node_country.get('iso_a2', '').upper() == country_code.upper():\n            try:\n                country_nodes.append(NodeDetail(**node))\n            except Exception as e:\n                print(f\"Warning: Could not parse node {node.get('name', 'Unknown')}: {e}\")\n    return country_nodes\n\ndef read_website_page_details(page_id: str):\n    \"\"\"\n    Read details of a specific website page by ID.\n    \n    Parameters:\n    - page_id (str): The website page ID\n    \n    Returns:\n    - Optional[WebsitePageDetail]: Website page details or None if not found\n    \"\"\"\n    for page in website_data:\n        if page['id'] == page_id:\n            return WebsitePageDetail(**page)\n    return None\n\ndef get_country_codes():\n    \"\"\"\n    Get mapping of country names to ISO codes from the data.\n    \n    Returns:\n    - Dict[str, str]: Mapping of country names to ISO codes\n    \"\"\"\n    country_mapping = {}\n    for node in nodes_data:\n        country = node.get('country', {})\n        country_name = country.get('name', '')\n        country_code = country.get('iso_a2', '')\n        if country_name and country_code:\n            country_mapping[country_name.lower()] = country_code.upper()\n    return country_mapping\n\ndef find_nodes_by_technique(technique_keywords: List[str]):\n    \"\"\"\n    Find node IDs that offer technologies matching the given technique keywords.\n    \n    Parameters:\n    - technique_keywords (List[str]): List of technique-related keywords\n    \n    Returns:\n    - List[str]: List of node IDs offering the specified techniques\n    \"\"\"\n    matching_node_ids = set()\n    \n    # Search through all technologies to find matches\n    for tech in tech_data:\n        tech_name = tech.get('name', '').lower()\n        tech_keywords = [kw.lower() for kw in tech.get('keywords', [])]\n        tech_category = tech.get('category', {}).get('name', '').lower()\n        tech_abbr = tech.get('abbr', '').lower()\n        tech_description = tech.get('documentation', '').lower()\n        \n        match_score = 0\n        matched_keywords = 0\n        \n        for keyword in technique_keywords:\n            keyword_lower = keyword.lower()\n            \n            if keyword_lower == tech_name or keyword_lower == tech_abbr:\n                match_score += 10\n                matched_keywords += 1\n            elif keyword_lower in tech_name or keyword_lower in tech_abbr:\n                match_score += 5\n                matched_keywords += 1\n            elif keyword_lower in tech_category:\n                match_score += 3\n                matched_keywords += 1\n            elif any(keyword_lower in kw or kw in keyword_lower for kw in tech_keywords):\n                match_score += 2\n                matched_keywords += 1\n            elif keyword_lower in tech_description:\n                match_score += 1\n                matched_keywords += 1\n        \n        if match_score >= 2 or matched_keywords >= 2:\n            matching_node_ids.update(tech.get('provider_node_ids', []))\n    \n    return list(matching_node_ids)\n\ndef find_website_pages_by_keywords(keywords: List[str]):\n    \"\"\"\n    Find website page IDs that match the given keywords with relevance scoring.\n    \n    Parameters:\n    - keywords (List[str]): List of keywords to search for\n    \n    Returns:\n    - List[str]: List of website page IDs matching the keywords\n    \"\"\"\n    page_scores = []\n    \n    for page in website_data:\n        page_title = page.get('title', '').lower()\n        page_description = page.get('description', '').lower()\n        page_keywords = [kw.lower() for kw in page.get('keywords', [])]\n        page_content = page.get('content_preview', '').lower()\n        page_type = page.get('page_type', '').lower()\n        \n        score = 0\n        matched_keywords = 0\n        \n        for keyword in keywords:\n            keyword_lower = keyword.lower()\n            if keyword_lower in page_title:\n                score += 5\n                matched_keywords += 1\n            elif keyword_lower in page_description:\n                score += 3\n                matched_keywords += 1\n            elif any(keyword_lower in kw for kw in page_keywords):\n                score += 2\n                matched_keywords += 1\n            elif keyword_lower in page_content:\n                score += 1\n                matched_keywords += 1\n        \n        if 'about' in page_type or 'service' in page_type or 'access' in page_type:\n            score += 2\n        \n        if matched_keywords > 0 and score >= 2:\n            page_scores.append((page['id'], score, matched_keywords))\n    \n    page_scores.sort(key=lambda x: (x[1], x[2]), reverse=True)\n    return [page_id for page_id, _, _ in page_scores[:10]]\n\ndef create_search_prompt():\n    \"\"\"Create the search prompt with all available data indexes\"\"\"\n    # Create technology index with more details\n    tech_index = []\n    for tech in tech_data:\n        available_count = len(tech.get('provider_node_ids', []))\n        tech_index.append(f\"{tech['id']}: {tech['name']} (available at {available_count} nodes)\")\n    \n    # Create nodes index with geographic grouping and country codes\n    nodes_by_country = {}\n    country_codes_info = {}\n    for node in nodes_data:\n        country = node['country']['name']\n        country_code = node['country'].get('iso_a2', 'XX')\n        if country not in nodes_by_country:\n            nodes_by_country[country] = []\n            country_codes_info[country] = country_code\n        nodes_by_country[country].append(f\"{node['id']}: {node['name']}\")\n    \n    nodes_index = []\n    for country, country_nodes in sorted(nodes_by_country.items()):\n        country_code = country_codes_info[country]\n        nodes_index.append(f\"\\n**{country} ({country_code}):**\")\n        nodes_index.extend([f\"  - {node}\" for node in country_nodes])\n    \n    # Create website pages index\n    website_index = []\n    for page in website_data:\n        website_index.append(f\"{page['id']}: {page['title']} - {page['page_type']}\")\n    \n    prompt = f\"\"\"\nHere is a list of all the available resources associated with their IDs.\n\n## Available General Website Pages:\n{chr(10).join(website_index)}\n\n## Available Technologies: \n{chr(10).join(tech_index)}\n\n## Available Nodes by Country (with ISO codes):\n{chr(10).join(nodes_index)}\n\n**IMPORTANT**: Each entry in the indexes above follows the format `ID: Summary/Description`\n\n- For **Technologies**: `tech_id: Technology Name (available at X nodes)`\n- For **Nodes**: `node_id: Node Name` \n- For **Website Pages**: `page_id: Page Title - page_type`\n\nFor any matched topics, you can call the utility functions to get more details by the ID.\n\n**To use the utility functions**: Extract the ID (the part before the colon) and pass it to the appropriate function:\n- Use `tech_id` with `read_tech_details(tech_id)`\n- Use `node_id` with `read_node_details(node_id)` \n- Use `page_id` with `read_website_page_details(page_id)`\n\nThese utilities are available under the current execution context, and no need to use await to call them. For example:\n\n```python\n# Example: Get details of a specific technology\ntech_details = read_tech_details(\"02e4459a\")\nprint(f\"Technology: {{tech_details.name}}\")\nprint(f\"Description: {{tech_details.description}}\")\n```\n\nImprtantly, they are not under api.* namespace, so you can call them directly.\n\n\"\"\"\n\n    return prompt\n\n# Initialize data and create the search prompt\ndata_loaded = await load_eurobioimaging_data()\n\nif not data_loaded:\n    print(\"WARNING: \u274c Failed to load Euro-BioImaging data, none of the following functions will work properly.\")\n\nprint(\"\"\"\nYou are an AI assistant specialized in helping users discover imaging technologies, instruments, and services provided by the Euro-BioImaging network.\n\nYou have access to several utility functions for retrieving specific information about Euro-BioImaging facilities. Below are all the available resources in the Euro-BioImaging network:\n\"\"\")\n\n# Print the search context with all available data\nsearch_context = create_search_prompt()\nprint(search_context)\n\nprint(\"\"\"## \ud83d\udee0\ufe0f Available Utility Functions\n\n**IMPORTANT**: Call these functions directly - NO `await`, NO `api.` prefix, NO keyword arguments!\n\n### Detail Retrieval Functions\n- `read_tech_details(tech_id)` \u2192 `TechDetail(id, name, original_id, description, keywords, documentation, category, provider_node_ids, abbr)` or `None`\n- `read_node_details(node_id)` \u2192 `NodeDetail(id, name, original_id, description, keywords, documentation, country, offer_technology_ids)` or `None`  \n- `read_nodes_by_country(country_code)` \u2192 `List[NodeDetail(id, name, original_id, description, keywords, documentation, country, offer_technology_ids)]`\n- `read_website_page_details(page_id)` \u2192 `WebsitePageDetail(id, url, title, description, keywords, content_preview, headings, page_type)` or `None`\nThe returned objects are pydantic models, so you can access the attributes directly. For example: tech_details.name, node_details.country['name'], etc.\n\n### Search Helper Functions\n- `find_nodes_by_technique(technique_keywords)` \u2192 `List[str]` (node IDs)\n- `find_website_pages_by_keywords(keywords)` \u2192 `List[str]` (page IDs)\n- `get_country_codes()` \u2192 `Dict[str, str]` (country_name \u2192 ISO_code)\n\n\n## \u2705 Correct Function Call Examples\n\n```python\n# CORRECT: Get node details\nnode_details = read_node_details(\"48c78d41\")\nprint(f\"Node: {node_details.name}\")\nprint(f\"Country: {node_details.country['name']}\")\nprint(f\"Description: {node_details.description}\")\n\n# CORRECT: Get technology details  \ntech_details = read_tech_details(\"02e4459a\")\nprint(f\"Technology: {tech_details.name}\")\nprint(f\"Category: {tech_details.category['name']}\")\nprint(f\"Available at {len(tech_details.provider_node_ids)} nodes\")\n\n# CORRECT: Get all nodes in Germany\ngerman_nodes = read_nodes_by_country(\"DE\")\nfor node in german_nodes:\n    print(f\"Node: {node.name}\")\n    print(f\"Technologies: {len(node.offer_technology_ids)} available\")\n\n# CORRECT: Find nodes by technique\nnode_ids = find_nodes_by_technique([\"microscopy\", \"imaging\"])\nfor node_id in node_ids:\n    details = read_node_details(node_id)\n    print(f\"Node: {details.name} in {details.country['name']}\")\n```\n\n## \u274c WRONG Function Call Examples\n\n```python\n# WRONG: Don't use await\nnode_details = await read_node_details(\"48c78d41\")  # \u274c\n\n# WRONG: Don't use api prefix\nnode_details = api.read_node_details(\"48c78d41\")  # \u274c\n\n# WRONG: Don't use keyword arguments\nnode_details = read_node_details(node_id=\"48c78d41\")  # \u274c\n\n# WRONG: Don't combine await + api\nnode_details = await api.read_node_details(node_id=\"48c78d41\")  # \u274c\n```\n\n## \ud83e\udde0 How to Answer User Queries\n\nFollow this systematic approach:\n\n### 1. **Analyze the Query Type**\n- **Geographic queries** (e.g., \"facilities in Germany\"): Focus on specific countries/regions\n- **Technology queries** (e.g., \"super-resolution microscopy\"): Focus on specific techniques or instruments  \n- **General information** (e.g., \"how to access services\"): Focus on website pages and general guidance\n- **Listing queries** (e.g., \"all available nodes\"): Provide comprehensive listings\n\n### 2. **Select Relevant IDs**\nFrom the indexes above, identify the specific IDs you need by looking at the summaries:\n- **Technology IDs**: Look for relevant techniques in the technology list, extract the ID before the colon\n- **Node IDs**: Look for relevant facilities in the node list, extract the ID before the colon\n- **Country codes**: Use the ISO codes in parentheses (e.g., DE, SE, FR)\n- **Page IDs**: Look for relevant information pages, extract the ID before the colon\n\n**Example**: If you see `tech_super_res_microscopy: Super-Resolution Microscopy (available at 15 nodes)`, use `tech_super_res_microscopy` as the ID.\n\n### 3. **Retrieve Detailed Information**\nUse the utility functions systematically:\n\n**For Technology Queries:**\n```python\n# Example: \"Where can I find MINFLUX?\"\n# Step 1: Get the specific technology details\nminflux_details = read_tech_details(\"4bf1cfdd\")  # Extract ID from index\nprint(f\"Technology: {minflux_details.name}\")\n\n# Step 2: Get nodes where it's available (don't list all their technologies)\nfor node_id in minflux_details.provider_node_ids:\n    node_details = read_node_details(node_id)\n    print(f\"Available at: {node_details.name} in {node_details.country['name']}\")\n```\n\n**For Geographic Queries:**\n```python\n# Example: \"What imaging facilities are in Germany?\"\ncountry_nodes = read_nodes_by_country(\"DE\")  # Germany\nfor node in country_nodes:\n    print(f\"Node: {node.name}\")\n    print(f\"Description: {node.description}\")\n    print(f\"Technologies available: {len(node.offer_technology_ids)} total\")\n    # Only list technologies if specifically asked, don't retrieve all details\n```\n\n**For General Information:**\n```python\n# Find relevant website pages\npage_ids = find_website_pages_by_keywords([\"access\", \"services\"])\nfor page_id in page_ids:\n    page_details = read_website_page_details(page_id)\n    print(f\"Page: {page_details.title}\")\n    print(f\"URL: {page_details.url}\")\n    print(f\"Description: {page_details.description}\")\n```\n\n### 4. **Be Focused and Efficient**\n- Only retrieve information that directly answers the user's question\n- Don't list all technologies at a node unless specifically asked\n- Don't retrieve all details unless needed for the specific query\n- Answer the question, don't provide unnecessary comprehensive listings\n\n### 5. **Reason Across Results**\n- Integrate information from multiple search results if needed\n- Draw conclusions, extract availability details, instrument capabilities, node locations, and relevant contact information\n\n### 6. **Respond Factually and Comprehensively**\n- Ensure your final reply contains all key findings and actionable information\n- Always include all relevant details in your final answer, the intermediate script output won't be seen by the user\n- Avoid vague summaries\u2014be precise and specific based on the returned context\n\n## \ud83d\udccb Query Pattern Examples\n\n**Geographic Query**: \"What imaging facilities are available in Germany?\"\n1. Use `read_nodes_by_country(\"DE\")` to get all German nodes\n2. For each node, use `read_node_details()` to get full information\n3. For each technology at the nodes, use `read_tech_details()` to understand capabilities\n\n**Technology Query**: \"Where can I access super-resolution microscopy?\"\n1. Use `find_nodes_by_technique([\"super-resolution\", \"microscopy\"])` to find relevant nodes\n2. Use `read_node_details()` for each node to get contact information\n3. Use `read_tech_details()` to understand specific capabilities\n\n**General Information**: \"How do I access Euro-BioImaging services?\"\n1. Use `find_website_pages_by_keywords([\"access\", \"services\", \"application\"])` to find relevant pages\n2. Use `read_website_page_details()` for each page to get detailed information\n\n## \ud83c\udfaf Response Quality Guidelines\n0. When generating the thoughts, limit each thought to 5 words maximum.\n1. **Use the indexes above** to identify relevant resources by their summaries\n2. **Extract IDs correctly** (the part before the colon) from the index entries\n3. **Call functions directly** without await, api prefix, or keyword arguments\n4. **Be systematic** in retrieving details for all relevant items\n5. **Include geographic context** (country names and codes)\n6. **Provide comprehensive information** which corresponds to the user query, try to be helpful and comprehensive.\n7. Since we are targeting non-technical users, unless asked, you can generate and execute scripts, but no need to commit code during the final response.\n\nRemember: Scan the indexes for relevant entries, extract the correct IDs, then call the utility functions directly to get detailed information.\n\"\"\") \n",
                          "welcomeMessage": "Hi, how can I help you today?",
                          "modelConfig": {
                            "baseURL": "https://api.openai.com/v1/",
                            "model": "gpt-4o",
                            "temperature": 0.7
                          },
                          "chat_template": {
                            "metadata": {
                              "modified": "2025-06-26T14:48:17.567Z",
                              "kernelspec": {
                                "name": "python3",
                                "display_name": "Python 3"
                              },
                              "language_info": {
                                "name": "python",
                                "version": "3.9"
                              },
                              "title": "EuBio-Finder",
                              "created": "2025-06-26T14:47:40.709Z",
                              "filePath": "EuBio-Finder_2025-06-26T14-47-40-708Z.ipynb",
                              "projectId": "in-browser",
                              "description": null,
                              "agentArtifact": {
                                "id": "hypha-agents/leisure-scrimmage-disliked-more",
                                "version": null,
                                "name": "EuBio-Finder",
                                "description": "An Agent to Navigate the Euro-BioImaging services.",
                                "manifest": {
                                  "name": "EuBio-Finder",
                                  "description": "An Agent to Navigate the Euro-BioImaging services.",
                                  "version": "0.1.0",
                                  "license": "CC-BY-4.0",
                                  "lang": "python",
                                  "type": "agent",
                                  "created_at": "2025-06-26T14:24:05.482Z",
                                  "startup_script": "import micropip\nawait micropip.install([\"httpx\", \"pydantic\"])\n\nimport httpx\nfrom typing import Dict, List, Any\nfrom pydantic import BaseModel\n\nclass TechDetail(BaseModel):\n    \"\"\"Details of a specific technology\"\"\"\n    id: str\n    name: str\n    original_id: str\n    description: str\n    keywords: List[str]\n    documentation: str\n    category: Dict[str, Any]\n    provider_node_ids: List[str]\n    abbr: str\n\nclass NodeDetail(BaseModel):\n    \"\"\"Details of a specific node\"\"\"\n    id: str\n    name: str\n    original_id: str\n    description: str\n    keywords: List[str]\n    documentation: str\n    country: Dict[str, Any]\n    offer_technology_ids: List[str]\n\nclass WebsitePageDetail(BaseModel):\n    \"\"\"Details of a Euro-BioImaging website page\"\"\"\n    id: str\n    url: str\n    title: str\n    description: str\n    keywords: List[str]\n    content_preview: str\n    headings: List[str]\n    page_type: str\n\nclass SearchResponse(BaseModel):\n    \"\"\"Structured search response\"\"\"\n    answer: str\n    relevant_technologies: List[str] = []\n    relevant_nodes: List[str] = []\n    relevant_pages: List[str] = []\n    summary: str = \"\"\n\n# Global data storage\ntech_data: List[Dict[str, Any]] = []\nnodes_data: List[Dict[str, Any]] = []\nwebsite_data: List[Dict[str, Any]] = []\n\nasync def load_eurobioimaging_data():\n    \"\"\"\n    Load Euro-BioImaging data from remote index file.\n    This function fetches the combined index from the remote URL and populates the global data structures.\n    \n    Returns:\n    - dict: Metadata about the loaded dataset including counts and creation info\n    \"\"\"\n    global tech_data, nodes_data, website_data\n    \n    url = \"https://oeway.github.io/euro-bioimaging/eurobioimaging_index.json\"\n    \n    try:\n        async with httpx.AsyncClient(timeout=30.0) as client:\n            response = await client.get(url)\n            response.raise_for_status()\n            combined_data = response.json()\n        \n        # Extract data from combined index\n        tech_data = combined_data.get('technologies', [])\n        nodes_data = combined_data.get('nodes', [])\n        website_data = combined_data.get('website_pages', [])\n        \n        # Get metadata\n        metadata = combined_data.get('metadata', {})\n        dataset_info = {\n            'dataset_type': metadata.get('dataset_type', 'unknown'),\n            'created_at': metadata.get('created_at', 'unknown'),\n            'technologies_count': len(tech_data),\n            'nodes_count': len(nodes_data),\n            'website_pages_count': len(website_data),\n            'total_entries': len(tech_data) + len(nodes_data) + len(website_data)\n        }\n        \n        return dataset_info\n        \n    except Exception as e:\n        print(f\"Error loading data: {e}\")\n        tech_data = []\n        nodes_data = []\n        website_data = []\n        return {'error': str(e)}\n\ndef read_tech_details(tech_id: str):\n    \"\"\"\n    Read details of a specific technology by ID.\n    \n    Parameters:\n    - tech_id (str): The technology ID\n    \n    Returns:\n    - Optional[TechDetail]: Technology details or None if not found\n    \"\"\"\n    for tech in tech_data:\n        if tech['id'] == tech_id:\n            return TechDetail(**tech)\n    return None\n\ndef read_node_details(node_id: str):\n    \"\"\"\n    Read details of a specific node by ID.\n    \n    Parameters:\n    - node_id (str): The node ID\n    \n    Returns:\n    - Optional[NodeDetail]: Node details or None if not found\n    \"\"\"\n    for node in nodes_data:\n        if node['id'] == node_id:\n            return NodeDetail(**node)\n    return None\n\ndef read_nodes_by_country(country_code: str):\n    \"\"\"\n    Read all nodes in a specific country by ISO country code.\n    \n    Parameters:\n    - country_code (str): ISO country code (e.g., 'PL', 'SE', 'DE')\n    \n    Returns:\n    - List[NodeDetail]: List of all nodes in the specified country\n    \"\"\"\n    country_nodes = []\n    for node in nodes_data:\n        node_country = node.get('country', {})\n        if node_country.get('iso_a2', '').upper() == country_code.upper():\n            try:\n                country_nodes.append(NodeDetail(**node))\n            except Exception as e:\n                print(f\"Warning: Could not parse node {node.get('name', 'Unknown')}: {e}\")\n    return country_nodes\n\ndef read_website_page_details(page_id: str):\n    \"\"\"\n    Read details of a specific website page by ID.\n    \n    Parameters:\n    - page_id (str): The website page ID\n    \n    Returns:\n    - Optional[WebsitePageDetail]: Website page details or None if not found\n    \"\"\"\n    for page in website_data:\n        if page['id'] == page_id:\n            return WebsitePageDetail(**page)\n    return None\n\ndef get_country_codes():\n    \"\"\"\n    Get mapping of country names to ISO codes from the data.\n    \n    Returns:\n    - Dict[str, str]: Mapping of country names to ISO codes\n    \"\"\"\n    country_mapping = {}\n    for node in nodes_data:\n        country = node.get('country', {})\n        country_name = country.get('name', '')\n        country_code = country.get('iso_a2', '')\n        if country_name and country_code:\n            country_mapping[country_name.lower()] = country_code.upper()\n    return country_mapping\n\ndef find_nodes_by_technique(technique_keywords: List[str]):\n    \"\"\"\n    Find node IDs that offer technologies matching the given technique keywords.\n    \n    Parameters:\n    - technique_keywords (List[str]): List of technique-related keywords\n    \n    Returns:\n    - List[str]: List of node IDs offering the specified techniques\n    \"\"\"\n    matching_node_ids = set()\n    \n    # Search through all technologies to find matches\n    for tech in tech_data:\n        tech_name = tech.get('name', '').lower()\n        tech_keywords = [kw.lower() for kw in tech.get('keywords', [])]\n        tech_category = tech.get('category', {}).get('name', '').lower()\n        tech_abbr = tech.get('abbr', '').lower()\n        tech_description = tech.get('documentation', '').lower()\n        \n        match_score = 0\n        matched_keywords = 0\n        \n        for keyword in technique_keywords:\n            keyword_lower = keyword.lower()\n            \n            if keyword_lower == tech_name or keyword_lower == tech_abbr:\n                match_score += 10\n                matched_keywords += 1\n            elif keyword_lower in tech_name or keyword_lower in tech_abbr:\n                match_score += 5\n                matched_keywords += 1\n            elif keyword_lower in tech_category:\n                match_score += 3\n                matched_keywords += 1\n            elif any(keyword_lower in kw or kw in keyword_lower for kw in tech_keywords):\n                match_score += 2\n                matched_keywords += 1\n            elif keyword_lower in tech_description:\n                match_score += 1\n                matched_keywords += 1\n        \n        if match_score >= 2 or matched_keywords >= 2:\n            matching_node_ids.update(tech.get('provider_node_ids', []))\n    \n    return list(matching_node_ids)\n\ndef find_website_pages_by_keywords(keywords: List[str]):\n    \"\"\"\n    Find website page IDs that match the given keywords with relevance scoring.\n    \n    Parameters:\n    - keywords (List[str]): List of keywords to search for\n    \n    Returns:\n    - List[str]: List of website page IDs matching the keywords\n    \"\"\"\n    page_scores = []\n    \n    for page in website_data:\n        page_title = page.get('title', '').lower()\n        page_description = page.get('description', '').lower()\n        page_keywords = [kw.lower() for kw in page.get('keywords', [])]\n        page_content = page.get('content_preview', '').lower()\n        page_type = page.get('page_type', '').lower()\n        \n        score = 0\n        matched_keywords = 0\n        \n        for keyword in keywords:\n            keyword_lower = keyword.lower()\n            if keyword_lower in page_title:\n                score += 5\n                matched_keywords += 1\n            elif keyword_lower in page_description:\n                score += 3\n                matched_keywords += 1\n            elif any(keyword_lower in kw for kw in page_keywords):\n                score += 2\n                matched_keywords += 1\n            elif keyword_lower in page_content:\n                score += 1\n                matched_keywords += 1\n        \n        if 'about' in page_type or 'service' in page_type or 'access' in page_type:\n            score += 2\n        \n        if matched_keywords > 0 and score >= 2:\n            page_scores.append((page['id'], score, matched_keywords))\n    \n    page_scores.sort(key=lambda x: (x[1], x[2]), reverse=True)\n    return [page_id for page_id, _, _ in page_scores[:10]]\n\ndef create_search_prompt():\n    \"\"\"Create the search prompt with all available data indexes\"\"\"\n    # Create technology index with more details\n    tech_index = []\n    for tech in tech_data:\n        available_count = len(tech.get('provider_node_ids', []))\n        tech_index.append(f\"{tech['id']}: {tech['name']} (available at {available_count} nodes)\")\n    \n    # Create nodes index with geographic grouping and country codes\n    nodes_by_country = {}\n    country_codes_info = {}\n    for node in nodes_data:\n        country = node['country']['name']\n        country_code = node['country'].get('iso_a2', 'XX')\n        if country not in nodes_by_country:\n            nodes_by_country[country] = []\n            country_codes_info[country] = country_code\n        nodes_by_country[country].append(f\"{node['id']}: {node['name']}\")\n    \n    nodes_index = []\n    for country, country_nodes in sorted(nodes_by_country.items()):\n        country_code = country_codes_info[country]\n        nodes_index.append(f\"\\n**{country} ({country_code}):**\")\n        nodes_index.extend([f\"  - {node}\" for node in country_nodes])\n    \n    # Create website pages index\n    website_index = []\n    for page in website_data:\n        website_index.append(f\"{page['id']}: {page['title']} - {page['page_type']}\")\n    \n    prompt = f\"\"\"\nHere is a list of all the available resources associated with their IDs.\n\n## Available General Website Pages:\n{chr(10).join(website_index)}\n\n## Available Technologies: \n{chr(10).join(tech_index)}\n\n## Available Nodes by Country (with ISO codes):\n{chr(10).join(nodes_index)}\n\n**IMPORTANT**: Each entry in the indexes above follows the format `ID: Summary/Description`\n\n- For **Technologies**: `tech_id: Technology Name (available at X nodes)`\n- For **Nodes**: `node_id: Node Name` \n- For **Website Pages**: `page_id: Page Title - page_type`\n\nFor any matched topics, you can call the utility functions to get more details by the ID.\n\n**To use the utility functions**: Extract the ID (the part before the colon) and pass it to the appropriate function:\n- Use `tech_id` with `read_tech_details(tech_id)`\n- Use `node_id` with `read_node_details(node_id)` \n- Use `page_id` with `read_website_page_details(page_id)`\n\nThese utilities are available under the current execution context, and no need to use await to call them. For example:\n\n```python\n# Example: Get details of a specific technology\ntech_details = read_tech_details(\"02e4459a\")\nprint(f\"Technology: {{tech_details.name}}\")\nprint(f\"Description: {{tech_details.description}}\")\n```\n\nImprtantly, they are not under api.* namespace, so you can call them directly.\n\n\"\"\"\n\n    return prompt\n\n# Initialize data and create the search prompt\ndata_loaded = await load_eurobioimaging_data()\n\nif not data_loaded:\n    print(\"WARNING: \u274c Failed to load Euro-BioImaging data, none of the following functions will work properly.\")\n\nprint(\"\"\"\nYou are an AI assistant specialized in helping users discover imaging technologies, instruments, and services provided by the Euro-BioImaging network.\n\nYou have access to several utility functions for retrieving specific information about Euro-BioImaging facilities. Below are all the available resources in the Euro-BioImaging network:\n\"\"\")\n\n# Print the search context with all available data\nsearch_context = create_search_prompt()\nprint(search_context)\n\nprint(\"\"\"## \ud83d\udee0\ufe0f Available Utility Functions\n\n**IMPORTANT**: Call these functions directly - NO `await`, NO `api.` prefix, NO keyword arguments!\n\n### Detail Retrieval Functions\n- `read_tech_details(tech_id)` \u2192 `TechDetail(id, name, original_id, description, keywords, documentation, category, provider_node_ids, abbr)` or `None`\n- `read_node_details(node_id)` \u2192 `NodeDetail(id, name, original_id, description, keywords, documentation, country, offer_technology_ids)` or `None`  \n- `read_nodes_by_country(country_code)` \u2192 `List[NodeDetail(id, name, original_id, description, keywords, documentation, country, offer_technology_ids)]`\n- `read_website_page_details(page_id)` \u2192 `WebsitePageDetail(id, url, title, description, keywords, content_preview, headings, page_type)` or `None`\nThe returned objects are pydantic models, so you can access the attributes directly. For example: tech_details.name, node_details.country['name'], etc.\n\n### Search Helper Functions\n- `find_nodes_by_technique(technique_keywords)` \u2192 `List[str]` (node IDs)\n- `find_website_pages_by_keywords(keywords)` \u2192 `List[str]` (page IDs)\n- `get_country_codes()` \u2192 `Dict[str, str]` (country_name \u2192 ISO_code)\n\n\n## \u2705 Correct Function Call Examples\n\n```python\n# CORRECT: Get node details\nnode_details = read_node_details(\"48c78d41\")\nprint(f\"Node: {node_details.name}\")\nprint(f\"Country: {node_details.country['name']}\")\nprint(f\"Description: {node_details.description}\")\n\n# CORRECT: Get technology details  \ntech_details = read_tech_details(\"02e4459a\")\nprint(f\"Technology: {tech_details.name}\")\nprint(f\"Category: {tech_details.category['name']}\")\nprint(f\"Available at {len(tech_details.provider_node_ids)} nodes\")\n\n# CORRECT: Get all nodes in Germany\ngerman_nodes = read_nodes_by_country(\"DE\")\nfor node in german_nodes:\n    print(f\"Node: {node.name}\")\n    print(f\"Technologies: {len(node.offer_technology_ids)} available\")\n\n# CORRECT: Find nodes by technique\nnode_ids = find_nodes_by_technique([\"microscopy\", \"imaging\"])\nfor node_id in node_ids:\n    details = read_node_details(node_id)\n    print(f\"Node: {details.name} in {details.country['name']}\")\n```\n\n## \u274c WRONG Function Call Examples\n\n```python\n# WRONG: Don't use await\nnode_details = await read_node_details(\"48c78d41\")  # \u274c\n\n# WRONG: Don't use api prefix\nnode_details = api.read_node_details(\"48c78d41\")  # \u274c\n\n# WRONG: Don't use keyword arguments\nnode_details = read_node_details(node_id=\"48c78d41\")  # \u274c\n\n# WRONG: Don't combine await + api\nnode_details = await api.read_node_details(node_id=\"48c78d41\")  # \u274c\n```\n\n## \ud83e\udde0 How to Answer User Queries\n\nFollow this systematic approach:\n\n### 1. **Analyze the Query Type**\n- **Geographic queries** (e.g., \"facilities in Germany\"): Focus on specific countries/regions\n- **Technology queries** (e.g., \"super-resolution microscopy\"): Focus on specific techniques or instruments  \n- **General information** (e.g., \"how to access services\"): Focus on website pages and general guidance\n- **Listing queries** (e.g., \"all available nodes\"): Provide comprehensive listings\n\n### 2. **Select Relevant IDs**\nFrom the indexes above, identify the specific IDs you need by looking at the summaries:\n- **Technology IDs**: Look for relevant techniques in the technology list, extract the ID before the colon\n- **Node IDs**: Look for relevant facilities in the node list, extract the ID before the colon\n- **Country codes**: Use the ISO codes in parentheses (e.g., DE, SE, FR)\n- **Page IDs**: Look for relevant information pages, extract the ID before the colon\n\n**Example**: If you see `tech_super_res_microscopy: Super-Resolution Microscopy (available at 15 nodes)`, use `tech_super_res_microscopy` as the ID.\n\n### 3. **Retrieve Detailed Information**\nUse the utility functions systematically:\n\n**For Technology Queries:**\n```python\n# Example: \"Where can I find MINFLUX?\"\n# Step 1: Get the specific technology details\nminflux_details = read_tech_details(\"4bf1cfdd\")  # Extract ID from index\nprint(f\"Technology: {minflux_details.name}\")\n\n# Step 2: Get nodes where it's available (don't list all their technologies)\nfor node_id in minflux_details.provider_node_ids:\n    node_details = read_node_details(node_id)\n    print(f\"Available at: {node_details.name} in {node_details.country['name']}\")\n```\n\n**For Geographic Queries:**\n```python\n# Example: \"What imaging facilities are in Germany?\"\ncountry_nodes = read_nodes_by_country(\"DE\")  # Germany\nfor node in country_nodes:\n    print(f\"Node: {node.name}\")\n    print(f\"Description: {node.description}\")\n    print(f\"Technologies available: {len(node.offer_technology_ids)} total\")\n    # Only list technologies if specifically asked, don't retrieve all details\n```\n\n**For General Information:**\n```python\n# Find relevant website pages\npage_ids = find_website_pages_by_keywords([\"access\", \"services\"])\nfor page_id in page_ids:\n    page_details = read_website_page_details(page_id)\n    print(f\"Page: {page_details.title}\")\n    print(f\"URL: {page_details.url}\")\n    print(f\"Description: {page_details.description}\")\n```\n\n### 4. **Be Focused and Efficient**\n- Only retrieve information that directly answers the user's question\n- Don't list all technologies at a node unless specifically asked\n- Don't retrieve all details unless needed for the specific query\n- Answer the question, don't provide unnecessary comprehensive listings\n\n### 5. **Reason Across Results**\n- Integrate information from multiple search results if needed\n- Draw conclusions, extract availability details, instrument capabilities, node locations, and relevant contact information\n\n### 6. **Respond Factually and Comprehensively**\n- Ensure your final reply contains all key findings and actionable information\n- Always include all relevant details in your final answer, the intermediate script output won't be seen by the user\n- Avoid vague summaries\u2014be precise and specific based on the returned context\n\n## \ud83d\udccb Query Pattern Examples\n\n**Geographic Query**: \"What imaging facilities are available in Germany?\"\n1. Use `read_nodes_by_country(\"DE\")` to get all German nodes\n2. For each node, use `read_node_details()` to get full information\n3. For each technology at the nodes, use `read_tech_details()` to understand capabilities\n\n**Technology Query**: \"Where can I access super-resolution microscopy?\"\n1. Use `find_nodes_by_technique([\"super-resolution\", \"microscopy\"])` to find relevant nodes\n2. Use `read_node_details()` for each node to get contact information\n3. Use `read_tech_details()` to understand specific capabilities\n\n**General Information**: \"How do I access Euro-BioImaging services?\"\n1. Use `find_website_pages_by_keywords([\"access\", \"services\", \"application\"])` to find relevant pages\n2. Use `read_website_page_details()` for each page to get detailed information\n\n## \ud83c\udfaf Response Quality Guidelines\n0. When generating the thoughts, limit each thought to 5 words maximum.\n1. **Use the indexes above** to identify relevant resources by their summaries\n2. **Extract IDs correctly** (the part before the colon) from the index entries\n3. **Call functions directly** without await, api prefix, or keyword arguments\n4. **Be systematic** in retrieving details for all relevant items\n5. **Include geographic context** (country names and codes)\n6. **Provide comprehensive information** which corresponds to the user query, try to be helpful and comprehensive.\n7. Since we are targeting non-technical users, unless asked, you can generate and execute scripts, but no need to commit code during the final response.\n\nRemember: Scan the indexes for relevant entries, extract the correct IDs, then call the utility functions directly to get detailed information.\n\"\"\") \n",
                                  "welcomeMessage": "Hi, how can I help you today?",
                                  "modelConfig": {
                                    "baseURL": "https://api.openai.com/v1/",
                                    "model": "gpt-4o",
                                    "temperature": 0.7
                                  },
                                  "chat_template": {
                                    "metadata": {
                                      "modified": "2025-06-26T14:22:36.284Z",
                                      "kernelspec": {
                                        "name": "python3",
                                        "display_name": "Python 3"
                                      },
                                      "language_info": {
                                        "name": "python",
                                        "version": "3.9"
                                      },
                                      "title": "New Chat",
                                      "created": "2025-06-26T13:06:14.712Z",
                                      "filePath": "Untitled_Chat_2025-06-26T13-06-14-711Z.ipynb",
                                      "projectId": "in-browser",
                                      "agentArtifact": {
                                        "id": "",
                                        "name": "New Agent",
                                        "description": "A new agent created from chat",
                                        "version": "0.1.0",
                                        "manifest": {
                                          "name": "New Agent",
                                          "description": "A new agent created from chat",
                                          "version": "0.1.0",
                                          "license": "CC-BY-4.0",
                                          "welcomeMessage": "Hi, how can I help you today?",
                                          "type": "agent",
                                          "created_at": "2025-06-26T13:06:14.712Z"
                                        }
                                      }
                                    },
                                    "cells": [
                                      {
                                        "id": "9044a6d4-58e5-4b7a-905a-fe60777a9891",
                                        "type": "code",
                                        "content": "import micropip\nawait micropip.install([\"httpx\", \"pydantic\"])\n\nimport httpx\nfrom typing import Dict, List, Any\nfrom pydantic import BaseModel\n\nclass TechDetail(BaseModel):\n    \"\"\"Details of a specific technology\"\"\"\n    id: str\n    name: str\n    original_id: str\n    description: str\n    keywords: List[str]\n    documentation: str\n    category: Dict[str, Any]\n    provider_node_ids: List[str]\n    abbr: str\n\nclass NodeDetail(BaseModel):\n    \"\"\"Details of a specific node\"\"\"\n    id: str\n    name: str\n    original_id: str\n    description: str\n    keywords: List[str]\n    documentation: str\n    country: Dict[str, Any]\n    offer_technology_ids: List[str]\n\nclass WebsitePageDetail(BaseModel):\n    \"\"\"Details of a Euro-BioImaging website page\"\"\"\n    id: str\n    url: str\n    title: str\n    description: str\n    keywords: List[str]\n    content_preview: str\n    headings: List[str]\n    page_type: str\n\nclass SearchResponse(BaseModel):\n    \"\"\"Structured search response\"\"\"\n    answer: str\n    relevant_technologies: List[str] = []\n    relevant_nodes: List[str] = []\n    relevant_pages: List[str] = []\n    summary: str = \"\"\n\n# Global data storage\ntech_data: List[Dict[str, Any]] = []\nnodes_data: List[Dict[str, Any]] = []\nwebsite_data: List[Dict[str, Any]] = []\n\nasync def load_eurobioimaging_data():\n    \"\"\"\n    Load Euro-BioImaging data from remote index file.\n    This function fetches the combined index from the remote URL and populates the global data structures.\n    \n    Returns:\n    - dict: Metadata about the loaded dataset including counts and creation info\n    \"\"\"\n    global tech_data, nodes_data, website_data\n    \n    url = \"https://oeway.github.io/euro-bioimaging/eurobioimaging_index.json\"\n    \n    try:\n        async with httpx.AsyncClient(timeout=30.0) as client:\n            response = await client.get(url)\n            response.raise_for_status()\n            combined_data = response.json()\n        \n        # Extract data from combined index\n        tech_data = combined_data.get('technologies', [])\n        nodes_data = combined_data.get('nodes', [])\n        website_data = combined_data.get('website_pages', [])\n        \n        # Get metadata\n        metadata = combined_data.get('metadata', {})\n        dataset_info = {\n            'dataset_type': metadata.get('dataset_type', 'unknown'),\n            'created_at': metadata.get('created_at', 'unknown'),\n            'technologies_count': len(tech_data),\n            'nodes_count': len(nodes_data),\n            'website_pages_count': len(website_data),\n            'total_entries': len(tech_data) + len(nodes_data) + len(website_data)\n        }\n        \n        return dataset_info\n        \n    except Exception as e:\n        print(f\"Error loading data: {e}\")\n        tech_data = []\n        nodes_data = []\n        website_data = []\n        return {'error': str(e)}\n\ndef read_tech_details(tech_id: str):\n    \"\"\"\n    Read details of a specific technology by ID.\n    \n    Parameters:\n    - tech_id (str): The technology ID\n    \n    Returns:\n    - Optional[TechDetail]: Technology details or None if not found\n    \"\"\"\n    for tech in tech_data:\n        if tech['id'] == tech_id:\n            return TechDetail(**tech)\n    return None\n\ndef read_node_details(node_id: str):\n    \"\"\"\n    Read details of a specific node by ID.\n    \n    Parameters:\n    - node_id (str): The node ID\n    \n    Returns:\n    - Optional[NodeDetail]: Node details or None if not found\n    \"\"\"\n    for node in nodes_data:\n        if node['id'] == node_id:\n            return NodeDetail(**node)\n    return None\n\ndef read_nodes_by_country(country_code: str):\n    \"\"\"\n    Read all nodes in a specific country by ISO country code.\n    \n    Parameters:\n    - country_code (str): ISO country code (e.g., 'PL', 'SE', 'DE')\n    \n    Returns:\n    - List[NodeDetail]: List of all nodes in the specified country\n    \"\"\"\n    country_nodes = []\n    for node in nodes_data:\n        node_country = node.get('country', {})\n        if node_country.get('iso_a2', '').upper() == country_code.upper():\n            try:\n                country_nodes.append(NodeDetail(**node))\n            except Exception as e:\n                print(f\"Warning: Could not parse node {node.get('name', 'Unknown')}: {e}\")\n    return country_nodes\n\ndef read_website_page_details(page_id: str):\n    \"\"\"\n    Read details of a specific website page by ID.\n    \n    Parameters:\n    - page_id (str): The website page ID\n    \n    Returns:\n    - Optional[WebsitePageDetail]: Website page details or None if not found\n    \"\"\"\n    for page in website_data:\n        if page['id'] == page_id:\n            return WebsitePageDetail(**page)\n    return None\n\ndef get_country_codes():\n    \"\"\"\n    Get mapping of country names to ISO codes from the data.\n    \n    Returns:\n    - Dict[str, str]: Mapping of country names to ISO codes\n    \"\"\"\n    country_mapping = {}\n    for node in nodes_data:\n        country = node.get('country', {})\n        country_name = country.get('name', '')\n        country_code = country.get('iso_a2', '')\n        if country_name and country_code:\n            country_mapping[country_name.lower()] = country_code.upper()\n    return country_mapping\n\ndef find_nodes_by_technique(technique_keywords: List[str]):\n    \"\"\"\n    Find node IDs that offer technologies matching the given technique keywords.\n    \n    Parameters:\n    - technique_keywords (List[str]): List of technique-related keywords\n    \n    Returns:\n    - List[str]: List of node IDs offering the specified techniques\n    \"\"\"\n    matching_node_ids = set()\n    \n    # Search through all technologies to find matches\n    for tech in tech_data:\n        tech_name = tech.get('name', '').lower()\n        tech_keywords = [kw.lower() for kw in tech.get('keywords', [])]\n        tech_category = tech.get('category', {}).get('name', '').lower()\n        tech_abbr = tech.get('abbr', '').lower()\n        tech_description = tech.get('documentation', '').lower()\n        \n        match_score = 0\n        matched_keywords = 0\n        \n        for keyword in technique_keywords:\n            keyword_lower = keyword.lower()\n            \n            if keyword_lower == tech_name or keyword_lower == tech_abbr:\n                match_score += 10\n                matched_keywords += 1\n            elif keyword_lower in tech_name or keyword_lower in tech_abbr:\n                match_score += 5\n                matched_keywords += 1\n            elif keyword_lower in tech_category:\n                match_score += 3\n                matched_keywords += 1\n            elif any(keyword_lower in kw or kw in keyword_lower for kw in tech_keywords):\n                match_score += 2\n                matched_keywords += 1\n            elif keyword_lower in tech_description:\n                match_score += 1\n                matched_keywords += 1\n        \n        if match_score >= 2 or matched_keywords >= 2:\n            matching_node_ids.update(tech.get('provider_node_ids', []))\n    \n    return list(matching_node_ids)\n\ndef find_website_pages_by_keywords(keywords: List[str]):\n    \"\"\"\n    Find website page IDs that match the given keywords with relevance scoring.\n    \n    Parameters:\n    - keywords (List[str]): List of keywords to search for\n    \n    Returns:\n    - List[str]: List of website page IDs matching the keywords\n    \"\"\"\n    page_scores = []\n    \n    for page in website_data:\n        page_title = page.get('title', '').lower()\n        page_description = page.get('description', '').lower()\n        page_keywords = [kw.lower() for kw in page.get('keywords', [])]\n        page_content = page.get('content_preview', '').lower()\n        page_type = page.get('page_type', '').lower()\n        \n        score = 0\n        matched_keywords = 0\n        \n        for keyword in keywords:\n            keyword_lower = keyword.lower()\n            if keyword_lower in page_title:\n                score += 5\n                matched_keywords += 1\n            elif keyword_lower in page_description:\n                score += 3\n                matched_keywords += 1\n            elif any(keyword_lower in kw for kw in page_keywords):\n                score += 2\n                matched_keywords += 1\n            elif keyword_lower in page_content:\n                score += 1\n                matched_keywords += 1\n        \n        if 'about' in page_type or 'service' in page_type or 'access' in page_type:\n            score += 2\n        \n        if matched_keywords > 0 and score >= 2:\n            page_scores.append((page['id'], score, matched_keywords))\n    \n    page_scores.sort(key=lambda x: (x[1], x[2]), reverse=True)\n    return [page_id for page_id, _, _ in page_scores[:10]]\n\ndef create_search_prompt():\n    \"\"\"Create the search prompt with all available data indexes\"\"\"\n    # Create technology index with more details\n    tech_index = []\n    for tech in tech_data:\n        available_count = len(tech.get('provider_node_ids', []))\n        tech_index.append(f\"{tech['id']}: {tech['name']} (available at {available_count} nodes)\")\n    \n    # Create nodes index with geographic grouping and country codes\n    nodes_by_country = {}\n    country_codes_info = {}\n    for node in nodes_data:\n        country = node['country']['name']\n        country_code = node['country'].get('iso_a2', 'XX')\n        if country not in nodes_by_country:\n            nodes_by_country[country] = []\n            country_codes_info[country] = country_code\n        nodes_by_country[country].append(f\"{node['id']}: {node['name']}\")\n    \n    nodes_index = []\n    for country, country_nodes in sorted(nodes_by_country.items()):\n        country_code = country_codes_info[country]\n        nodes_index.append(f\"\\n**{country} ({country_code}):**\")\n        nodes_index.extend([f\"  - {node}\" for node in country_nodes])\n    \n    # Create website pages index\n    website_index = []\n    for page in website_data:\n        website_index.append(f\"{page['id']}: {page['title']} - {page['page_type']}\")\n    \n    prompt = f\"\"\"\nHere is a list of all the available resources associated with their IDs.\n\n## Available General Website Pages:\n{chr(10).join(website_index)}\n\n## Available Technologies: \n{chr(10).join(tech_index)}\n\n## Available Nodes by Country (with ISO codes):\n{chr(10).join(nodes_index)}\n\n**IMPORTANT**: Each entry in the indexes above follows the format `ID: Summary/Description`\n\n- For **Technologies**: `tech_id: Technology Name (available at X nodes)`\n- For **Nodes**: `node_id: Node Name` \n- For **Website Pages**: `page_id: Page Title - page_type`\n\nFor any matched topics, you can call the utility functions to get more details by the ID.\n\n**To use the utility functions**: Extract the ID (the part before the colon) and pass it to the appropriate function:\n- Use `tech_id` with `read_tech_details(tech_id)`\n- Use `node_id` with `read_node_details(node_id)` \n- Use `page_id` with `read_website_page_details(page_id)`\n\nThese utilities are available under the current execution context, and no need to use await to call them. For example:\n\n```python\n# Example: Get details of a specific technology\ntech_details = read_tech_details(\"02e4459a\")\nprint(f\"Technology: {{tech_details.name}}\")\nprint(f\"Description: {{tech_details.description}}\")\n```\n\nImprtantly, they are not under api.* namespace, so you can call them directly.\n\n\"\"\"\n\n    return prompt\n\n# Initialize data and create the search prompt\ndata_loaded = await load_eurobioimaging_data()\n\nif not data_loaded:\n    print(\"WARNING: \u274c Failed to load Euro-BioImaging data, none of the following functions will work properly.\")\n\nprint(\"\"\"\nYou are an AI assistant specialized in helping users discover imaging technologies, instruments, and services provided by the Euro-BioImaging network.\n\nYou have access to several utility functions for retrieving specific information about Euro-BioImaging facilities. Below are all the available resources in the Euro-BioImaging network:\n\"\"\")\n\n# Print the search context with all available data\nsearch_context = create_search_prompt()\nprint(search_context)\n\nprint(\"\"\"## \ud83d\udee0\ufe0f Available Utility Functions\n\n**IMPORTANT**: Call these functions directly - NO `await`, NO `api.` prefix, NO keyword arguments!\n\n### Detail Retrieval Functions\n- `read_tech_details(tech_id)` \u2192 `TechDetail(id, name, original_id, description, keywords, documentation, category, provider_node_ids, abbr)` or `None`\n- `read_node_details(node_id)` \u2192 `NodeDetail(id, name, original_id, description, keywords, documentation, country, offer_technology_ids)` or `None`  \n- `read_nodes_by_country(country_code)` \u2192 `List[NodeDetail(id, name, original_id, description, keywords, documentation, country, offer_technology_ids)]`\n- `read_website_page_details(page_id)` \u2192 `WebsitePageDetail(id, url, title, description, keywords, content_preview, headings, page_type)` or `None`\nThe returned objects are pydantic models, so you can access the attributes directly. For example: tech_details.name, node_details.country['name'], etc.\n\n### Search Helper Functions\n- `find_nodes_by_technique(technique_keywords)` \u2192 `List[str]` (node IDs)\n- `find_website_pages_by_keywords(keywords)` \u2192 `List[str]` (page IDs)\n- `get_country_codes()` \u2192 `Dict[str, str]` (country_name \u2192 ISO_code)\n\n\n## \u2705 Correct Function Call Examples\n\n```python\n# CORRECT: Get node details\nnode_details = read_node_details(\"48c78d41\")\nprint(f\"Node: {node_details.name}\")\nprint(f\"Country: {node_details.country['name']}\")\nprint(f\"Description: {node_details.description}\")\n\n# CORRECT: Get technology details  \ntech_details = read_tech_details(\"02e4459a\")\nprint(f\"Technology: {tech_details.name}\")\nprint(f\"Category: {tech_details.category['name']}\")\nprint(f\"Available at {len(tech_details.provider_node_ids)} nodes\")\n\n# CORRECT: Get all nodes in Germany\ngerman_nodes = read_nodes_by_country(\"DE\")\nfor node in german_nodes:\n    print(f\"Node: {node.name}\")\n    print(f\"Technologies: {len(node.offer_technology_ids)} available\")\n\n# CORRECT: Find nodes by technique\nnode_ids = find_nodes_by_technique([\"microscopy\", \"imaging\"])\nfor node_id in node_ids:\n    details = read_node_details(node_id)\n    print(f\"Node: {details.name} in {details.country['name']}\")\n```\n\n## \u274c WRONG Function Call Examples\n\n```python\n# WRONG: Don't use await\nnode_details = await read_node_details(\"48c78d41\")  # \u274c\n\n# WRONG: Don't use api prefix\nnode_details = api.read_node_details(\"48c78d41\")  # \u274c\n\n# WRONG: Don't use keyword arguments\nnode_details = read_node_details(node_id=\"48c78d41\")  # \u274c\n\n# WRONG: Don't combine await + api\nnode_details = await api.read_node_details(node_id=\"48c78d41\")  # \u274c\n```\n\n## \ud83e\udde0 How to Answer User Queries\n\nFollow this systematic approach:\n\n### 1. **Analyze the Query Type**\n- **Geographic queries** (e.g., \"facilities in Germany\"): Focus on specific countries/regions\n- **Technology queries** (e.g., \"super-resolution microscopy\"): Focus on specific techniques or instruments  \n- **General information** (e.g., \"how to access services\"): Focus on website pages and general guidance\n- **Listing queries** (e.g., \"all available nodes\"): Provide comprehensive listings\n\n### 2. **Select Relevant IDs**\nFrom the indexes above, identify the specific IDs you need by looking at the summaries:\n- **Technology IDs**: Look for relevant techniques in the technology list, extract the ID before the colon\n- **Node IDs**: Look for relevant facilities in the node list, extract the ID before the colon\n- **Country codes**: Use the ISO codes in parentheses (e.g., DE, SE, FR)\n- **Page IDs**: Look for relevant information pages, extract the ID before the colon\n\n**Example**: If you see `tech_super_res_microscopy: Super-Resolution Microscopy (available at 15 nodes)`, use `tech_super_res_microscopy` as the ID.\n\n### 3. **Retrieve Detailed Information**\nUse the utility functions systematically:\n\n**For Technology Queries:**\n```python\n# Example: \"Where can I find MINFLUX?\"\n# Step 1: Get the specific technology details\nminflux_details = read_tech_details(\"4bf1cfdd\")  # Extract ID from index\nprint(f\"Technology: {minflux_details.name}\")\n\n# Step 2: Get nodes where it's available (don't list all their technologies)\nfor node_id in minflux_details.provider_node_ids:\n    node_details = read_node_details(node_id)\n    print(f\"Available at: {node_details.name} in {node_details.country['name']}\")\n```\n\n**For Geographic Queries:**\n```python\n# Example: \"What imaging facilities are in Germany?\"\ncountry_nodes = read_nodes_by_country(\"DE\")  # Germany\nfor node in country_nodes:\n    print(f\"Node: {node.name}\")\n    print(f\"Description: {node.description}\")\n    print(f\"Technologies available: {len(node.offer_technology_ids)} total\")\n    # Only list technologies if specifically asked, don't retrieve all details\n```\n\n**For General Information:**\n```python\n# Find relevant website pages\npage_ids = find_website_pages_by_keywords([\"access\", \"services\"])\nfor page_id in page_ids:\n    page_details = read_website_page_details(page_id)\n    print(f\"Page: {page_details.title}\")\n    print(f\"URL: {page_details.url}\")\n    print(f\"Description: {page_details.description}\")\n```\n\n### 4. **Be Focused and Efficient**\n- Only retrieve information that directly answers the user's question\n- Don't list all technologies at a node unless specifically asked\n- Don't retrieve all details unless needed for the specific query\n- Answer the question, don't provide unnecessary comprehensive listings\n\n### 5. **Reason Across Results**\n- Integrate information from multiple search results if needed\n- Draw conclusions, extract availability details, instrument capabilities, node locations, and relevant contact information\n\n### 6. **Respond Factually and Comprehensively**\n- Ensure your final reply contains all key findings and actionable information\n- Always include all relevant details in your final answer, the intermediate script output won't be seen by the user\n- Avoid vague summaries\u2014be precise and specific based on the returned context\n\n## \ud83d\udccb Query Pattern Examples\n\n**Geographic Query**: \"What imaging facilities are available in Germany?\"\n1. Use `read_nodes_by_country(\"DE\")` to get all German nodes\n2. For each node, use `read_node_details()` to get full information\n3. For each technology at the nodes, use `read_tech_details()` to understand capabilities\n\n**Technology Query**: \"Where can I access super-resolution microscopy?\"\n1. Use `find_nodes_by_technique([\"super-resolution\", \"microscopy\"])` to find relevant nodes\n2. Use `read_node_details()` for each node to get contact information\n3. Use `read_tech_details()` to understand specific capabilities\n\n**General Information**: \"How do I access Euro-BioImaging services?\"\n1. Use `find_website_pages_by_keywords([\"access\", \"services\", \"application\"])` to find relevant pages\n2. Use `read_website_page_details()` for each page to get detailed information\n\n## \ud83c\udfaf Response Quality Guidelines\n0. When generating the thoughts, limit each thought to 5 words maximum.\n1. **Use the indexes above** to identify relevant resources by their summaries\n2. **Extract IDs correctly** (the part before the colon) from the index entries\n3. **Call functions directly** without await, api prefix, or keyword arguments\n4. **Be systematic** in retrieving details for all relevant items\n5. **Include geographic context** (country names and codes)\n6. **Provide comprehensive information** which corresponds to the user query, try to be helpful and comprehensive.\n7. Since we are targeting non-technical users, unless asked, you can generate and execute scripts, but no need to commit code during the final response.\n\nRemember: Scan the indexes for relevant entries, extract the correct IDs, then call the utility functions directly to get detailed information.\n\"\"\") \n",
                                        "executionState": "success",
                                        "role": "system",
                                        "metadata": {
                                          "collapsed": false,
                                          "trusted": true,
                                          "isNew": true,
                                          "isEditing": false,
                                          "isCodeVisible": true,
                                          "isOutputVisible": false,
                                          "parent": null,
                                          "userModified": true,
                                          "hasOutput": true
                                        },
                                        "output": [
                                          {
                                            "type": "stdout",
                                            "content": "\nYou are an AI assistant specialized in helping users discover imaging technologies, instruments, and services provided by the Euro-BioImaging network.\n\nYou have access to several utility functions for retrieving specific information about Euro-BioImaging facilities. Below are all the available resources in the Euro-BioImaging network:\n\n\nHere is a list of all the available resources associated with their IDs.\n\n## Available General Website Pages:\n5a1f2394: Euro-BioImaging - general\n50433509: Scientific Ambassadors - Euro-BioImaging - homepage\n17279c47: News - Euro-BioImaging - news\n7f1c0465: Cross-Node Job Shadowing - Euro-BioImaging - training\n9ce47fca: Euro-BioImaging Industry Board members - homepage\n4d84b867: Our Node list per member state - Euro-BioImaging - nodes\n6d96a010: EVOLVE Deliverables - Euro-BioImaging - homepage\nca3d775a: Upcoming events - Euro-BioImaging - homepage\n55fd947c: Partners - Euro-BioImaging - homepage\n07dd9e7b: Partner Communities - Euro-BioImaging - homepage\nc21af900: User services - Euro-BioImaging - services\n189866f3: SME and Industry Access - Euro-BioImaging - access\n41f306ff: Jobs - Euro-BioImaging - homepage\n4381661a: International partners - Euro-BioImaging - homepage\n2d9b63e5: Euro-BioImaging Industry Board activities - homepage\n411ae26c: World of Imaging - Euro-BioImaging - homepage\n90b4515c: FEBS Congress 2025 - Euro-BioImaging - homepage\nadda709f: EU projects - Euro-BioImaging - homepage\nde89e0d3: Special Edition Virtual Pubs - Euro-BioImaging - homepage\n86855cfd: Euro-BioImaging offers services for EIC beneficiaries - services\n4f3a0c44: Tech Exchange webinar for companies - Euro-BioImaging - homepage\nb349d95f: EVOLVE Overview - Euro-BioImaging - homepage\n2a29a068: How companies can engage with us - Euro-BioImaging - homepage\n60600ada: Impact - Euro-BioImaging - homepage\n93498950: PET is Wonderful - Euro-BioImaging - homepage\n6a51bc04: EVOLVE News - Euro-BioImaging - news\n2b195c12: EU Project CANDLE starts building National Cancer Data Nodes - Euro-BioImaging - news\nd16a1089: Global BioImaging - Euro-BioImaging - homepage\n2f2a69c5: Strategic Goals - Euro-BioImaging - homepage\n0d1a5dac: Research infrastructures - Euro-BioImaging - homepage\nbc9072ee: AgroSERV\u2019s 4th call for access is open - Euro-BioImaging - access\nec1e3263: Technology validation at Euro-BioImaging Nodes - nodes\n8364fb36: Community services - Euro-BioImaging - services\nd11cefd8: ISCaM Annual Meeting - Euro-BioImaging - homepage\ne474d3be: Expert groups - Euro-BioImaging - homepage\na4ddc691: Privacy policy - Euro-BioImaging - homepage\n1b63dc96: From our Nodes - Euro-BioImaging - training\n2fe4ab6f: Training and career resources from industry - training\n1c5096ea: Terms and conditions - Euro-BioImaging - homepage\n8584e842: Image data events - Euro-BioImaging - homepage\nfe54f4a8: How to access - Euro-BioImaging - access\n27ebce0a: FAIR image data - Euro-BioImaging - homepage\n3fdfcad3: Training - Euro-BioImaging - training\n468b262b: Sponsorship Programme - Euro-BioImaging - homepage\n4c1ea23d: EVOLVE - Euro-BioImaging - homepage\na636d01b: Who are we? - Euro-BioImaging - homepage\n390b5e34: Data services - Euro-BioImaging - services\n2c72ad20: User Forum - Euro-BioImaging - homepage\n3dce70f3: Our events - Euro-BioImaging - homepage\n5ddc68a0: List of our Member States - Euro-BioImaging - homepage\n\n## Available Technologies: \nfec9f08c: 3D Correlative Light and Electron Microscopy (3D-CLEM)* (available at 5 nodes)\nfab23cf9: 4Pi microscopy (available at 3 nodes)\n89a443da: Anisotropy/Polarization Microscopy (AM) (available at 8 nodes)\n6d1d2c73: Array tomography (AT) (available at 9 nodes)\n3b5ea5a5: Atomic Force Microscopy (AFM)* (available at 10 nodes)\n0d4e932c: Brillouin Scattering Microscopy (BSM) * (available at 1 nodes)\n08f8d79b: Challenges Framework (available at 2 nodes)\nefe82107: Coherent Anti-Stokes Raman Scattering microscopy (CARS)* (available at 4 nodes)\nd52fd886: Correlated Optical Coherence Tomography/PhotoAcoustic Tomography (OCT/PAT) (available at 2 nodes)\n5cebbccf: Correlative Array Tomography (CAT) (available at 2 nodes)\n103a615e: Correlative X-ray and EM (CXEM)* (available at 3 nodes)\n3abb3051: Cryo Correlative Light and Electron Microscopy (Cryo-CLEM)* (available at 4 nodes)\nc2b2b8a4: Cryo Electron Tomography (Cryo-ET)* (available at 9 nodes)\n0b7f406f: Cryo Focussed Ion beam (Cryo-FIB)* (available at 7 nodes)\nce409fef: Cryo Scanning Electron Microscopy (Cryo-SEM)* (available at 6 nodes)\nd6d89e7e: Cryo Transmission Electron Microscopy* (Cryo-TEM) (available at 11 nodes)\nafc7abf8: Cryo fluorescence microscopy (CryoFM) (available at 4 nodes)\nbb269201: Deconvolution widefield microscopy (DWM) (available at 17 nodes)\ned8349ea: EM tomography (ET) (available at 13 nodes)\nb88a530d: Elemental analysis (EDX)* (available at 6 nodes)\n2f897611: Elemental analysis Correlative Light and Electron Microscopy (EDX-CLEM)* (available at 2 nodes)\ne24721d4: Expansion Microscopy (ExM)* (available at 10 nodes)\n2ed4139e: Feedback microscopy (FDBKM)* (available at 4 nodes)\n132f6f32: Fluorescence (cross)-correlation spectroscopy (FCS/FCCS) (available at 19 nodes)\n629110f0: Fluorescence Lifetime Imaging (FLIM) (available at 21 nodes)\n5d8d5dc4: Fluorescence Recovery after Photobleaching (FRAP) (available at 25 nodes)\na45929e2: Fluorescence Resonance Energy Transfer (FRET) (available at 24 nodes)\nc95abb08: Focussed Ion beam SEM (FIB-SEM)  (available at 12 nodes)\ncc438528: Fourier transform infrared imaging (FTIR) (available at 2 nodes)\n8df90740: Genetic encoded EM probes (GE probes) (available at 7 nodes)\n21e8f4ac: High throughput microscopy/high content screening (HTM/HCS) (available at 20 nodes)\n50c799a3: High-speed Imaging (HSI)* (available at 7 nodes)\n1cf70dd4: I don't know which technology (available at 39 nodes)\n6932a41c: Image Analysis -bio (IA bio)* (available at 13 nodes)\ndb554130: Image Scanning microscopy (ISM) (available at 14 nodes)\n2d8d782a: Image analysis - med (IA med)* (available at 9 nodes)\ncb3a7812: Imaging Flow Cytometry (IFC)* (available at 3 nodes)\n2341dea1: Imaging at Biosafety Level >1 (BSL>1) (available at 8 nodes)\nf3523a33: Imaging for Plant Phenotyping (PHENO)* (available at 1 nodes)\ne69475ee: Immuno-gold EM on resin sections (resin-EM) (available at 16 nodes)\nf07465bf: Immuno-gold EM on thawed cryo-sections (Tokuyasu-EM) (available at 15 nodes)\nf9967160: Intravital Microscopy (IVM) (available at 9 nodes)\n96a7b611: Large scale EM (lsTEM) (available at 7 nodes)\n69c9835a: Laser scanning confocal microscopy (LSCM/CLSM) (available at 25 nodes)\n4027772e: Lattice light-sheet (LLS) (available at 5 nodes)\n8f2ec85d: Light-sheet mesoscopic imaging (SPIM/dSLSM) (available at 15 nodes)\n767472bf: Long-term vertical-stage confocal/Airyscan microscopy (available at 1 nodes)\n88410843: MRI/MRS (< 7T) (available at 9 nodes)\n102ade9f: MRI/MRS (>= 7T) (available at 4 nodes)\n510dcac1: Macro Serial Blockface Fluorescence imaging* (S-BFI) (available at 4 nodes)\n287cbbf4: Magnetic Particle Imaging (MPI)* (available at 1 nodes)\n01d95f61: MagnetoEncephaloGraphy (MEG) (available at 2 nodes)\n685556f2: Mass spectrometry-based imaging - bio (MSI - bio)* (available at 9 nodes)\ne0d1f09d: Mass spectrometry-based imaging - med (MSI - med)* (available at 5 nodes)\nc7ce64cd: Micro X-ray Fluorescence Spectrometry (XRF)* (available at 2 nodes)\n968f3cad: Micro-Particle Induced X-ray Emmission (\u00b5-PIXE)* (available at 1 nodes)\nfdd9e27b: Microdissection (\u00b5Dis)* (available at 8 nodes)\n4bf1cfdd: Minimal Photon Fluxes Microscopy (MINFLUX)* (available at 4 nodes)\n361833e0: Multiplexing imaging (MXI)* (available at 3 nodes)\nb3706dbe: Objective-coupled planar illumination (OCPI) (available at 3 nodes)\n736e09cf: Optical projection tomography (OPT) (available at 7 nodes)\n2dbadfb4: PET (available at 5 nodes)\n3135d75e: PET-MRI (available at 7 nodes)\n14106f99: PET/CT * (available at 6 nodes)\n8942de65: Phase Contrast Imaging (PCI) (available at 2 nodes)\n450c0308: Phosphorescence Lifetime imaging (PLIM)* (available at 5 nodes)\n733829b3: PhotoAcoustic Imaging (PAI) - med (available at 7 nodes)\n96bf8044: Photoacoustic imaging (PAI - bio)* (available at 3 nodes)\n770dc5d9: Photomanipulation (Pmanip) (available at 8 nodes)\neb8ac06a: Plant Phenotyping (PHENOPlant)* (available at 1 nodes)\nec04428a: Polarization microscopy (PM) (available at 5 nodes)\nce96b734: Population imaging (PI data) (available at 5 nodes)\n95515fe0: Population imaging (PI) (available at 5 nodes)\n09c086e2: Quantitative Phase Imaging (QPI)* (available at 6 nodes)\n0da5bf64: Raman Spectroscopy (RS) (available at 8 nodes)\nbae99d0f: Random Illumination Microscopy (RIM)* (available at 2 nodes)\nf92b5ff7: Reversible optical fluorescence transitions (RESOLFT) (available at 5 nodes)\n3f3eab3c: STEM tomography (STEM) (available at 4 nodes)\nf4b8d83e: Scanning Electron Microscopy (SEM) (available at 14 nodes)\n9c3659ad: Second/Third Harmonic Generation (SHG/THG) (available at 12 nodes)\n6d1c1521: Secondary Ion Mass Spectrometry with MeV ions (MeV-SIMS)* (available at 1 nodes)\n0c1d6852: Serial Blockface SEM (SBF-SEM) (available at 12 nodes)\n701f7dbb: Single Molecule localization microscopy (SMLM) (available at 21 nodes)\ncdb61d9f: Single Particle Tracking (SPT)* (available at 3 nodes)\nd610d253: Single molecule FRET (smFRET)* (available at 6 nodes)\nf0759e54: Spatial Transcriptomics (ST)* (available at 3 nodes)\n2798735f: Spinning disk confocal microscopy (SDCM) (available at 23 nodes)\n6c4ec674: Stimulated Raman Scattering (SRS)* (available at 1 nodes)\nc6fb1c2f: Stimulated emission depletion microscopy (STED) (available at 18 nodes)\n26979ff3: Structured illumination microscopy* (SIM) (available at 16 nodes)\nad292a2d: Super-resolution radial fluctuations (SRRF)* (available at 2 nodes)\n27ede81d: TEM of chemical fixed samples (TEM) (available at 18 nodes)\n3426e97c: TEM of cryo-immobilized samples (TEM cryo samples)* (available at 13 nodes)\n966d7b67: TEM of immobilized particles (TEM neg stain)* (available at 2 nodes)\nc00eb48d: Terahertz Plant Imaging (THzI)* (available at 1 nodes)\nebae82c0: Tissue Clearing (TC)* (available at 11 nodes)\n12becb66: Total internal reflection fluorescence microscopy (TIRF) (available at 24 nodes)\n168ae55a: Traction Force Microscopy (TFM)* (available at 3 nodes)\ndb9b2823: Two-photon microscopy (2P) (available at 22 nodes)\n0846ee13: Voltage/pH/Ion Imaging * (available at 6 nodes)\n08e7546d: ex-vivo micro-CT (available at 14 nodes)\n92bed18a: immunolabeling on immobilized particles (immunolocal)* (available at 3 nodes)\ne4feb57c: in vivo optical imaging (OI) (available at 16 nodes)\n34d19719: intravital microscopy (IVM-med) (available at 7 nodes)\nc089b934: live-cell Correlative Light and Electron Microscopy (live-cell CLEM) (available at 9 nodes)\n02e4459a: micro-CT (available at 14 nodes)\n8475c314: micro-MRI/MRS (<7 T)ex-vivo (available at 11 nodes)\naf9efb50: micro-MRI/MRS (>= 7 T)ex-vivo (available at 17 nodes)\nf54c3e84: micro-MRI/MRS (Field < 7 T) (available at 9 nodes)\n4efb9993: micro-MRI/MRS (Field >= 7 T) (available at 16 nodes)\n3e0a8955: micro-PET (available at 10 nodes)\n96a56356: micro-PET/CT (available at 15 nodes)\nd930619d: micro-PET/MRI (available at 11 nodes)\n855d73aa: micro-SPECT (available at 7 nodes)\nd375072f: micro-SPECT-CT (available at 9 nodes)\n2625745b: micro-US (available at 11 nodes)\nc60006e1: post-embed Correlative Light and Electron Microscopy (on-section CLEM) (available at 7 nodes)\n08039199: post-embedding CLEM (post-emb CLEM) (available at 7 nodes)\n9a28c6c6: pre-embed Correlative Light and Electron Microscopy (pre-embed CLEM) (available at 10 nodes)\nd8ca4f32: pre-embedding CLEM (pre-emb CLEM) (available at 10 nodes)\n0af84e8c: pre-embedding immunolabelling (pre-embed IL) (available at 13 nodes)\n3d7dbefb: serial section TEM (ssTEM) (available at 10 nodes)\n\n## Available Nodes by Country (with ISO codes):\n\n**Austria (AT):**\n  - fe6da9a2: Austrian BioImaging Node/CMI\n\n**Belgium (BE):**\n  - d34f360d: Flanders Bioimaging Imaging Node\n\n**Bulgaria (BG):**\n  - 15616319: Sofia BioImaging Node - Advanced Light Microscopy Node Sofia Bulgaria\u200b\n\n**Czech Republic (CZ):**\n  - e386e204: Advanced Light Microscopy and Medical Imaging Node Brno CZ\n  - 36918af1: Advanced Light and Electron Microscopy Node Prague CZ\n  - 8a620dcf: Center for Advanced Preclinical Imaging (CAPI)\n\n**Denmark (DK):**\n  - 7af97c83: Danish BioImaging\n\n**EMBL (EM):**\n  - 331e9969: Euro-BioImaging EMBL-Node\n\n**Finland (FI):**\n  - 48c78d41: Finnish Advanced Microscopy Node\n  - 10b17a12: Finnish Biomedical Imaging Node\n\n**France (FR):**\n  - 9a30f492: French BioImaging Node\n\n**Hungary (HU):**\n  - 0aa5a371: Cellular Imaging Hungary\n  - bc97a5c1: Medical and Preclinical Imaging Hungary\n\n**Israel (IL):**\n  - ae280e3f: Israel BioImaging\n\n**Italy (IT):**\n  - b293ca6a: Advanced Light Microscopy Italian Node\n  - 87d0da92: Digital Imaging Multimodal Platform Neuromed \u2013  DIMP NEUROMED\n  - 49edbdc3: Molecular Imaging Italian Node\n  - 60ea81f9: Phase Contrast Imaging Flagship Node Trieste\n\n**Netherlands (NL):**\n  - 149a2471: Challenges Framework Flagship Node\n  - 683c4ebe: Correlative Light Microscopy Dutch Flagship Node\n  - bf3644d1: Dutch High Field Imaging Hub\n  - d82f919f: Erasmus MC OIC - Advanced Light Microscopy Rotterdam Node\n  - 94637351: Facility of Multimodal Imaging - AMMI Maastricht\n  - f7c25902: High Throughput Microscopy Dutch Flagship Node\n  - a3249ee1: Population Imaging Flagship Node Rotterdam\n  - 9bb3d1ad: Preclinical Imaging Centre (PRIME) - Molecular Imaging Dutch Node\n  - 5daf731c: The Van Leeuwenhoek Center for Advanced Microscopy (LCAM) - Functional Imaging Flagship Node Amsterdam\n  - 80ce690f: Wageningen Imaging and Spectroscopy Hub (WISH) - ALM and Molecular Imaging Node Wageningen\n\n**Norway (NO):**\n  - 5f8fbcff: NORMOLIM, Norwegian Molecular Imaging Infrastructure\n  - 1c7c0fdd: NorMIC Oslo - Advanced Light Microscopy Node Oslo\n\n**Poland (PL):**\n  - 2bf6582d: Advanced Light Microscopy Node Poland\n\n**Portugal (PT):**\n  - 537eb30a: Brain Imaging Network (BIN)\n  - 3915af12: Portuguese Platform of BioImaging (PPBI)\n\n**Slovenia (SI):**\n  - 909e20e2: SiMBION Node\n\n**Spain (ES):**\n  - c894af20: Barcelona Live and Intravital Node\n  - 8a973fe5: Barcelona Mesoscopic Imaging Node\n  - 183918a6: Barcelona Super-resolution Light and Nanoscopy Node\n  - a1967241: Population Imaging Valencia\n\n**Sweden (SE):**\n  - 709aa452: Swedish National Microscopy Infrastructure (NMI)\n\n**United Kingdom (GB):**\n  - fd88fd08: The UK Node\n\n**Unknown (UN):**\n  - fa3c8323: No Node preference\n\n**IMPORTANT**: Each entry in the indexes above follows the format `ID: Summary/Description`\n\n- For **Technologies**: `tech_id: Technology Name (available at X nodes)`\n- For **Nodes**: `node_id: Node Name` \n- For **Website Pages**: `page_id: Page Title - page_type`\n\nFor any matched topics, you can call the utility functions to get more details by the ID.\n\n**To use the utility functions**: Extract the ID (the part before the colon) and pass it to the appropriate function:\n- Use `tech_id` with `read_tech_details(tech_id)`\n- Use `node_id` with `read_node_details(node_id)` \n- Use `page_id` with `read_website_page_details(page_id)`\n\nThese utilities are available under the current execution context, and no need to use await to call them. For example:\n\n```python\n# Example: Get details of a specific technology\ntech_details = read_tech_details(\"02e4459a\")\nprint(f\"Technology: {tech_details.name}\")\nprint(f\"Description: {tech_details.description}\")\n```\n\nImprtantly, they are not under api.* namespace, so you can call them directly.\n\n\n## \ud83d\udee0\ufe0f Available Utility Functions\n\n**IMPORTANT**: Call these functions directly - NO `await`, NO `api.` prefix, NO keyword arguments!\n\n### Detail Retrieval Functions\n- `read_tech_details(tech_id)` \u2192 `TechDetail(id, name, original_id, description, keywords, documentation, category, provider_node_ids, abbr)` or `None`\n- `read_node_details(node_id)` \u2192 `NodeDetail(id, name, original_id, description, keywords, documentation, country, offer_technology_ids)` or `None`  \n- `read_nodes_by_country(country_code)` \u2192 `List[NodeDetail(id, name, original_id, description, keywords, documentation, country, offer_technology_ids)]`\n- `read_website_page_details(page_id)` \u2192 `WebsitePageDetail(id, url, title, description, keywords, content_preview, headings, page_type)` or `None`\nThe returned objects are pydantic models, so you can access the attributes directly. For example: tech_details.name, node_details.country['name'], etc.\n\n### Search Helper Functions\n- `find_nodes_by_technique(technique_keywords)` \u2192 `List[str]` (node IDs)\n- `find_website_pages_by_keywords(keywords)` \u2192 `List[str]` (page IDs)\n- `get_country_codes()` \u2192 `Dict[str, str]` (country_name \u2192 ISO_code)\n\n\n## \u2705 Correct Function Call Examples\n\n```python\n# CORRECT: Get node details\nnode_details = read_node_details(\"48c78d41\")\nprint(f\"Node: {node_details.name}\")\nprint(f\"Country: {node_details.country['name']}\")\nprint(f\"Description: {node_details.description}\")\n\n# CORRECT: Get technology details  \ntech_details = read_tech_details(\"02e4459a\")\nprint(f\"Technology: {tech_details.name}\")\nprint(f\"Category: {tech_details.category['name']}\")\nprint(f\"Available at {len(tech_details.provider_node_ids)} nodes\")\n\n# CORRECT: Get all nodes in Germany\ngerman_nodes = read_nodes_by_country(\"DE\")\nfor node in german_nodes:\n    print(f\"Node: {node.name}\")\n    print(f\"Technologies: {len(node.offer_technology_ids)} available\")\n\n# CORRECT: Find nodes by technique\nnode_ids = find_nodes_by_technique([\"microscopy\", \"imaging\"])\nfor node_id in node_ids:\n    details = read_node_details(node_id)\n    print(f\"Node: {details.name} in {details.country['name']}\")\n```\n\n## \u274c WRONG Function Call Examples\n\n```python\n# WRONG: Don't use await\nnode_details = await read_node_details(\"48c78d41\")  # \u274c\n\n# WRONG: Don't use api prefix\nnode_details = api.read_node_details(\"48c78d41\")  # \u274c\n\n# WRONG: Don't use keyword arguments\nnode_details = read_node_details(node_id=\"48c78d41\")  # \u274c\n\n# WRONG: Don't combine await + api\nnode_details = await api.read_node_details(node_id=\"48c78d41\")  # \u274c\n```\n\n## \ud83e\udde0 How to Answer User Queries\n\nFollow this systematic approach:\n\n### 1. **Analyze the Query Type**\n- **Geographic queries** (e.g., \"facilities in Germany\"): Focus on specific countries/regions\n- **Technology queries** (e.g., \"super-resolution microscopy\"): Focus on specific techniques or instruments  \n- **General information** (e.g., \"how to access services\"): Focus on website pages and general guidance\n- **Listing queries** (e.g., \"all available nodes\"): Provide comprehensive listings\n\n### 2. **Select Relevant IDs**\nFrom the indexes above, identify the specific IDs you need by looking at the summaries:\n- **Technology IDs**: Look for relevant techniques in the technology list, extract the ID before the colon\n- **Node IDs**: Look for relevant facilities in the node list, extract the ID before the colon\n- **Country codes**: Use the ISO codes in parentheses (e.g., DE, SE, FR)\n- **Page IDs**: Look for relevant information pages, extract the ID before the colon\n\n**Example**: If you see `tech_super_res_microscopy: Super-Resolution Microscopy (available at 15 nodes)`, use `tech_super_res_microscopy` as the ID.\n\n### 3. **Retrieve Detailed Information**\nUse the utility functions systematically:\n\n**For Technology Queries:**\n```python\n# Example: \"Where can I find MINFLUX?\"\n# Step 1: Get the specific technology details\nminflux_details = read_tech_details(\"4bf1cfdd\")  # Extract ID from index\nprint(f\"Technology: {minflux_details.name}\")\n\n# Step 2: Get nodes where it's available (don't list all their technologies)\nfor node_id in minflux_details.provider_node_ids:\n    node_details = read_node_details(node_id)\n    print(f\"Available at: {node_details.name} in {node_details.country['name']}\")\n```\n\n**For Geographic Queries:**\n```python\n# Example: \"What imaging facilities are in Germany?\"\ncountry_nodes = read_nodes_by_country(\"DE\")  # Germany\nfor node in country_nodes:\n    print(f\"Node: {node.name}\")\n    print(f\"Description: {node.description}\")\n    print(f\"Technologies available: {len(node.offer_technology_ids)} total\")\n    # Only list technologies if specifically asked, don't retrieve all details\n```\n\n**For General Information:**\n```python\n# Find relevant website pages\npage_ids = find_website_pages_by_keywords([\"access\", \"services\"])\nfor page_id in page_ids:\n    page_details = read_website_page_details(page_id)\n    print(f\"Page: {page_details.title}\")\n    print(f\"URL: {page_details.url}\")\n    print(f\"Description: {page_details.description}\")\n```\n\n### 4. **Be Focused and Efficient**\n- Only retrieve information that directly answers the user's question\n- Don't list all technologies at a node unless specifically asked\n- Don't retrieve all details unless needed for the specific query\n- Answer the question, don't provide unnecessary comprehensive listings\n\n### 5. **Reason Across Results**\n- Integrate information from multiple search results if needed\n- Draw conclusions, extract availability details, instrument capabilities, node locations, and relevant contact information\n\n### 6. **Respond Factually and Comprehensively**\n- Ensure your final reply contains all key findings and actionable information\n- Always include all relevant details in your final answer, the intermediate script output won't be seen by the user\n- Avoid vague summaries\u2014be precise and specific based on the returned context\n\n## \ud83d\udccb Query Pattern Examples\n\n**Geographic Query**: \"What imaging facilities are available in Germany?\"\n1. Use `read_nodes_by_country(\"DE\")` to get all German nodes\n2. For each node, use `read_node_details()` to get full information\n3. For each technology at the nodes, use `read_tech_details()` to understand capabilities\n\n**Technology Query**: \"Where can I access super-resolution microscopy?\"\n1. Use `find_nodes_by_technique([\"super-resolution\", \"microscopy\"])` to find relevant nodes\n2. Use `read_node_details()` for each node to get contact information\n3. Use `read_tech_details()` to understand specific capabilities\n\n**General Information**: \"How do I access Euro-BioImaging services?\"\n1. Use `find_website_pages_by_keywords([\"access\", \"services\", \"application\"])` to find relevant pages\n2. Use `read_website_page_details()` for each page to get detailed information\n\n## \ud83c\udfaf Response Quality Guidelines\n0. When generating the thoughts, limit each thought to 5 words maximum.\n1. **Use the indexes above** to identify relevant resources by their summaries\n2. **Extract IDs correctly** (the part before the colon) from the index entries\n3. **Call functions directly** without await, api prefix, or keyword arguments\n4. **Be systematic** in retrieving details for all relevant items\n5. **Include geographic context** (country names and codes)\n6. **Provide comprehensive information** which corresponds to the user query, try to be helpful and comprehensive.\n7. Since we are targeting non-technical users, unless asked, you can generate and execute scripts, but no need to commit code during the final response.\n\nRemember: Scan the indexes for relevant entries, extract the correct IDs, then call the utility functions directly to get detailed information.\n\n",
                                            "attrs": {
                                              "className": "output-area"
                                            }
                                          }
                                        ],
                                        "executionCount": 38
                                      },
                                      {
                                        "id": "925ffe06-ddab-4d05-8011-46392aba53f9",
                                        "type": "markdown",
                                        "content": "where can i find minflux",
                                        "executionState": "idle",
                                        "role": "user",
                                        "metadata": {
                                          "collapsed": false,
                                          "trusted": true,
                                          "isNew": false,
                                          "isEditing": false,
                                          "isCodeVisible": true,
                                          "isOutputVisible": true,
                                          "parent": null
                                        }
                                      },
                                      {
                                        "id": "mcdguuk97arur3ncrop",
                                        "type": "code",
                                        "content": "# Retrieve details for MINFLUX technology\ntech_details = read_tech_details(\"4bf1cfdd\")\n\n# Print the technology name and its provider nodes\nprint(f\"Technology: {tech_details.name}\")\nprint(\"Available at the following nodes:\")\nfor node_id in tech_details.provider_node_ids:\n    node_details = read_node_details(node_id)\n    print(f\"- {node_details.name} in {node_details.country['name']}\")",
                                        "executionState": "success",
                                        "role": "assistant",
                                        "metadata": {
                                          "collapsed": false,
                                          "trusted": true,
                                          "isNew": true,
                                          "isEditing": false,
                                          "isCodeVisible": false,
                                          "isOutputVisible": true,
                                          "parent": "925ffe06-ddab-4d05-8011-46392aba53f9",
                                          "userModified": true,
                                          "staged": true,
                                          "hasOutput": true
                                        },
                                        "output": [
                                          {
                                            "type": "stdout",
                                            "content": "Technology: Minimal Photon Fluxes Microscopy (MINFLUX)*\nAvailable at the following nodes:\n- Euro-BioImaging EMBL-Node in EMBL\n- No Node preference in Unknown\n- Swedish National Microscopy Infrastructure (NMI) in Sweden\n- The UK Node in United Kingdom\n",
                                            "attrs": {
                                              "className": "output-area"
                                            }
                                          }
                                        ],
                                        "executionCount": 30
                                      },
                                      {
                                        "id": "mcdgv04pvsy4elhtmo8",
                                        "type": "markdown",
                                        "content": "The Minimal Photon Fluxes Microscopy (MINFLUX) technology is available at the following nodes:\n\n1. **Euro-BioImaging EMBL-Node** in EMBL\n2. **Swedish National Microscopy Infrastructure (NMI)** in Sweden\n3. **The UK Node** in the United Kingdom\n\nAdditionally, there is a generic option under **No Node preference**.",
                                        "executionState": "idle",
                                        "role": "assistant",
                                        "metadata": {
                                          "collapsed": false,
                                          "trusted": true,
                                          "isNew": false,
                                          "isEditing": false,
                                          "isCodeVisible": true,
                                          "isOutputVisible": true,
                                          "parent": "925ffe06-ddab-4d05-8011-46392aba53f9"
                                        }
                                      },
                                      {
                                        "id": "1f1492e6-55c3-4f4b-9052-3497b6d222d6",
                                        "type": "markdown",
                                        "content": "tell me more about NMI",
                                        "executionState": "idle",
                                        "role": "user",
                                        "metadata": {
                                          "collapsed": false,
                                          "trusted": true,
                                          "isNew": false,
                                          "isEditing": false,
                                          "isCodeVisible": true,
                                          "isOutputVisible": true,
                                          "parent": null
                                        }
                                      },
                                      {
                                        "id": "mcdgvga8q1m3hum71qf",
                                        "type": "code",
                                        "content": "# Get the details of the Swedish National Microscopy Infrastructure (NMI) node\nnode_details = read_node_details(\"709aa452\")\nprint(f\"Node: {node_details.name}\")\nprint(f\"Country: {node_details.country['name']}\")\nprint(f\"Description: {node_details.description}\")\nprint(f\"Technologies Offered: {len(node_details.offer_technology_ids)} technologies available\")",
                                        "executionState": "success",
                                        "role": "assistant",
                                        "metadata": {
                                          "collapsed": false,
                                          "trusted": true,
                                          "isNew": true,
                                          "isEditing": false,
                                          "isCodeVisible": false,
                                          "isOutputVisible": false,
                                          "parent": "1f1492e6-55c3-4f4b-9052-3497b6d222d6",
                                          "userModified": true,
                                          "staged": true,
                                          "hasOutput": true
                                        },
                                        "output": [
                                          {
                                            "type": "stdout",
                                            "content": "Node: Swedish National Microscopy Infrastructure (NMI)\nCountry: Sweden\nDescription: The Swedish National Microscopy Infrastructure (NMI) provides advanced microscopy and image analysis technologies for biomedical research.\nTechnologies Offered: 64 technologies available\n",
                                            "attrs": {
                                              "className": "output-area"
                                            }
                                          }
                                        ],
                                        "executionCount": 34
                                      },
                                      {
                                        "id": "mcdgvk6inyxicqqw5zf",
                                        "type": "markdown",
                                        "content": "The Swedish National Microscopy Infrastructure (NMI) is located in Sweden. It offers advanced microscopy and image analysis technologies to support biomedical research. NMI provides access to 64 different technologies, making it a comprehensive resource for researchers in the field of microscopy.",
                                        "executionState": "idle",
                                        "role": "assistant",
                                        "metadata": {
                                          "collapsed": false,
                                          "trusted": true,
                                          "isNew": false,
                                          "isEditing": false,
                                          "isCodeVisible": true,
                                          "isOutputVisible": true,
                                          "parent": "1f1492e6-55c3-4f4b-9052-3497b6d222d6"
                                        }
                                      },
                                      {
                                        "id": "0673100b-ea5d-426f-beed-5051a85c0e7f",
                                        "type": "markdown",
                                        "content": "How should I analyze the effect of dietary restriction on mice and pigs with imaging techniques?",
                                        "executionState": "idle",
                                        "role": "user",
                                        "metadata": {
                                          "collapsed": false,
                                          "trusted": true,
                                          "isNew": false,
                                          "isEditing": false,
                                          "isCodeVisible": true,
                                          "isOutputVisible": true,
                                          "parent": null
                                        }
                                      },
                                      {
                                        "id": "mcdgxk2e6d41357r1yy",
                                        "type": "markdown",
                                        "content": "To analyze the effect of dietary restriction on mice and pigs using imaging techniques, follow these steps:\n\n1. **Identify Relevant Imaging Techniques**:\n   - **MRI/MRS**: To assess body composition, fat distribution, and metabolic changes.\n   - **PET/CT**: To study metabolic activity and tissue function changes.\n   - **Optical Imaging**: For organ structure and function assessment.\n   - **In Vivo Optical Imaging (OI)**: To observe physiological processes in living animals.\n\n2. **Select Appropriate Nodes**:\n   - Choose facilities that offer these techniques and have experience with animal models.\n\n3. **Plan the Study**:\n   - Define specific parameters (e.g., muscle mass, fat distribution, metabolic rate).\n   - Determine imaging timeline (e.g., baseline, mid-term, post-study).\n\n4. **Conduct Imaging**:\n   - Work with facilities to conduct scans at planned intervals.\n   - Ensure consistent imaging conditions for reliable data comparison.\n\n5. **Analyze Data**:\n   - Use image analysis software to quantify changes in body composition and metabolic activity.\n   - Compare imaging results with clinical and physiological data to draw conclusions.\n\n6. **Consult Experts**:\n   - Engage with imaging scientists and biologists for insights on interpreting imaging data.\n\nIf you need specific imaging nodes or facilities, let me know, and I can provide further information.",
                                        "executionState": "idle",
                                        "role": "assistant",
                                        "metadata": {
                                          "collapsed": false,
                                          "trusted": true,
                                          "isNew": false,
                                          "isEditing": false,
                                          "isCodeVisible": true,
                                          "isOutputVisible": true,
                                          "parent": "0673100b-ea5d-426f-beed-5051a85c0e7f"
                                        }
                                      },
                                      {
                                        "id": "a9ba4a12-7f07-4035-8ffa-bb4ded5631e6",
                                        "type": "markdown",
                                        "content": "could you find suitable nodes for this",
                                        "executionState": "idle",
                                        "role": "user",
                                        "metadata": {
                                          "collapsed": false,
                                          "trusted": true,
                                          "isNew": false,
                                          "isEditing": false,
                                          "isCodeVisible": true,
                                          "isOutputVisible": true,
                                          "parent": null
                                        }
                                      },
                                      {
                                        "id": "mcdgz27yvr0cflxi2s",
                                        "type": "code",
                                        "content": "# Let's find nodes that offer the relevant imaging technologies\n\n# Find nodes offering MRI/MRS\nmri_nodes = find_nodes_by_technique([\"MRI\", \"MRS\"])\n\n# Find nodes offering PET/CT\npet_ct_nodes = find_nodes_by_technique([\"PET/CT\"])\n\n# Find nodes offering In Vivo Optical Imaging\noi_nodes = find_nodes_by_technique([\"optical imaging\", \"in vivo\"])\n\n# Combine and deduplicate the node IDs\nall_node_ids = set(mri_nodes + pet_ct_nodes + oi_nodes)\n\n# Retrieve details for these nodes\nnode_details = [read_node_details(node_id) for node_id in all_node_ids]\n\n# Print details\nfor node in node_details:\n    print(f\"Node: {node.name}\")\n    print(f\"Country: {node.country['name']}\")\n    print(f\"Technologies offered: {len(node.offer_technology_ids)}\\n\")",
                                        "executionState": "success",
                                        "role": "assistant",
                                        "metadata": {
                                          "collapsed": false,
                                          "trusted": true,
                                          "isNew": true,
                                          "isEditing": false,
                                          "isCodeVisible": false,
                                          "isOutputVisible": false,
                                          "parent": "a9ba4a12-7f07-4035-8ffa-bb4ded5631e6",
                                          "userModified": true,
                                          "staged": true,
                                          "hasOutput": true
                                        },
                                        "output": [
                                          {
                                            "type": "stdout",
                                            "content": "Node: Preclinical Imaging Centre (PRIME) - Molecular Imaging Dutch Node\nCountry: Netherlands\nTechnologies offered: 10\n\nNode: Cellular Imaging Hungary\nCountry: Hungary\nTechnologies offered: 23\n\nNode: Dutch High Field Imaging Hub\nCountry: Netherlands\nTechnologies offered: 2\n\nNode: Brain Imaging Network (BIN)\nCountry: Portugal\nTechnologies offered: 14\n\nNode: Digital Imaging Multimodal Platform Neuromed \u2013  DIMP NEUROMED\nCountry: Italy\nTechnologies offered: 10\n\nNode: Facility of Multimodal Imaging - AMMI Maastricht\nCountry: Netherlands\nTechnologies offered: 24\n\nNode: The UK Node\nCountry: United Kingdom\nTechnologies offered: 57\n\nNode: Israel BioImaging\nCountry: Israel\nTechnologies offered: 41\n\nNode: Advanced Light Microscopy and Medical Imaging Node Brno CZ\nCountry: Czech Republic\nTechnologies offered: 18\n\nNode: Advanced Light Microscopy Node Poland\nCountry: Poland\nTechnologies offered: 24\n\nNode: Population Imaging Valencia\nCountry: Spain\nTechnologies offered: 9\n\nNode: Swedish National Microscopy Infrastructure (NMI)\nCountry: Sweden\nTechnologies offered: 64\n\nNode: Finnish Biomedical Imaging Node\nCountry: Finland\nTechnologies offered: 19\n\nNode: Austrian BioImaging Node/CMI\nCountry: Austria\nTechnologies offered: 50\n\nNode: French BioImaging Node\nCountry: France\nTechnologies offered: 68\n\nNode: Center for Advanced Preclinical Imaging (CAPI)\nCountry: Czech Republic\nTechnologies offered: 15\n\nNode: Molecular Imaging Italian Node\nCountry: Italy\nTechnologies offered: 20\n\nNode: Barcelona Mesoscopic Imaging Node\nCountry: Spain\nTechnologies offered: 13\n\nNode: SiMBION Node\nCountry: Slovenia\nTechnologies offered: 18\n\nNode: Advanced Light Microscopy Italian Node\nCountry: Italy\nTechnologies offered: 33\n\nNode: Portuguese Platform of BioImaging (PPBI)\nCountry: Portugal\nTechnologies offered: 35\n\nNode: Flanders Bioimaging Imaging Node\nCountry: Belgium\nTechnologies offered: 68\n\nNode: No Node preference\nCountry: Unknown\nTechnologies offered: 101\n\nNode: Euro-BioImaging EMBL-Node\nCountry: EMBL\nTechnologies offered: 42\n\nNode: Medical and Preclinical Imaging Hungary\nCountry: Hungary\nTechnologies offered: 14\n\nNode: Correlative Light Microscopy Dutch Flagship Node\nCountry: Netherlands\nTechnologies offered: 25\n\nNode: NORMOLIM, Norwegian Molecular Imaging Infrastructure\nCountry: Norway\nTechnologies offered: 10\n\nNode: Finnish Advanced Microscopy Node\nCountry: Finland\nTechnologies offered: 37\n\nNode: Danish BioImaging\nCountry: Denmark\nTechnologies offered: 40\n\nNode: Barcelona Super-resolution Light and Nanoscopy Node\nCountry: Spain\nTechnologies offered: 16\n\nNode: Advanced Light and Electron Microscopy Node Prague CZ\nCountry: Czech Republic\nTechnologies offered: 64\n\nNode: Barcelona Live and Intravital Node\nCountry: Spain\nTechnologies offered: 18\n\nNode: Population Imaging Flagship Node Rotterdam\nCountry: Netherlands\nTechnologies offered: 4\n\n",
                                            "attrs": {
                                              "className": "output-area"
                                            }
                                          }
                                        ],
                                        "executionCount": 36
                                      },
                                      {
                                        "id": "mcdh0840s4ukagyeu0h",
                                        "type": "markdown",
                                        "content": "Based on the imaging techniques relevant for analyzing dietary restrictions in mice and pigs, here are some suitable nodes:\n\n1. **Preclinical Imaging Centre (PRIME) - Molecular Imaging Dutch Node**\n   - **Country**: Netherlands\n   - **Technologies Offered**: 10\n\n2. **Cellular Imaging Hungary**\n   - **Country**: Hungary\n   - **Technologies Offered**: 23\n\n3. **Digital Imaging Multimodal Platform Neuromed \u2013  DIMP NEUROMED**\n   - **Country**: Italy\n   - **Technologies Offered**: 10\n\n4. **The UK Node**\n   - **Country**: United Kingdom\n   - **Technologies Offered**: 57\n\n5. **Swedish National Microscopy Infrastructure (NMI)**\n   - **Country**: Sweden\n   - **Technologies Offered**: 64\n\n6. **French BioImaging Node**\n   - **Country**: France\n   - **Technologies Offered**: 68\n\nThese nodes offer a variety of imaging technologies that can be used for comprehensive studies on dietary restriction effects. You may want to contact these facilities to discuss specific imaging capabilities and how they align with your research needs.",
                                        "executionState": "idle",
                                        "role": "assistant",
                                        "metadata": {
                                          "collapsed": false,
                                          "trusted": true,
                                          "isNew": false,
                                          "isEditing": false,
                                          "isCodeVisible": true,
                                          "isOutputVisible": true,
                                          "parent": "a9ba4a12-7f07-4035-8ffa-bb4ded5631e6"
                                        }
                                      }
                                    ]
                                  },
                                  "_security": {
                                    "sanitized": true,
                                    "sanitizedAt": "2025-06-26T14:24:05.482Z",
                                    "version": "1.0",
                                    "note": "All API keys and sensitive data have been automatically removed"
                                  }
                                }
                              }
                            },
                            "cells": [
                              {
                                "id": "9044a6d4-58e5-4b7a-905a-fe60777a9891",
                                "type": "code",
                                "content": "import micropip\nawait micropip.install([\"httpx\", \"pydantic\"])\n\nimport httpx\nfrom typing import Dict, List, Any\nfrom pydantic import BaseModel\n\nclass TechDetail(BaseModel):\n    \"\"\"Details of a specific technology\"\"\"\n    id: str\n    name: str\n    original_id: str\n    description: str\n    keywords: List[str]\n    documentation: str\n    category: Dict[str, Any]\n    provider_node_ids: List[str]\n    abbr: str\n\nclass NodeDetail(BaseModel):\n    \"\"\"Details of a specific node\"\"\"\n    id: str\n    name: str\n    original_id: str\n    description: str\n    keywords: List[str]\n    documentation: str\n    country: Dict[str, Any]\n    offer_technology_ids: List[str]\n\nclass WebsitePageDetail(BaseModel):\n    \"\"\"Details of a Euro-BioImaging website page\"\"\"\n    id: str\n    url: str\n    title: str\n    description: str\n    keywords: List[str]\n    content_preview: str\n    headings: List[str]\n    page_type: str\n\nclass SearchResponse(BaseModel):\n    \"\"\"Structured search response\"\"\"\n    answer: str\n    relevant_technologies: List[str] = []\n    relevant_nodes: List[str] = []\n    relevant_pages: List[str] = []\n    summary: str = \"\"\n\n# Global data storage\ntech_data: List[Dict[str, Any]] = []\nnodes_data: List[Dict[str, Any]] = []\nwebsite_data: List[Dict[str, Any]] = []\n\nasync def load_eurobioimaging_data():\n    \"\"\"\n    Load Euro-BioImaging data from remote index file.\n    This function fetches the combined index from the remote URL and populates the global data structures.\n    \n    Returns:\n    - dict: Metadata about the loaded dataset including counts and creation info\n    \"\"\"\n    global tech_data, nodes_data, website_data\n    \n    url = \"https://oeway.github.io/euro-bioimaging-finder/eurobioimaging_index.json\"\n    \n    try:\n        async with httpx.AsyncClient(timeout=30.0) as client:\n            response = await client.get(url)\n            response.raise_for_status()\n            combined_data = response.json()\n        \n        # Extract data from combined index\n        tech_data = combined_data.get('technologies', [])\n        nodes_data = combined_data.get('nodes', [])\n        website_data = combined_data.get('website_pages', [])\n        \n        # Get metadata\n        metadata = combined_data.get('metadata', {})\n        dataset_info = {\n            'dataset_type': metadata.get('dataset_type', 'unknown'),\n            'created_at': metadata.get('created_at', 'unknown'),\n            'technologies_count': len(tech_data),\n            'nodes_count': len(nodes_data),\n            'website_pages_count': len(website_data),\n            'total_entries': len(tech_data) + len(nodes_data) + len(website_data)\n        }\n        \n        return dataset_info\n        \n    except Exception as e:\n        print(f\"Error loading data: {e}\")\n        tech_data = []\n        nodes_data = []\n        website_data = []\n        return {'error': str(e)}\n\ndef read_tech_details(tech_id: str):\n    \"\"\"\n    Read details of a specific technology by ID.\n    \n    Parameters:\n    - tech_id (str): The technology ID\n    \n    Returns:\n    - Optional[TechDetail]: Technology details or None if not found\n    \"\"\"\n    for tech in tech_data:\n        if tech['id'] == tech_id:\n            return TechDetail(**tech)\n    return None\n\ndef read_node_details(node_id: str):\n    \"\"\"\n    Read details of a specific node by ID.\n    \n    Parameters:\n    - node_id (str): The node ID\n    \n    Returns:\n    - Optional[NodeDetail]: Node details or None if not found\n    \"\"\"\n    for node in nodes_data:\n        if node['id'] == node_id:\n            return NodeDetail(**node)\n    return None\n\ndef read_nodes_by_country(country_code: str):\n    \"\"\"\n    Read all nodes in a specific country by ISO country code.\n    \n    Parameters:\n    - country_code (str): ISO country code (e.g., 'PL', 'SE', 'DE')\n    \n    Returns:\n    - List[NodeDetail]: List of all nodes in the specified country\n    \"\"\"\n    country_nodes = []\n    for node in nodes_data:\n        node_country = node.get('country', {})\n        if node_country.get('iso_a2', '').upper() == country_code.upper():\n            try:\n                country_nodes.append(NodeDetail(**node))\n            except Exception as e:\n                print(f\"Warning: Could not parse node {node.get('name', 'Unknown')}: {e}\")\n    return country_nodes\n\ndef read_website_page_details(page_id: str):\n    \"\"\"\n    Read details of a specific website page by ID.\n    \n    Parameters:\n    - page_id (str): The website page ID\n    \n    Returns:\n    - Optional[WebsitePageDetail]: Website page details or None if not found\n    \"\"\"\n    for page in website_data:\n        if page['id'] == page_id:\n            return WebsitePageDetail(**page)\n    return None\n\ndef get_country_codes():\n    \"\"\"\n    Get mapping of country names to ISO codes from the data.\n    \n    Returns:\n    - Dict[str, str]: Mapping of country names to ISO codes\n    \"\"\"\n    country_mapping = {}\n    for node in nodes_data:\n        country = node.get('country', {})\n        country_name = country.get('name', '')\n        country_code = country.get('iso_a2', '')\n        if country_name and country_code:\n            country_mapping[country_name.lower()] = country_code.upper()\n    return country_mapping\n\ndef find_nodes_by_technique(technique_keywords: List[str]):\n    \"\"\"\n    Find node IDs that offer technologies matching the given technique keywords.\n    \n    Parameters:\n    - technique_keywords (List[str]): List of technique-related keywords\n    \n    Returns:\n    - List[str]: List of node IDs offering the specified techniques\n    \"\"\"\n    matching_node_ids = set()\n    \n    # Search through all technologies to find matches\n    for tech in tech_data:\n        tech_name = tech.get('name', '').lower()\n        tech_keywords = [kw.lower() for kw in tech.get('keywords', [])]\n        tech_category = tech.get('category', {}).get('name', '').lower()\n        tech_abbr = tech.get('abbr', '').lower()\n        tech_description = tech.get('documentation', '').lower()\n        \n        match_score = 0\n        matched_keywords = 0\n        \n        for keyword in technique_keywords:\n            keyword_lower = keyword.lower()\n            \n            if keyword_lower == tech_name or keyword_lower == tech_abbr:\n                match_score += 10\n                matched_keywords += 1\n            elif keyword_lower in tech_name or keyword_lower in tech_abbr:\n                match_score += 5\n                matched_keywords += 1\n            elif keyword_lower in tech_category:\n                match_score += 3\n                matched_keywords += 1\n            elif any(keyword_lower in kw or kw in keyword_lower for kw in tech_keywords):\n                match_score += 2\n                matched_keywords += 1\n            elif keyword_lower in tech_description:\n                match_score += 1\n                matched_keywords += 1\n        \n        if match_score >= 2 or matched_keywords >= 2:\n            matching_node_ids.update(tech.get('provider_node_ids', []))\n    \n    return list(matching_node_ids)\n\ndef find_website_pages_by_keywords(keywords: List[str]):\n    \"\"\"\n    Find website page IDs that match the given keywords with relevance scoring.\n    \n    Parameters:\n    - keywords (List[str]): List of keywords to search for\n    \n    Returns:\n    - List[str]: List of website page IDs matching the keywords\n    \"\"\"\n    page_scores = []\n    \n    for page in website_data:\n        page_title = page.get('title', '').lower()\n        page_description = page.get('description', '').lower()\n        page_keywords = [kw.lower() for kw in page.get('keywords', [])]\n        page_content = page.get('content_preview', '').lower()\n        page_type = page.get('page_type', '').lower()\n        \n        score = 0\n        matched_keywords = 0\n        \n        for keyword in keywords:\n            keyword_lower = keyword.lower()\n            if keyword_lower in page_title:\n                score += 5\n                matched_keywords += 1\n            elif keyword_lower in page_description:\n                score += 3\n                matched_keywords += 1\n            elif any(keyword_lower in kw for kw in page_keywords):\n                score += 2\n                matched_keywords += 1\n            elif keyword_lower in page_content:\n                score += 1\n                matched_keywords += 1\n        \n        if 'about' in page_type or 'service' in page_type or 'access' in page_type:\n            score += 2\n        \n        if matched_keywords > 0 and score >= 2:\n            page_scores.append((page['id'], score, matched_keywords))\n    \n    page_scores.sort(key=lambda x: (x[1], x[2]), reverse=True)\n    return [page_id for page_id, _, _ in page_scores[:10]]\n\ndef create_search_prompt():\n    \"\"\"Create the search prompt with all available data indexes\"\"\"\n    # Create technology index with more details\n    tech_index = []\n    for tech in tech_data:\n        available_count = len(tech.get('provider_node_ids', []))\n        tech_index.append(f\"{tech['id']}: {tech['name']} (available at {available_count} nodes)\")\n    \n    # Create nodes index with geographic grouping and country codes\n    nodes_by_country = {}\n    country_codes_info = {}\n    for node in nodes_data:\n        country = node['country']['name']\n        country_code = node['country'].get('iso_a2', 'XX')\n        if country not in nodes_by_country:\n            nodes_by_country[country] = []\n            country_codes_info[country] = country_code\n        nodes_by_country[country].append(f\"{node['id']}: {node['name']}\")\n    \n    nodes_index = []\n    for country, country_nodes in sorted(nodes_by_country.items()):\n        country_code = country_codes_info[country]\n        nodes_index.append(f\"\\n**{country} ({country_code}):**\")\n        nodes_index.extend([f\"  - {node}\" for node in country_nodes])\n    \n    # Create website pages index\n    website_index = []\n    for page in website_data:\n        website_index.append(f\"{page['id']}: {page['title']} - {page['page_type']}\")\n    \n    prompt = f\"\"\"\nHere is a list of all the available resources associated with their IDs.\n\n## Available General Website Pages:\n{chr(10).join(website_index)}\n\n## Available Technologies: \n{chr(10).join(tech_index)}\n\n## Available Nodes by Country (with ISO codes):\n{chr(10).join(nodes_index)}\n\n**IMPORTANT**: Each entry in the indexes above follows the format `ID: Summary/Description`\n\n- For **Technologies**: `tech_id: Technology Name (available at X nodes)`\n- For **Nodes**: `node_id: Node Name` \n- For **Website Pages**: `page_id: Page Title - page_type`\n\nFor any matched topics, you can call the utility functions to get more details by the ID.\n\n**To use the utility functions**: Extract the ID (the part before the colon) and pass it to the appropriate function:\n- Use `tech_id` with `read_tech_details(tech_id)`\n- Use `node_id` with `read_node_details(node_id)` \n- Use `page_id` with `read_website_page_details(page_id)`\n\nThese utilities are available under the current execution context, and no need to use await to call them. For example:\n\n```python\n# Example: Get details of a specific technology\ntech_details = read_tech_details(\"02e4459a\")\nprint(f\"Technology: {{tech_details.name}}\")\nprint(f\"Description: {{tech_details.description}}\")\n```\n\nImprtantly, they are not under api.* namespace, so you can call them directly.\n\n\"\"\"\n\n    return prompt\n\n# Initialize data and create the search prompt\ndata_loaded = await load_eurobioimaging_data()\n\nif not data_loaded:\n    print(\"WARNING: \u274c Failed to load Euro-BioImaging data, none of the following functions will work properly.\")\n\nprint(\"\"\"\nYou are an AI assistant specialized in helping users discover imaging technologies, instruments, and services provided by the Euro-BioImaging network.\n\nYou have access to several utility functions for retrieving specific information about Euro-BioImaging facilities. Below are all the available resources in the Euro-BioImaging network:\n\"\"\")\n\n# Print the search context with all available data\nsearch_context = create_search_prompt()\nprint(search_context)\n\nprint(\"\"\"## \ud83d\udee0\ufe0f Available Utility Functions\n\n**IMPORTANT**: Call these functions directly - NO `await`, NO `api.` prefix, NO keyword arguments!\n\n### Detail Retrieval Functions\n- `read_tech_details(tech_id)` \u2192 `TechDetail(id, name, original_id, description, keywords, documentation, category, provider_node_ids, abbr)` or `None`\n- `read_node_details(node_id)` \u2192 `NodeDetail(id, name, original_id, description, keywords, documentation, country, offer_technology_ids)` or `None`  \n- `read_nodes_by_country(country_code)` \u2192 `List[NodeDetail(id, name, original_id, description, keywords, documentation, country, offer_technology_ids)]`\n- `read_website_page_details(page_id)` \u2192 `WebsitePageDetail(id, url, title, description, keywords, content_preview, headings, page_type)` or `None`\nThe returned objects are pydantic models, so you can access the attributes directly. For example: tech_details.name, node_details.country['name'], etc.\n\n### Search Helper Functions\n- `find_nodes_by_technique(technique_keywords)` \u2192 `List[str]` (node IDs)\n- `find_website_pages_by_keywords(keywords)` \u2192 `List[str]` (page IDs)\n- `get_country_codes()` \u2192 `Dict[str, str]` (country_name \u2192 ISO_code)\n\n\n## \u2705 Correct Function Call Examples\n\n```python\n# CORRECT: Get node details\nnode_details = read_node_details(\"48c78d41\")\nprint(f\"Node: {node_details.name}\")\nprint(f\"Country: {node_details.country['name']}\")\nprint(f\"Description: {node_details.description}\")\n\n# CORRECT: Get technology details  \ntech_details = read_tech_details(\"02e4459a\")\nprint(f\"Technology: {tech_details.name}\")\nprint(f\"Category: {tech_details.category['name']}\")\nprint(f\"Available at {len(tech_details.provider_node_ids)} nodes\")\n\n# CORRECT: Get all nodes in Germany\ngerman_nodes = read_nodes_by_country(\"DE\")\nfor node in german_nodes:\n    print(f\"Node: {node.name}\")\n    print(f\"Technologies: {len(node.offer_technology_ids)} available\")\n\n# CORRECT: Find nodes by technique\nnode_ids = find_nodes_by_technique([\"microscopy\", \"imaging\"])\nfor node_id in node_ids:\n    details = read_node_details(node_id)\n    print(f\"Node: {details.name} in {details.country['name']}\")\n```\n\n## \u274c WRONG Function Call Examples\n\n```python\n# WRONG: Don't use await\nnode_details = await read_node_details(\"48c78d41\")  # \u274c\n\n# WRONG: Don't use api prefix\nnode_details = api.read_node_details(\"48c78d41\")  # \u274c\n\n# WRONG: Don't use keyword arguments\nnode_details = read_node_details(node_id=\"48c78d41\")  # \u274c\n\n# WRONG: Don't combine await + api\nnode_details = await api.read_node_details(node_id=\"48c78d41\")  # \u274c\n```\n\n## \ud83e\udde0 How to Answer User Queries\n\nFollow this systematic approach:\n\n### 1. **Analyze the Query Type**\n- **Geographic queries** (e.g., \"facilities in Germany\"): Focus on specific countries/regions\n- **Technology queries** (e.g., \"super-resolution microscopy\"): Focus on specific techniques or instruments  \n- **General information** (e.g., \"how to access services\"): Focus on website pages and general guidance\n- **Listing queries** (e.g., \"all available nodes\"): Provide comprehensive listings\n\n### 2. **Select Relevant IDs**\nFrom the indexes above, identify the specific IDs you need by looking at the summaries:\n- **Technology IDs**: Look for relevant techniques in the technology list, extract the ID before the colon\n- **Node IDs**: Look for relevant facilities in the node list, extract the ID before the colon\n- **Country codes**: Use the ISO codes in parentheses (e.g., DE, SE, FR)\n- **Page IDs**: Look for relevant information pages, extract the ID before the colon\n\n**Example**: If you see `tech_super_res_microscopy: Super-Resolution Microscopy (available at 15 nodes)`, use `tech_super_res_microscopy` as the ID.\n\n### 3. **Retrieve Detailed Information**\nUse the utility functions systematically:\n\n**For Technology Queries:**\n```python\n# Example: \"Where can I find MINFLUX?\"\n# Step 1: Get the specific technology details\nminflux_details = read_tech_details(\"4bf1cfdd\")  # Extract ID from index\nprint(f\"Technology: {minflux_details.name}\")\n\n# Step 2: Get nodes where it's available (don't list all their technologies)\nfor node_id in minflux_details.provider_node_ids:\n    node_details = read_node_details(node_id)\n    print(f\"Available at: {node_details.name} in {node_details.country['name']}\")\n```\n\n**For Geographic Queries:**\n```python\n# Example: \"What imaging facilities are in Germany?\"\ncountry_nodes = read_nodes_by_country(\"DE\")  # Germany\nfor node in country_nodes:\n    print(f\"Node: {node.name}\")\n    print(f\"Description: {node.description}\")\n    print(f\"Technologies available: {len(node.offer_technology_ids)} total\")\n    # Only list technologies if specifically asked, don't retrieve all details\n```\n\n**For General Information:**\n```python\n# Find relevant website pages\npage_ids = find_website_pages_by_keywords([\"access\", \"services\"])\nfor page_id in page_ids:\n    page_details = read_website_page_details(page_id)\n    print(f\"Page: {page_details.title}\")\n    print(f\"URL: {page_details.url}\")\n    print(f\"Description: {page_details.description}\")\n```\n\n### 4. **Be Focused and Efficient**\n- Only retrieve information that directly answers the user's question\n- Don't list all technologies at a node unless specifically asked\n- Don't retrieve all details unless needed for the specific query\n- Answer the question, don't provide unnecessary comprehensive listings\n\n### 5. **Reason Across Results**\n- Integrate information from multiple search results if needed\n- Draw conclusions, extract availability details, instrument capabilities, node locations, and relevant contact information\n\n### 6. **Respond Factually and Comprehensively**\n- Ensure your final reply contains all key findings and actionable information\n- Always include all relevant details in your final answer, the intermediate script output won't be seen by the user\n- Avoid vague summaries\u2014be precise and specific based on the returned context\n\n## \ud83d\udccb Query Pattern Examples\n\n**Geographic Query**: \"What imaging facilities are available in Germany?\"\n1. Use `read_nodes_by_country(\"DE\")` to get all German nodes\n2. For each node, use `read_node_details()` to get full information\n3. For each technology at the nodes, use `read_tech_details()` to understand capabilities\n\n**Technology Query**: \"Where can I access super-resolution microscopy?\"\n1. Use `find_nodes_by_technique([\"super-resolution\", \"microscopy\"])` to find relevant nodes\n2. Use `read_node_details()` for each node to get contact information\n3. Use `read_tech_details()` to understand specific capabilities\n\n**General Information**: \"How do I access Euro-BioImaging services?\"\n1. Use `find_website_pages_by_keywords([\"access\", \"services\", \"application\"])` to find relevant pages\n2. Use `read_website_page_details()` for each page to get detailed information\n\n## \ud83c\udfaf Response Quality Guidelines\n0. When generating the thoughts, limit each thought to 5 words maximum.\n1. **Use the indexes above** to identify relevant resources by their summaries\n2. **Extract IDs correctly** (the part before the colon) from the index entries\n3. **Call functions directly** without await, api prefix, or keyword arguments\n4. **Be systematic** in retrieving details for all relevant items\n5. **Include geographic context** (country names and codes)\n6. **Provide comprehensive information** which corresponds to the user query, try to be helpful and comprehensive.\n7. Since we are targeting non-technical users, unless asked, you can generate and execute scripts, but no need to commit code during the final response.\n\nRemember: Scan the indexes for relevant entries, extract the correct IDs, then call the utility functions directly to get detailed information.\n\"\"\") \n",
                                "executionState": "success",
                                "role": "system",
                                "metadata": {
                                  "collapsed": false,
                                  "trusted": true,
                                  "isNew": true,
                                  "isEditing": false,
                                  "isCodeVisible": false,
                                  "isOutputVisible": false,
                                  "parent": null,
                                  "userModified": true,
                                  "hasOutput": true
                                },
                                "output": [
                                  {
                                    "type": "stdout",
                                    "content": "\nYou are an AI assistant specialized in helping users discover imaging technologies, instruments, and services provided by the Euro-BioImaging network.\n\nYou have access to several utility functions for retrieving specific information about Euro-BioImaging facilities. Below are all the available resources in the Euro-BioImaging network:\n\n\nHere is a list of all the available resources associated with their IDs.\n\n## Available General Website Pages:\n5a1f2394: Euro-BioImaging - general\n50433509: Scientific Ambassadors - Euro-BioImaging - homepage\n17279c47: News - Euro-BioImaging - news\n7f1c0465: Cross-Node Job Shadowing - Euro-BioImaging - training\n9ce47fca: Euro-BioImaging Industry Board members - homepage\n4d84b867: Our Node list per member state - Euro-BioImaging - nodes\n6d96a010: EVOLVE Deliverables - Euro-BioImaging - homepage\nca3d775a: Upcoming events - Euro-BioImaging - homepage\n55fd947c: Partners - Euro-BioImaging - homepage\n07dd9e7b: Partner Communities - Euro-BioImaging - homepage\nc21af900: User services - Euro-BioImaging - services\n189866f3: SME and Industry Access - Euro-BioImaging - access\n41f306ff: Jobs - Euro-BioImaging - homepage\n4381661a: International partners - Euro-BioImaging - homepage\n2d9b63e5: Euro-BioImaging Industry Board activities - homepage\n411ae26c: World of Imaging - Euro-BioImaging - homepage\n90b4515c: FEBS Congress 2025 - Euro-BioImaging - homepage\nadda709f: EU projects - Euro-BioImaging - homepage\nde89e0d3: Special Edition Virtual Pubs - Euro-BioImaging - homepage\n86855cfd: Euro-BioImaging offers services for EIC beneficiaries - services\n4f3a0c44: Tech Exchange webinar for companies - Euro-BioImaging - homepage\nb349d95f: EVOLVE Overview - Euro-BioImaging - homepage\n2a29a068: How companies can engage with us - Euro-BioImaging - homepage\n60600ada: Impact - Euro-BioImaging - homepage\n93498950: PET is Wonderful - Euro-BioImaging - homepage\n6a51bc04: EVOLVE News - Euro-BioImaging - news\n2b195c12: EU Project CANDLE starts building National Cancer Data Nodes - Euro-BioImaging - news\nd16a1089: Global BioImaging - Euro-BioImaging - homepage\n2f2a69c5: Strategic Goals - Euro-BioImaging - homepage\n0d1a5dac: Research infrastructures - Euro-BioImaging - homepage\nbc9072ee: AgroSERV\u2019s 4th call for access is open - Euro-BioImaging - access\nec1e3263: Technology validation at Euro-BioImaging Nodes - nodes\n8364fb36: Community services - Euro-BioImaging - services\nd11cefd8: ISCaM Annual Meeting - Euro-BioImaging - homepage\ne474d3be: Expert groups - Euro-BioImaging - homepage\na4ddc691: Privacy policy - Euro-BioImaging - homepage\n1b63dc96: From our Nodes - Euro-BioImaging - training\n2fe4ab6f: Training and career resources from industry - training\n1c5096ea: Terms and conditions - Euro-BioImaging - homepage\n8584e842: Image data events - Euro-BioImaging - homepage\nfe54f4a8: How to access - Euro-BioImaging - access\n27ebce0a: FAIR image data - Euro-BioImaging - homepage\n3fdfcad3: Training - Euro-BioImaging - training\n468b262b: Sponsorship Programme - Euro-BioImaging - homepage\n4c1ea23d: EVOLVE - Euro-BioImaging - homepage\na636d01b: Who are we? - Euro-BioImaging - homepage\n390b5e34: Data services - Euro-BioImaging - services\n2c72ad20: User Forum - Euro-BioImaging - homepage\n3dce70f3: Our events - Euro-BioImaging - homepage\n5ddc68a0: List of our Member States - Euro-BioImaging - homepage\n\n## Available Technologies: \nfec9f08c: 3D Correlative Light and Electron Microscopy (3D-CLEM)* (available at 5 nodes)\nfab23cf9: 4Pi microscopy (available at 3 nodes)\n89a443da: Anisotropy/Polarization Microscopy (AM) (available at 8 nodes)\n6d1d2c73: Array tomography (AT) (available at 9 nodes)\n3b5ea5a5: Atomic Force Microscopy (AFM)* (available at 10 nodes)\n0d4e932c: Brillouin Scattering Microscopy (BSM) * (available at 1 nodes)\n08f8d79b: Challenges Framework (available at 2 nodes)\nefe82107: Coherent Anti-Stokes Raman Scattering microscopy (CARS)* (available at 4 nodes)\nd52fd886: Correlated Optical Coherence Tomography/PhotoAcoustic Tomography (OCT/PAT) (available at 2 nodes)\n5cebbccf: Correlative Array Tomography (CAT) (available at 2 nodes)\n103a615e: Correlative X-ray and EM (CXEM)* (available at 3 nodes)\n3abb3051: Cryo Correlative Light and Electron Microscopy (Cryo-CLEM)* (available at 4 nodes)\nc2b2b8a4: Cryo Electron Tomography (Cryo-ET)* (available at 9 nodes)\n0b7f406f: Cryo Focussed Ion beam (Cryo-FIB)* (available at 7 nodes)\nce409fef: Cryo Scanning Electron Microscopy (Cryo-SEM)* (available at 6 nodes)\nd6d89e7e: Cryo Transmission Electron Microscopy* (Cryo-TEM) (available at 11 nodes)\nafc7abf8: Cryo fluorescence microscopy (CryoFM) (available at 4 nodes)\nbb269201: Deconvolution widefield microscopy (DWM) (available at 17 nodes)\ned8349ea: EM tomography (ET) (available at 13 nodes)\nb88a530d: Elemental analysis (EDX)* (available at 6 nodes)\n2f897611: Elemental analysis Correlative Light and Electron Microscopy (EDX-CLEM)* (available at 2 nodes)\ne24721d4: Expansion Microscopy (ExM)* (available at 10 nodes)\n2ed4139e: Feedback microscopy (FDBKM)* (available at 4 nodes)\n132f6f32: Fluorescence (cross)-correlation spectroscopy (FCS/FCCS) (available at 19 nodes)\n629110f0: Fluorescence Lifetime Imaging (FLIM) (available at 21 nodes)\n5d8d5dc4: Fluorescence Recovery after Photobleaching (FRAP) (available at 25 nodes)\na45929e2: Fluorescence Resonance Energy Transfer (FRET) (available at 24 nodes)\nc95abb08: Focussed Ion beam SEM (FIB-SEM)  (available at 12 nodes)\ncc438528: Fourier transform infrared imaging (FTIR) (available at 2 nodes)\n8df90740: Genetic encoded EM probes (GE probes) (available at 7 nodes)\n21e8f4ac: High throughput microscopy/high content screening (HTM/HCS) (available at 20 nodes)\n50c799a3: High-speed Imaging (HSI)* (available at 7 nodes)\n1cf70dd4: I don't know which technology (available at 39 nodes)\n6932a41c: Image Analysis -bio (IA bio)* (available at 13 nodes)\ndb554130: Image Scanning microscopy (ISM) (available at 14 nodes)\n2d8d782a: Image analysis - med (IA med)* (available at 9 nodes)\ncb3a7812: Imaging Flow Cytometry (IFC)* (available at 3 nodes)\n2341dea1: Imaging at Biosafety Level >1 (BSL>1) (available at 8 nodes)\nf3523a33: Imaging for Plant Phenotyping (PHENO)* (available at 1 nodes)\ne69475ee: Immuno-gold EM on resin sections (resin-EM) (available at 16 nodes)\nf07465bf: Immuno-gold EM on thawed cryo-sections (Tokuyasu-EM) (available at 15 nodes)\nf9967160: Intravital Microscopy (IVM) (available at 9 nodes)\n96a7b611: Large scale EM (lsTEM) (available at 7 nodes)\n69c9835a: Laser scanning confocal microscopy (LSCM/CLSM) (available at 25 nodes)\n4027772e: Lattice light-sheet (LLS) (available at 5 nodes)\n8f2ec85d: Light-sheet mesoscopic imaging (SPIM/dSLSM) (available at 15 nodes)\n767472bf: Long-term vertical-stage confocal/Airyscan microscopy (available at 1 nodes)\n88410843: MRI/MRS (< 7T) (available at 9 nodes)\n102ade9f: MRI/MRS (>= 7T) (available at 4 nodes)\n510dcac1: Macro Serial Blockface Fluorescence imaging* (S-BFI) (available at 4 nodes)\n287cbbf4: Magnetic Particle Imaging (MPI)* (available at 1 nodes)\n01d95f61: MagnetoEncephaloGraphy (MEG) (available at 2 nodes)\n685556f2: Mass spectrometry-based imaging - bio (MSI - bio)* (available at 9 nodes)\ne0d1f09d: Mass spectrometry-based imaging - med (MSI - med)* (available at 5 nodes)\nc7ce64cd: Micro X-ray Fluorescence Spectrometry (XRF)* (available at 2 nodes)\n968f3cad: Micro-Particle Induced X-ray Emmission (\u00b5-PIXE)* (available at 1 nodes)\nfdd9e27b: Microdissection (\u00b5Dis)* (available at 8 nodes)\n4bf1cfdd: Minimal Photon Fluxes Microscopy (MINFLUX)* (available at 4 nodes)\n361833e0: Multiplexing imaging (MXI)* (available at 3 nodes)\nb3706dbe: Objective-coupled planar illumination (OCPI) (available at 3 nodes)\n736e09cf: Optical projection tomography (OPT) (available at 7 nodes)\n2dbadfb4: PET (available at 5 nodes)\n3135d75e: PET-MRI (available at 7 nodes)\n14106f99: PET/CT * (available at 6 nodes)\n8942de65: Phase Contrast Imaging (PCI) (available at 2 nodes)\n450c0308: Phosphorescence Lifetime imaging (PLIM)* (available at 5 nodes)\n733829b3: PhotoAcoustic Imaging (PAI) - med (available at 7 nodes)\n96bf8044: Photoacoustic imaging (PAI - bio)* (available at 3 nodes)\n770dc5d9: Photomanipulation (Pmanip) (available at 8 nodes)\neb8ac06a: Plant Phenotyping (PHENOPlant)* (available at 1 nodes)\nec04428a: Polarization microscopy (PM) (available at 5 nodes)\nce96b734: Population imaging (PI data) (available at 5 nodes)\n95515fe0: Population imaging (PI) (available at 5 nodes)\n09c086e2: Quantitative Phase Imaging (QPI)* (available at 6 nodes)\n0da5bf64: Raman Spectroscopy (RS) (available at 8 nodes)\nbae99d0f: Random Illumination Microscopy (RIM)* (available at 2 nodes)\nf92b5ff7: Reversible optical fluorescence transitions (RESOLFT) (available at 5 nodes)\n3f3eab3c: STEM tomography (STEM) (available at 4 nodes)\nf4b8d83e: Scanning Electron Microscopy (SEM) (available at 14 nodes)\n9c3659ad: Second/Third Harmonic Generation (SHG/THG) (available at 12 nodes)\n6d1c1521: Secondary Ion Mass Spectrometry with MeV ions (MeV-SIMS)* (available at 1 nodes)\n0c1d6852: Serial Blockface SEM (SBF-SEM) (available at 12 nodes)\n701f7dbb: Single Molecule localization microscopy (SMLM) (available at 21 nodes)\ncdb61d9f: Single Particle Tracking (SPT)* (available at 3 nodes)\nd610d253: Single molecule FRET (smFRET)* (available at 6 nodes)\nf0759e54: Spatial Transcriptomics (ST)* (available at 3 nodes)\n2798735f: Spinning disk confocal microscopy (SDCM) (available at 23 nodes)\n6c4ec674: Stimulated Raman Scattering (SRS)* (available at 1 nodes)\nc6fb1c2f: Stimulated emission depletion microscopy (STED) (available at 18 nodes)\n26979ff3: Structured illumination microscopy* (SIM) (available at 16 nodes)\nad292a2d: Super-resolution radial fluctuations (SRRF)* (available at 2 nodes)\n27ede81d: TEM of chemical fixed samples (TEM) (available at 18 nodes)\n3426e97c: TEM of cryo-immobilized samples (TEM cryo samples)* (available at 13 nodes)\n966d7b67: TEM of immobilized particles (TEM neg stain)* (available at 2 nodes)\nc00eb48d: Terahertz Plant Imaging (THzI)* (available at 1 nodes)\nebae82c0: Tissue Clearing (TC)* (available at 11 nodes)\n12becb66: Total internal reflection fluorescence microscopy (TIRF) (available at 24 nodes)\n168ae55a: Traction Force Microscopy (TFM)* (available at 3 nodes)\ndb9b2823: Two-photon microscopy (2P) (available at 22 nodes)\n0846ee13: Voltage/pH/Ion Imaging * (available at 6 nodes)\n08e7546d: ex-vivo micro-CT (available at 14 nodes)\n92bed18a: immunolabeling on immobilized particles (immunolocal)* (available at 3 nodes)\ne4feb57c: in vivo optical imaging (OI) (available at 16 nodes)\n34d19719: intravital microscopy (IVM-med) (available at 7 nodes)\nc089b934: live-cell Correlative Light and Electron Microscopy (live-cell CLEM) (available at 9 nodes)\n02e4459a: micro-CT (available at 14 nodes)\n8475c314: micro-MRI/MRS (<7 T)ex-vivo (available at 11 nodes)\naf9efb50: micro-MRI/MRS (>= 7 T)ex-vivo (available at 17 nodes)\nf54c3e84: micro-MRI/MRS (Field < 7 T) (available at 9 nodes)\n4efb9993: micro-MRI/MRS (Field >= 7 T) (available at 16 nodes)\n3e0a8955: micro-PET (available at 10 nodes)\n96a56356: micro-PET/CT (available at 15 nodes)\nd930619d: micro-PET/MRI (available at 11 nodes)\n855d73aa: micro-SPECT (available at 7 nodes)\nd375072f: micro-SPECT-CT (available at 9 nodes)\n2625745b: micro-US (available at 11 nodes)\nc60006e1: post-embed Correlative Light and Electron Microscopy (on-section CLEM) (available at 7 nodes)\n08039199: post-embedding CLEM (post-emb CLEM) (available at 7 nodes)\n9a28c6c6: pre-embed Correlative Light and Electron Microscopy (pre-embed CLEM) (available at 10 nodes)\nd8ca4f32: pre-embedding CLEM (pre-emb CLEM) (available at 10 nodes)\n0af84e8c: pre-embedding immunolabelling (pre-embed IL) (available at 13 nodes)\n3d7dbefb: serial section TEM (ssTEM) (available at 10 nodes)\n\n## Available Nodes by Country (with ISO codes):\n\n**Austria (AT):**\n  - fe6da9a2: Austrian BioImaging Node/CMI\n\n**Belgium (BE):**\n  - d34f360d: Flanders Bioimaging Imaging Node\n\n**Bulgaria (BG):**\n  - 15616319: Sofia BioImaging Node - Advanced Light Microscopy Node Sofia Bulgaria\u200b\n\n**Czech Republic (CZ):**\n  - e386e204: Advanced Light Microscopy and Medical Imaging Node Brno CZ\n  - 36918af1: Advanced Light and Electron Microscopy Node Prague CZ\n  - 8a620dcf: Center for Advanced Preclinical Imaging (CAPI)\n\n**Denmark (DK):**\n  - 7af97c83: Danish BioImaging\n\n**EMBL (EM):**\n  - 331e9969: Euro-BioImaging EMBL-Node\n\n**Finland (FI):**\n  - 48c78d41: Finnish Advanced Microscopy Node\n  - 10b17a12: Finnish Biomedical Imaging Node\n\n**France (FR):**\n  - 9a30f492: French BioImaging Node\n\n**Hungary (HU):**\n  - 0aa5a371: Cellular Imaging Hungary\n  - bc97a5c1: Medical and Preclinical Imaging Hungary\n\n**Israel (IL):**\n  - ae280e3f: Israel BioImaging\n\n**Italy (IT):**\n  - b293ca6a: Advanced Light Microscopy Italian Node\n  - 87d0da92: Digital Imaging Multimodal Platform Neuromed \u2013  DIMP NEUROMED\n  - 49edbdc3: Molecular Imaging Italian Node\n  - 60ea81f9: Phase Contrast Imaging Flagship Node Trieste\n\n**Netherlands (NL):**\n  - 149a2471: Challenges Framework Flagship Node\n  - 683c4ebe: Correlative Light Microscopy Dutch Flagship Node\n  - bf3644d1: Dutch High Field Imaging Hub\n  - d82f919f: Erasmus MC OIC - Advanced Light Microscopy Rotterdam Node\n  - 94637351: Facility of Multimodal Imaging - AMMI Maastricht\n  - f7c25902: High Throughput Microscopy Dutch Flagship Node\n  - a3249ee1: Population Imaging Flagship Node Rotterdam\n  - 9bb3d1ad: Preclinical Imaging Centre (PRIME) - Molecular Imaging Dutch Node\n  - 5daf731c: The Van Leeuwenhoek Center for Advanced Microscopy (LCAM) - Functional Imaging Flagship Node Amsterdam\n  - 80ce690f: Wageningen Imaging and Spectroscopy Hub (WISH) - ALM and Molecular Imaging Node Wageningen\n\n**Norway (NO):**\n  - 5f8fbcff: NORMOLIM, Norwegian Molecular Imaging Infrastructure\n  - 1c7c0fdd: NorMIC Oslo - Advanced Light Microscopy Node Oslo\n\n**Poland (PL):**\n  - 2bf6582d: Advanced Light Microscopy Node Poland\n\n**Portugal (PT):**\n  - 537eb30a: Brain Imaging Network (BIN)\n  - 3915af12: Portuguese Platform of BioImaging (PPBI)\n\n**Slovenia (SI):**\n  - 909e20e2: SiMBION Node\n\n**Spain (ES):**\n  - c894af20: Barcelona Live and Intravital Node\n  - 8a973fe5: Barcelona Mesoscopic Imaging Node\n  - 183918a6: Barcelona Super-resolution Light and Nanoscopy Node\n  - a1967241: Population Imaging Valencia\n\n**Sweden (SE):**\n  - 709aa452: Swedish National Microscopy Infrastructure (NMI)\n\n**United Kingdom (GB):**\n  - fd88fd08: The UK Node\n\n**Unknown (UN):**\n  - fa3c8323: No Node preference\n\n**IMPORTANT**: Each entry in the indexes above follows the format `ID: Summary/Description`\n\n- For **Technologies**: `tech_id: Technology Name (available at X nodes)`\n- For **Nodes**: `node_id: Node Name` \n- For **Website Pages**: `page_id: Page Title - page_type`\n\nFor any matched topics, you can call the utility functions to get more details by the ID.\n\n**To use the utility functions**: Extract the ID (the part before the colon) and pass it to the appropriate function:\n- Use `tech_id` with `read_tech_details(tech_id)`\n- Use `node_id` with `read_node_details(node_id)` \n- Use `page_id` with `read_website_page_details(page_id)`\n\nThese utilities are available under the current execution context, and no need to use await to call them. For example:\n\n```python\n# Example: Get details of a specific technology\ntech_details = read_tech_details(\"02e4459a\")\nprint(f\"Technology: {tech_details.name}\")\nprint(f\"Description: {tech_details.description}\")\n```\n\nImprtantly, they are not under api.* namespace, so you can call them directly.\n\n\n## \ud83d\udee0\ufe0f Available Utility Functions\n\n**IMPORTANT**: Call these functions directly - NO `await`, NO `api.` prefix, NO keyword arguments!\n\n### Detail Retrieval Functions\n- `read_tech_details(tech_id)` \u2192 `TechDetail(id, name, original_id, description, keywords, documentation, category, provider_node_ids, abbr)` or `None`\n- `read_node_details(node_id)` \u2192 `NodeDetail(id, name, original_id, description, keywords, documentation, country, offer_technology_ids)` or `None`  \n- `read_nodes_by_country(country_code)` \u2192 `List[NodeDetail(id, name, original_id, description, keywords, documentation, country, offer_technology_ids)]`\n- `read_website_page_details(page_id)` \u2192 `WebsitePageDetail(id, url, title, description, keywords, content_preview, headings, page_type)` or `None`\nThe returned objects are pydantic models, so you can access the attributes directly. For example: tech_details.name, node_details.country['name'], etc.\n\n### Search Helper Functions\n- `find_nodes_by_technique(technique_keywords)` \u2192 `List[str]` (node IDs)\n- `find_website_pages_by_keywords(keywords)` \u2192 `List[str]` (page IDs)\n- `get_country_codes()` \u2192 `Dict[str, str]` (country_name \u2192 ISO_code)\n\n\n## \u2705 Correct Function Call Examples\n\n```python\n# CORRECT: Get node details\nnode_details = read_node_details(\"48c78d41\")\nprint(f\"Node: {node_details.name}\")\nprint(f\"Country: {node_details.country['name']}\")\nprint(f\"Description: {node_details.description}\")\n\n# CORRECT: Get technology details  \ntech_details = read_tech_details(\"02e4459a\")\nprint(f\"Technology: {tech_details.name}\")\nprint(f\"Category: {tech_details.category['name']}\")\nprint(f\"Available at {len(tech_details.provider_node_ids)} nodes\")\n\n# CORRECT: Get all nodes in Germany\ngerman_nodes = read_nodes_by_country(\"DE\")\nfor node in german_nodes:\n    print(f\"Node: {node.name}\")\n    print(f\"Technologies: {len(node.offer_technology_ids)} available\")\n\n# CORRECT: Find nodes by technique\nnode_ids = find_nodes_by_technique([\"microscopy\", \"imaging\"])\nfor node_id in node_ids:\n    details = read_node_details(node_id)\n    print(f\"Node: {details.name} in {details.country['name']}\")\n```\n\n## \u274c WRONG Function Call Examples\n\n```python\n# WRONG: Don't use await\nnode_details = await read_node_details(\"48c78d41\")  # \u274c\n\n# WRONG: Don't use api prefix\nnode_details = api.read_node_details(\"48c78d41\")  # \u274c\n\n# WRONG: Don't use keyword arguments\nnode_details = read_node_details(node_id=\"48c78d41\")  # \u274c\n\n# WRONG: Don't combine await + api\nnode_details = await api.read_node_details(node_id=\"48c78d41\")  # \u274c\n```\n\n## \ud83e\udde0 How to Answer User Queries\n\nFollow this systematic approach:\n\n### 1. **Analyze the Query Type**\n- **Geographic queries** (e.g., \"facilities in Germany\"): Focus on specific countries/regions\n- **Technology queries** (e.g., \"super-resolution microscopy\"): Focus on specific techniques or instruments  \n- **General information** (e.g., \"how to access services\"): Focus on website pages and general guidance\n- **Listing queries** (e.g., \"all available nodes\"): Provide comprehensive listings\n\n### 2. **Select Relevant IDs**\nFrom the indexes above, identify the specific IDs you need by looking at the summaries:\n- **Technology IDs**: Look for relevant techniques in the technology list, extract the ID before the colon\n- **Node IDs**: Look for relevant facilities in the node list, extract the ID before the colon\n- **Country codes**: Use the ISO codes in parentheses (e.g., DE, SE, FR)\n- **Page IDs**: Look for relevant information pages, extract the ID before the colon\n\n**Example**: If you see `tech_super_res_microscopy: Super-Resolution Microscopy (available at 15 nodes)`, use `tech_super_res_microscopy` as the ID.\n\n### 3. **Retrieve Detailed Information**\nUse the utility functions systematically:\n\n**For Technology Queries:**\n```python\n# Example: \"Where can I find MINFLUX?\"\n# Step 1: Get the specific technology details\nminflux_details = read_tech_details(\"4bf1cfdd\")  # Extract ID from index\nprint(f\"Technology: {minflux_details.name}\")\n\n# Step 2: Get nodes where it's available (don't list all their technologies)\nfor node_id in minflux_details.provider_node_ids:\n    node_details = read_node_details(node_id)\n    print(f\"Available at: {node_details.name} in {node_details.country['name']}\")\n```\n\n**For Geographic Queries:**\n```python\n# Example: \"What imaging facilities are in Germany?\"\ncountry_nodes = read_nodes_by_country(\"DE\")  # Germany\nfor node in country_nodes:\n    print(f\"Node: {node.name}\")\n    print(f\"Description: {node.description}\")\n    print(f\"Technologies available: {len(node.offer_technology_ids)} total\")\n    # Only list technologies if specifically asked, don't retrieve all details\n```\n\n**For General Information:**\n```python\n# Find relevant website pages\npage_ids = find_website_pages_by_keywords([\"access\", \"services\"])\nfor page_id in page_ids:\n    page_details = read_website_page_details(page_id)\n    print(f\"Page: {page_details.title}\")\n    print(f\"URL: {page_details.url}\")\n    print(f\"Description: {page_details.description}\")\n```\n\n### 4. **Be Focused and Efficient**\n- Only retrieve information that directly answers the user's question\n- Don't list all technologies at a node unless specifically asked\n- Don't retrieve all details unless needed for the specific query\n- Answer the question, don't provide unnecessary comprehensive listings\n\n### 5. **Reason Across Results**\n- Integrate information from multiple search results if needed\n- Draw conclusions, extract availability details, instrument capabilities, node locations, and relevant contact information\n\n### 6. **Respond Factually and Comprehensively**\n- Ensure your final reply contains all key findings and actionable information\n- Always include all relevant details in your final answer, the intermediate script output won't be seen by the user\n- Avoid vague summaries\u2014be precise and specific based on the returned context\n\n## \ud83d\udccb Query Pattern Examples\n\n**Geographic Query**: \"What imaging facilities are available in Germany?\"\n1. Use `read_nodes_by_country(\"DE\")` to get all German nodes\n2. For each node, use `read_node_details()` to get full information\n3. For each technology at the nodes, use `read_tech_details()` to understand capabilities\n\n**Technology Query**: \"Where can I access super-resolution microscopy?\"\n1. Use `find_nodes_by_technique([\"super-resolution\", \"microscopy\"])` to find relevant nodes\n2. Use `read_node_details()` for each node to get contact information\n3. Use `read_tech_details()` to understand specific capabilities\n\n**General Information**: \"How do I access Euro-BioImaging services?\"\n1. Use `find_website_pages_by_keywords([\"access\", \"services\", \"application\"])` to find relevant pages\n2. Use `read_website_page_details()` for each page to get detailed information\n\n## \ud83c\udfaf Response Quality Guidelines\n0. When generating the thoughts, limit each thought to 5 words maximum.\n1. **Use the indexes above** to identify relevant resources by their summaries\n2. **Extract IDs correctly** (the part before the colon) from the index entries\n3. **Call functions directly** without await, api prefix, or keyword arguments\n4. **Be systematic** in retrieving details for all relevant items\n5. **Include geographic context** (country names and codes)\n6. **Provide comprehensive information** which corresponds to the user query, try to be helpful and comprehensive.\n7. Since we are targeting non-technical users, unless asked, you can generate and execute scripts, but no need to commit code during the final response.\n\nRemember: Scan the indexes for relevant entries, extract the correct IDs, then call the utility functions directly to get detailed information.\n\n",
                                    "attrs": {
                                      "className": "output-area"
                                    }
                                  }
                                ],
                                "executionCount": 40
                              }
                            ]
                          },
                          "_security": {
                            "sanitized": true,
                            "sanitizedAt": "2025-06-26T14:49:01.886Z",
                            "version": "1.0",
                            "note": "All API keys and sensitive data have been automatically removed"
                          }
                        }
                      }
                    },
                    "cells": [
                      {
                        "id": "9044a6d4-58e5-4b7a-905a-fe60777a9891",
                        "type": "code",
                        "content": "import micropip\nawait micropip.install([\"httpx\", \"pydantic\", \"bm25s\"])\n\nimport httpx\nfrom typing import Dict, List, Any, Optional, Tuple\nfrom pydantic import BaseModel\nimport bm25s\nfrom pathlib import Path\nimport tempfile\nimport micropip\nimport pickle\n\nclass TechDetail(BaseModel):\n    \"\"\"Details of a specific technology\"\"\"\n    id: str\n    name: str\n    original_id: str\n    description: str\n    keywords: List[str]\n    documentation: str\n    category: Dict[str, Any]\n    provider_node_ids: List[str]\n    abbr: str\n\nclass NodeDetail(BaseModel):\n    \"\"\"Details of a specific node\"\"\"\n    id: str\n    name: str\n    original_id: str\n    description: str\n    keywords: List[str]\n    documentation: str\n    country: Dict[str, Any]\n    offer_technology_ids: List[str]\n\nclass WebsitePageDetail(BaseModel):\n    \"\"\"Details of a Euro-BioImaging website page\"\"\"\n    id: str\n    url: str\n    title: str\n    description: str\n    keywords: List[str]\n    documentation: str\n    headings: List[str]\n    page_type: str\n\nclass SearchResponse(BaseModel):\n    \"\"\"Structured search response\"\"\"\n    answer: str\n    relevant_technologies: List[str] = []\n    relevant_nodes: List[str] = []\n    relevant_pages: List[str] = []\n    summary: str = \"\"\n\n# Global data storage\ntech_data: List[Dict[str, Any]] = []\nnodes_data: List[Dict[str, Any]] = []\nwebsite_data: List[Dict[str, Any]] = []\nbm25_retriever = None\nbm25_metadata = None\n\nasync def load_eurobioimaging_data():\n    \"\"\"\n    Load Euro-BioImaging data from remote index file.\n    This function fetches the combined index from the remote URL and populates the global data structures.\n    \n    Returns:\n    - dict: Metadata about the loaded dataset including counts and creation info\n    \"\"\"\n    global tech_data, nodes_data, website_data, bm25_retriever, bm25_metadata\n    \n    base_url = \"https://oeway.github.io/euro-bioimaging-finder\"\n    \n    try:\n        async with httpx.AsyncClient(timeout=30.0) as client:\n            # Load main index\n            response = await client.get(f\"{base_url}/eurobioimaging_index.json\")\n            response.raise_for_status()\n            combined_data = response.json()\n            \n            # Extract data from combined index\n            tech_data = combined_data.get('technologies', [])\n            nodes_data = combined_data.get('nodes', [])\n            website_data = combined_data.get('website_pages', [])\n            bm25_metadata = combined_data.get('bm25_metadata', [])\n            \n            # Download and load BM25 pickle file\n            bm25_response = await client.get(f\"{base_url}/eurobioimaging_bm25_index.pkl\")\n            bm25_response.raise_for_status()\n            \n            # Save to temp file and load\n            with tempfile.NamedTemporaryFile(suffix='.pkl', delete=False) as temp_file:\n                temp_file.write(bm25_response.content)\n                temp_file.flush()\n                \n                with open(temp_file.name, 'rb') as f:\n                    bm25_retriever = pickle.load(f)\n            \n            # Get metadata\n            metadata = combined_data.get('metadata', {})\n            dataset_info = {\n                'dataset_type': metadata.get('dataset_type', 'unknown'),\n                'created_at': metadata.get('created_at', 'unknown'),\n                'technologies_count': len(tech_data),\n                'nodes_count': len(nodes_data),\n                'website_pages_count': len(website_data),\n                'total_entries': len(tech_data) + len(nodes_data) + len(website_data),\n                'bm25_documents': len(bm25_metadata) if bm25_metadata else 0\n            }\n            \n            return dataset_info\n            \n    except Exception as e:\n        print(f\"Error loading data: {e}\")\n        tech_data = []\n        nodes_data = []\n        website_data = []\n        bm25_retriever = None\n        bm25_metadata = None\n        raise e\n\ndef read_tech_details(tech_id: str):\n    \"\"\"\n    Read details of a specific technology by ID.\n    \n    Parameters:\n    - tech_id (str): The technology ID\n    \n    Returns:\n    - Optional[TechDetail]: Technology details or None if not found\n    \"\"\"\n    for tech in tech_data:\n        if tech['id'] == tech_id:\n            return TechDetail(**tech)\n    raise Exception(f\"Technology with ID {tech_id} not found\")\n\ndef read_node_details(node_id: str):\n    \"\"\"\n    Read details of a specific node by ID.\n    \n    Parameters:\n    - node_id (str): The node ID\n    \n    Returns:\n    - Optional[NodeDetail]: Node details or None if not found\n    \"\"\"\n    for node in nodes_data:\n        if node['id'] == node_id:\n            return NodeDetail(**node)\n    raise Exception(f\"Node with ID {node_id} not found\")\n\ndef read_nodes_by_country(country_code: str):\n    \"\"\"\n    Read all nodes in a specific country by ISO country code.\n    \n    Parameters:\n    - country_code (str): ISO country code (e.g., 'PL', 'SE', 'DE')\n    \n    Returns:\n    - List[NodeDetail]: List of all nodes in the specified country\n    \"\"\"\n    country_nodes = []\n    for node in nodes_data:\n        node_country = node.get('country', {})\n        if node_country.get('iso_a2', '').upper() == country_code.upper():\n            try:\n                country_nodes.append(NodeDetail(**node))\n            except Exception as e:\n                print(f\"Warning: Could not parse node {node.get('name', 'Unknown')}: {e}\")\n    return country_nodes\n\ndef read_website_page_details(page_id: str):\n    \"\"\"\n    Read details of a specific website page by ID.\n    \n    Parameters:\n    - page_id (str): The website page ID\n    \n    Returns:\n    - Optional[WebsitePageDetail]: Website page details or None if not found\n    \"\"\"\n    for page in website_data:\n        if page['id'] == page_id:\n            return WebsitePageDetail(**page)\n    raise Exception(f\"Website page with ID {page_id} not found\")\n\ndef get_country_codes():\n    \"\"\"\n    Get mapping of country names to ISO codes from the data.\n    \n    Returns:\n    - Dict[str, str]: Mapping of country names to ISO codes\n    \"\"\"\n    country_mapping = {}\n    for node in nodes_data:\n        country = node.get('country', {})\n        country_name = country.get('name', '')\n        country_code = country.get('iso_a2', '')\n        if country_name and country_code:\n            country_mapping[country_name.lower()] = country_code.upper()\n    return country_mapping\n\ndef find_nodes_by_technique(technique_keywords: List[str]):\n    \"\"\"\n    Find node IDs that offer technologies matching the given technique keywords.\n    \n    Parameters:\n    - technique_keywords (List[str]): List of technique-related keywords\n    \n    Returns:\n    - List[str]: List of node IDs offering the specified techniques\n    \"\"\"\n    matching_node_ids = set()\n    \n    # Search through all technologies to find matches\n    for tech in tech_data:\n        tech_name = tech.get('name', '').lower()\n        tech_keywords = [kw.lower() for kw in tech.get('keywords', [])]\n        tech_category = tech.get('category', {}).get('name', '').lower()\n        tech_abbr = tech.get('abbr', '').lower()\n        tech_description = tech.get('documentation', '').lower()\n        \n        match_score = 0\n        matched_keywords = 0\n        \n        for keyword in technique_keywords:\n            keyword_lower = keyword.lower()\n            \n            if keyword_lower == tech_name or keyword_lower == tech_abbr:\n                match_score += 10\n                matched_keywords += 1\n            elif keyword_lower in tech_name or keyword_lower in tech_abbr:\n                match_score += 5\n                matched_keywords += 1\n            elif keyword_lower in tech_category:\n                match_score += 3\n                matched_keywords += 1\n            elif any(keyword_lower in kw or kw in keyword_lower for kw in tech_keywords):\n                match_score += 2\n                matched_keywords += 1\n            elif keyword_lower in tech_description:\n                match_score += 1\n                matched_keywords += 1\n        \n        if match_score >= 2 or matched_keywords >= 2:\n            matching_node_ids.update(tech.get('provider_node_ids', []))\n    \n    return list(matching_node_ids)\n\ndef find_website_pages_by_keywords(keywords: List[str]):\n    \"\"\"\n    Find website page IDs that match the given keywords with relevance scoring.\n    \n    Parameters:\n    - keywords (List[str]): List of keywords to search for\n    \n    Returns:\n    - List[str]: List of website page IDs matching the keywords\n    \"\"\"\n    page_scores = []\n    \n    for page in website_data:\n        page_title = page.get('title', '').lower()\n        page_description = page.get('description', '').lower()\n        page_keywords = [kw.lower() for kw in page.get('keywords', [])]\n        page_content = page.get('documentation', '').lower()\n        page_type = page.get('page_type', '').lower()\n        \n        score = 0\n        matched_keywords = 0\n        \n        for keyword in keywords:\n            keyword_lower = keyword.lower()\n            if keyword_lower in page_title:\n                score += 5\n                matched_keywords += 1\n            elif keyword_lower in page_description:\n                score += 3\n                matched_keywords += 1\n            elif any(keyword_lower in kw for kw in page_keywords):\n                score += 2\n                matched_keywords += 1\n            elif keyword_lower in page_content:\n                score += 1\n                matched_keywords += 1\n        \n        if 'about' in page_type or 'service' in page_type or 'access' in page_type:\n            score += 2\n        \n        if matched_keywords > 0 and score >= 2:\n            page_scores.append((page['id'], score, matched_keywords))\n    \n    page_scores.sort(key=lambda x: (x[1], x[2]), reverse=True)\n    return [page_id for page_id, _, _ in page_scores[:10]]\n\ndef create_search_prompt():\n    \"\"\"Create the search prompt with all available data indexes\"\"\"\n    \n    def truncate_line(line: str, max_length: int = 256) -> str:\n        \"\"\"Truncate line to max_length, preserving the format\"\"\"\n        if len(line) <= max_length:\n            return line\n        return line[:max_length-3] + \"...\"\n    \n    # Create technology index with \"- id: name / description\" format\n    tech_index = []\n    for tech in tech_data:\n        name = tech.get('name', '')\n        description = tech.get('description', '').replace('\\n', ' ').strip()\n        line = f\"- {tech['id']}:{name}/{description}\"\n        tech_index.append(truncate_line(line))\n    \n    # Create nodes index with \"- id:name/description\" format, grouped by country\n    nodes_by_country = {}\n    country_codes_info = {}\n    for node in nodes_data:\n        country = node['country']['name']\n        country_code = node['country'].get('iso_a2', 'XX')\n        if country not in nodes_by_country:\n            nodes_by_country[country] = []\n            country_codes_info[country] = country_code\n        \n        name = node.get('name', '')\n        description = node.get('description', '').replace('\\n', ' ').strip()\n        line = f\"- {node['id']}:{name}/{description}\"\n        nodes_by_country[country].append(truncate_line(line))\n    \n    nodes_index = []\n    for country, country_nodes in sorted(nodes_by_country.items()):\n        country_code = country_codes_info[country]\n        nodes_index.append(f\"\\n**{country} ({country_code}):**\")\n        nodes_index.extend([f\"  {node}\" for node in country_nodes])\n    \n    # Create website pages index with \"- id: title / description\" format\n    website_index = []\n    for page in website_data:\n        title = page.get('title', '')\n        description = page.get('description', '').replace('\\n', ' ').strip()\n        line = f\"- {page['id']}:{title}/{description}\"\n        website_index.append(truncate_line(line))\n    \n    prompt = f\"\"\"\nHere is a list of all the available resources associated with their IDs.\n\n## Available General Website Pages:\n{chr(10).join(website_index)}\n\n## Available Technologies: \n{chr(10).join(tech_index)}\n\n## Available Nodes by Country (with ISO codes):\n{chr(10).join(nodes_index)}\n\n**IMPORTANT**: Each entry in the indexes above follows the format `- ID: Name / Description`\n\n- For **Technologies**: `- tech_id: Technology Name/Brief description`\n- For **Nodes**: `- node_id: Node Name/Brief description` \n- For **Website Pages**: `- page_id: Page Title/Brief description`\n\nFor any matched topics, you can call the utility functions to get more details by the ID.\n\n**To use the utility functions**: Extract the ID (the part after the dash and before the colon) and pass it to the appropriate function:\n- Use `tech_id` with `read_tech_details(tech_id)`\n- Use `node_id` with `read_node_details(node_id)` \n- Use `page_id` with `read_website_page_details(page_id)`\n\nThese utilities are available under the current execution context, and no need to use await to call them. For example:\n\n```python\n# Example: Get details of a specific technology\ntech_details = read_tech_details(\"02e4459a\")\nprint(f\"Technology: {{tech_details.name}}\")\nprint(f\"Description: {{tech_details.description}}\")\n```\n\nImprtantly, they are not under api.* namespace, so you can call them directly.\n\n\"\"\"\n\n    return prompt\n\ndef fulltext_search(query: str, k: int = 5) -> List[Dict[str, Any]]:\n    \"\"\"\n    Perform full-text search using BM25 index\n    \n    Parameters:\n    - query (str): The search query\n    - k (int): Number of results to return (default: 5)\n    \n    Returns:\n    - List[Dict]: List of matching documents with metadata\n    \"\"\"\n    if not bm25_retriever or not bm25_metadata:\n        raise Exception(\"Error: BM25 index not loaded\")\n    \n    # Tokenize query\n    query_tokens = bm25s.tokenize(query)\n    \n    # Get results\n    results, scores = bm25_retriever.retrieve(query_tokens, k=k)\n    \n    # Format results\n    search_results = []\n    for i in range(results.shape[1]):\n        doc_idx = results[0, i]\n        score = scores[0, i]\n        \n        # Get metadata for the document\n        metadata = bm25_metadata[doc_idx]\n        doc_type = metadata['type']\n        doc_id = metadata['id']\n        \n        # Get full details based on type\n        if doc_type == 'tech':\n            details = read_tech_details(doc_id)\n            if details:\n                search_results.append({\n                    'type': doc_type,\n                    'id': doc_id,\n                    'name': details.name,\n                    'description': details.description,\n                    'score': float(score),\n                    'documentation': details.documentation,\n                    'category': details.category,\n                    'provider_node_ids': details.provider_node_ids,\n                })\n        elif doc_type == 'node':\n            details = read_node_details(doc_id)\n            if details:\n                search_results.append({\n                    'type': doc_type,\n                    'id': doc_id,\n                    'name': details.name,\n                    'description': details.description,\n                    'score': float(score),\n                    'documentation': details.documentation,\n                    'country': details.country,\n                    'offer_technology_ids': details.offer_technology_ids,\n                })\n        elif doc_type == 'page':\n            details = read_website_page_details(doc_id)\n            if details:\n                search_results.append({\n                    'type': doc_type,\n                    'id': doc_id,\n                    'name': details.title,\n                    'description': details.description,\n                    'score': float(score),\n                    'url': details.url,\n                    'documentation': details.documentation,\n                    'headings': details.headings,\n                    'page_type': details.page_type,\n                })\n    \n    return search_results\n\n# Initialize data and create the search prompt\ndata_loaded = await load_eurobioimaging_data()\n\nif not data_loaded:\n    print(\"WARNING: \u274c Failed to load Euro-BioImaging data, none of the following functions will work properly.\")\n\nprint(\"\"\"\nYou are an AI assistant specialized in helping users discover imaging technologies, instruments, and services provided by the Euro-BioImaging network.\n\nYou have access to several utility functions for retrieving specific information about Euro-BioImaging facilities. Below are all the available resources in the Euro-BioImaging network:\n\"\"\")\n\n# Print the search context with all available data\nsearch_context = create_search_prompt()\nprint(search_context)\n\n# The printed text will be used for the LLM agent as prompt.\nprint(\"\"\"## \ud83d\udee0\ufe0f Available Utility Functions\n\n**IMPORTANT**: Call these functions directly - NO `await`, NO `api.` prefix, NO keyword arguments!\n\n### Detail Retrieval Functions\n- `read_tech_details(tech_id)` \u2192 `TechDetail(id, name, original_id, description, keywords, documentation, category, provider_node_ids, abbr)` or `None`\n- `read_node_details(node_id)` \u2192 `NodeDetail(id, name, original_id, description, keywords, documentation, country, offer_technology_ids)` or `None`  \n- `read_nodes_by_country(country_code)` \u2192 `List[NodeDetail(id, name, original_id, description, keywords, documentation, country, offer_technology_ids)]`\n- `read_website_page_details(page_id)` \u2192 `WebsitePageDetail(id, url, title, description, keywords, documentation, headings, page_type)` or `None`\nThe returned objects are pydantic models, so you can access the attributes directly. For example: tech_details.name, node_details.country['name'], etc.\n\n### Search Functions\n- `fulltext_search(query, k=5)` \u2192 `List[Dict]` (full-text search across all content types)\n- `get_country_codes()` \u2192 `Dict[str, str]` (country_name \u2192 ISO_code)\n\n\n## \u2705 Correct Function Call Examples\n\n```python\n# CORRECT: Get node details\nnode_details = read_node_details(\"48c78d41\")\nprint(f\"Node: {node_details.name}\")\nprint(f\"Country: {node_details.country['name']}\")\nprint(f\"Description: {node_details.description}\")\n\n# CORRECT: Get technology details  \ntech_details = read_tech_details(\"02e4459a\")\nprint(f\"Technology: {tech_details.name}\")\nprint(f\"Category: {tech_details.category['name']}\")\nprint(f\"Available at {len(tech_details.provider_node_ids)} nodes\")\n\n# CORRECT: Get all nodes in Germany\ngerman_nodes = read_nodes_by_country(\"DE\")\nfor node in german_nodes:\n    print(f\"Node: {node.name}\")\n    print(f\"Technologies: {len(node.offer_technology_ids)} available\")\n\n# CORRECT: Full-text search across all content\nresults = fulltext_search(\"super resolution microscopy\", k=5)\nfor result in results:\n    print(f\"Score: {result['score']:.2f} - Type: {result['type']} - Name: {result['name']}\")\n    print(f\"Description: {result['description']}\")\n```\n\n## \u274c WRONG Function Call Examples\n\n```python\n# WRONG: Don't use await\nnode_details = await read_node_details(\"48c78d41\")  # \u274c\n\n# WRONG: Don't use api prefix\nnode_details = api.read_node_details(\"48c78d41\")  # \u274c\n\n# WRONG: Don't use keyword arguments\nnode_details = read_node_details(node_id=\"48c78d41\")  # \u274c\n\n# WRONG: Don't combine await + api\nnode_details = await api.read_node_details(node_id=\"48c78d41\")  # \u274c\n```\n\n## \ud83e\udde0 How to Answer User Queries\n\nFollow this systematic approach:\n\n### 1. **Analyze the Query Type**\n- **Geographic queries** (e.g., \"facilities in Germany\"): Focus on specific countries/regions\n- **Technology queries** (e.g., \"super-resolution microscopy\"): Focus on specific techniques or instruments  \n- **General information** (e.g., \"how to access services\"): Focus on website pages and general guidance\n- **Listing queries** (e.g., \"all available nodes\"): Provide comprehensive listings\n\n### 2. **Select Relevant IDs**\nFrom the indexes above, identify the specific IDs you need by looking at the summaries:\n- **Technology IDs**: Look for relevant techniques in the technology list, extract the ID before the colon\n- **Node IDs**: Look for relevant facilities in the node list, extract the ID before the colon\n- **Country codes**: Use the ISO codes in parentheses (e.g., DE, SE, FR)\n- **Page IDs**: Look for relevant information pages, extract the ID before the colon\n\n**Example**: If you see `tech_super_res_microscopy: Super-Resolution Microscopy (available at 15 nodes)`, use `tech_super_res_microscopy` as the ID.\n\n### 3. **Retrieve Detailed Information**\nUse the utility functions systematically:\n\n**For Technology Queries:**\n```python\n# Example: \"Where can I find MINFLUX?\"\n# Step 1: Get the specific technology details\nminflux_details = read_tech_details(\"4bf1cfdd\")  # Extract ID from index\nprint(f\"Technology: {minflux_details.name}\")\n\n# Step 2: Get nodes where it's available (don't list all their technologies)\nfor node_id in minflux_details.provider_node_ids:\n    node_details = read_node_details(node_id)\n    print(f\"Available at: {node_details.name} in {node_details.country['name']}\")\n```\n\n**For Geographic Queries:**\n```python\n# Example: \"What imaging facilities are in Germany?\"\ncountry_nodes = read_nodes_by_country(\"DE\")  # Germany\nfor node in country_nodes:\n    print(f\"Node: {node.name}\")\n    print(f\"Description: {node.description}\")\n    print(f\"Technologies available: {len(node.offer_technology_ids)} total\")\n    # Only list technologies if specifically asked, don't retrieve all details\n```\n\n**For General Full-text Search:**\n```python\n# Use full-text search to find relevant content\nresults = fulltext_search(\"access services application\", k=5)\nfor result in results:\n    if result['type'] == 'page':\n        page_details = read_website_page_details(result['id'])\n        print(f\"Page: {page_details.title}\")\n        print(f\"URL: {page_details.url}\")\n        print(f\"Description: {page_details.description}\")\n```\n\n```python\n# Example: \"Find super-resolution microscopy techniques\"\nresults = fulltext_search(\"super resolution microscopy\", k=3)\nfor result in results:\n    if result['type'] == 'tech':\n        print(f\"Technology: {result['name']} (Score: {result['score']:.2f})\")\n        print(f\"Description: {result['description']}\")\n        # Get provider nodes if needed\n        tech_details = read_tech_details(result['id'])\n        for node_id in tech_details.provider_node_ids:\n            node_details = read_node_details(node_id)\n            print(f\"  Available at: {node_details.name} in {node_details.country['name']}\")\n```\n\n### 4. **Be Focused and Efficient**\n- Only retrieve information that directly answers the user's question\n- Don't list all technologies at a node unless specifically asked\n- Don't retrieve all details unless needed for the specific query\n- Answer the question, don't provide unnecessary comprehensive listings\n\n### 5. **Reason Across Results**\n- Integrate information from multiple search results if needed\n- Draw conclusions, extract availability details, instrument capabilities, node locations, and relevant contact information\n\n### 6. **Respond Factually and Comprehensively**\n- Ensure your final reply contains all key findings and actionable information\n- Always include all relevant details in your final answer, the intermediate script output won't be seen by the user\n- Avoid vague summaries\u2014be precise and specific based on the returned context\n\n## \ud83d\udccb Query Pattern Examples\n\n**Geographic Query**: \"What imaging facilities are available in Germany?\"\n1. Use `read_nodes_by_country(\"DE\")` to get all German nodes\n2. For each node, use `read_node_details()` to get full information\n3. For each technology at the nodes, use `read_tech_details()` to understand capabilities\n\n**Technology Query**: \"Where can I access super-resolution microscopy?\"\n1. Use `fulltext_search(\"super resolution microscopy\", k=3)` to find relevant technologies and nodes\n2. Filter results by type to focus on technologies and nodes\n3. Use `read_tech_details()` and `read_node_details()` to get detailed information\n\n**General Information**: \"How do I access Euro-BioImaging services?\"\n1. Use `fulltext_search(\"access services application procedures\", k=3)` to find relevant content\n2. Filter results for website pages that contain access information\n3. Use `read_website_page_details()` for each relevant page to get detailed information\n\n## \ud83c\udfaf Response Quality Guidelines\n0. When generating the thoughts, limit each thought to 5 words maximum.\n1. **Use the indexes above** to identify relevant resources by their summaries\n2. **Extract IDs correctly** (the part before the colon) from the index entries\n3. **Call functions directly** without await, api prefix, or keyword arguments\n4. **Be systematic** in retrieving details for all relevant items\n5. **Include geographic context** (country names and codes)\n6. **Provide comprehensive information** which corresponds to the user query, try to be helpful and comprehensive.\n7. Since we are targeting non-technical users, unless asked, you can generate and execute scripts, but no need to commit code during the final response.\n\nRemember: Scan the indexes for relevant entries, extract the correct IDs, then call the utility functions directly to get detailed information.\n\"\"\") \n",
                        "executionState": "success",
                        "role": "system",
                        "metadata": {
                          "collapsed": false,
                          "trusted": true,
                          "isNew": true,
                          "isEditing": false,
                          "isCodeVisible": false,
                          "isOutputVisible": true,
                          "parent": null,
                          "userModified": true,
                          "hasOutput": true
                        },
                        "output": [
                          {
                            "type": "stdout",
                            "content": "\nYou are an AI assistant specialized in helping users discover imaging technologies, instruments, and services provided by the Euro-BioImaging network.\n\nYou have access to several utility functions for retrieving specific information about Euro-BioImaging facilities. Below are all the available resources in the Euro-BioImaging network:\n\n\nHere is a list of all the available resources associated with their IDs.\n\n## Available General Website Pages:\n- a8afc69e:Euro-BioImaging/Access imaging technologies, expert training, data services across 41 Nodes in Europe.\n- 1d68d33b:From our partners - Euro-BioImaging/Grants for microscopy courses, training events, and application deadlines for researchers.\n- 756a7f96:FAIR image data - Euro-BioImaging/FAIR data services, training, and resources for bioimaging; contact for guidance.\n- a3c08c29:International Congress of Immunology - Euro-BioImaging/IUIS 2025 in Vienna: sessions, networking, workshops on immunology, Aug 17-22, 2025.\n- d49d869c:User services - Euro-BioImaging/Image Data Analysis services, access procedures, and expert support for users.\n- 76e849d9:Global BioImaging - Euro-BioImaging/Global BioImaging offers training, workshops, and support for imaging facilities globally.\n- 3fc6ae71:Euro-BioImaging Industry Board activities/Details on Tech Exchange webinars, Industry Board meetings, and membership opportunities.\n- 61a3d89f:Expert groups - Euro-BioImaging/Expert groups for image data analysis, human imaging, and workflows; contact details provided.\n- 8f75ae57:FEBS Congress 2025 - Euro-BioImaging/International forum for molecular life sciences, featuring lectures, symposia, and networking.\n- fe025651:Data services - Euro-BioImaging/Offers Image Data Services, analysis support, and FAIR data management tools for researchers.\n- 8d261b64:EVOLVE Deliverables - Euro-BioImaging/Detailed deliverables and milestones for Euro-BioImaging's strategic projects until 2027.\n- 559d72a4:New technologies - Euro-BioImaging/Details on showcasing and proof-of-concept for imaging technologies in life sciences.\n- 0de8066b:Archives: Events - Euro-BioImaging/Event listings for training and virtual discussions on advanced imaging techniques.\n- 2eed3cb2:Scientific Ambassadors 2025 - Euro-BioImaging/Profiles of 2025 Scientific Ambassadors and their imaging research contributions.\n- 286b7774:FAQ - Euro-BioImaging/Access imaging technologies, training, and support for life science research.\n- b36a5da9:Euro-BioImaging Training Courses - Euro-BioImaging/Training courses for Node staff on imaging techniques, management, and user support.\n- 2d37d231:Image data events - Euro-BioImaging/Events on image data management, FAIR principles, and innovative solutions in bioimaging.\n- 3e9f57f1:EU Project CANDLE starts building National Cancer Data Nodes - Euro-BioImaging/CANDLE builds EU cancer data nodes, enhancing research infrastructure and data sharing.\n- 04971200:How to cite us / How to acknowledge us - Euro-BioImaging/Guidelines for citing Euro-BioImaging in research publications and outputs.\n- 70076ce6:Cross-Node Job Shadowing - Euro-BioImaging/Job Shadowing program for Node Staff to enhance skills and collaboration across Europe.\n- d5725c0b:Contact us - Euro-BioImaging/Contact for inquiries, join virtual meetings, and subscribe to bioimaging updates.\n- be8afe8a:Partner Communities - Euro-BioImaging/Details on partner communities, their focus areas, and contact for suggestions.\n- 7977e1b0:International partners - Euro-BioImaging/Details on global imaging partnerships and access to advanced bioimaging resources.\n- f3743b49:Governance - Euro-BioImaging/Details on governance, member states, imaging facilities, and access procedures.\n- 762dd8ec:Tech Exchange webinar for companies - Euro-BioImaging/Monthly Tech Exchange webinars for imaging technologies; register for updates and recordings.\n- 2094ac30:SME and Industry Access - Euro-BioImaging/Access 240+ imaging facilities, consultation, and diverse imaging technologies for R&D.\n- ad5b1d1b:We are hiring! Scientific Project Manager for the IMAGINE project - Euro-BioImaging/Hiring Scientific Project Manager for IMAGINE project at EMBL, focusing on advanced imaging technologies.\n- 079328e9:Euro-BioImaging at TiM2025: Sharing Knowledge and Celebrating Open Data - Euro-BioImaging/Highlights workshops, data sharing, and resources from TiM2025 for ongoing learning.\n- 506d1e1b:EVOLVE News - Euro-BioImaging/Updates on training, job openings, mentoring masterclasses, and Node participation calls.\n- 46b19aac:Virtual Pub - Euro-BioImaging/Weekly virtual meetings on imaging tech; register via Zoom for talks and updates.\n- d8243da5:Funding - Euro-BioImaging/Funding options for researchers, including specific programs and application details.\n- 6c1e6f61:Our Team - Euro-BioImaging/Team roles, contact info, and management of imaging services in Europe.\n- 901b7776:Upcoming events - Euro-BioImaging/List of events and training in imaging and related fields through 2025.\n- fbe2ddeb:World of Imaging - Euro-BioImaging/Insights on global open access imaging initiatives and expert interviews.\n- b8e91076:EU projects - Euro-BioImaging/Details on EU-funded projects enhancing imaging services and research accessibility.\n- dc19e247:User Forum - Euro-BioImaging/User Forum events on imaging technologies for diverse research areas, featuring expert presentations.\n- a28cda35:Where to find us - Euro-BioImaging/Access world-class imaging facilities across Europe via the Euro-BioImaging Access Portal.\n- 834bd38f:Special Edition Virtual Pubs - Euro-BioImaging/Explore imaging technologies in research, with recordings and diverse topics covered.\n- 12ba7bc4:Remote Access - Euro-BioImaging/Remote access options for imaging services, including mail-in samples and virtual consultations.\n- ca962267:Euro-BioImaging offers services for EIC beneficiaries/Access imaging technologies, consultancy, and grants for EIC beneficiaries.\n- 7bbb7096:Research infrastructures - Euro-BioImaging/Access diverse life science services: imaging, biobanks, screening, structural biology.\n- c40ca520:Who are we? - Euro-BioImaging/Access advanced imaging technologies, training, and support across Europe via Euro-BioImaging.\n- 581f8b21:Technical support - Euro-BioImaging/Technical support for FAIR image data management, tools like XNAT-PIC, OME-Zarr, BatchConvert.\n- dd5e3428:AgroSERV\u2019s 4th call for access is open - Euro-BioImaging/AgroSERV offers funding for agroecology projects; apply by Oct 15, 2025.\n- e62da0ea:Strategic Goals - Euro-BioImaging/Strategic goals for 2024-2028 focus on advanced imaging services and user training.\n- da0aa881:PET is Wonderful - Euro-BioImaging/10th Anniversary PET Conference in Edinburgh, July 2-4, 2025; registration open, abstracts due May 25.\n- 7d8dab87:Documents - Euro-BioImaging/Access governance documents, annual reports, equality plan, and node list.\n- d06079f1:Euro-BioImaging/Access imaging technologies, expert training, data services across 41 Nodes in Europe.\n- ff305709:ISCaM Annual Meeting - Euro-BioImaging/ISCaM2025 meeting on cancer metabolism, July 2-4, Brussels; networking, presentations, and support for juniors.\n- d0250d99:Scientific Ambassadors - Euro-BioImaging/Join the Scientific Ambassadors program for training, networking, and advocacy in bioimaging.\n\n## Available Technologies: \n- 21ace7af:3D Correlative Light and Electron Microscopy (3D-CLEM)*/3D registration, volume EM & light microscopy, complex spatial analysis\n- 8d00238b:4Pi microscopy/Sub-150nm axial resolution, dual-objective, spherical wavefront imaging\n- 58d8cb68:Anisotropy/Polarization Microscopy (AM)/Fluorescence anisotropy for real-time biomolecular dynamics, nanosecond resolution.\n- 40194dad:Array tomography (AT)/3D ultrastructure, large samples, sub-10nm resolution, rapid sectioning\n- 6b83ff3b:Atomic Force Microscopy (AFM)*/Nanoscale morphology characterization, sub-nm resolution, elastic/viscous property evaluation.\n- 5977955d:Brillouin Scattering Microscopy (BSM) */Non-invasive, nanoscale mechanical property mapping, live cell imaging\n- 7c59051b:Challenges Framework/Open-source platform for collaborative medical image analysis challenges.\n- 5d9c29ad:Coherent Anti-Stokes Raman Scattering microscopy (CARS)*/Label-free, fast imaging of molecular vibrations in live samples.\n- e1040bd1:Correlated Optical Coherence Tomography/PhotoAcoustic Tomography (OCT/PAT)/Bimodal imaging: high-resolution OCT & PAT for deep tissue analysis.\n- 624bb10d:Correlative Array Tomography (CAT)/3D molecular architecture, high-resolution fluorescence, rapid ultrastructure capture\n- 901e98ba:Correlative X-ray and EM (CXEM)*/Subcellular resolution, X-ray & EM correlation, elemental distribution analysis.\n- a7df1346:Cryo Correlative Light and Electron Microscopy (Cryo-CLEM)*/Spatially correlated cryo-fluorescence and EM, versatile fluorophores.\n- 8d81c319:Cryo Electron Tomography (Cryo-ET)*/3D reconstruction of hydrated specimens, no fixation, high-resolution subtomogram averaging.\n- d74842f9:Cryo Focussed Ion beam (Cryo-FIB)*/Sub-100nm lamella preparation for cryoET, focused ion beam milling.\n- 1ae3a383:Cryo Scanning Electron Microscopy (Cryo-SEM)*/Cryo-SEM: sub-10nm resolution, hydrated specimens, native state imaging.\n- 3add638e:Cryo Transmission Electron Microscopy* (Cryo-TEM)/Atomic resolution, cryo-preserved samples, protein and virus structure analysis\n- a2746544:Cryo fluorescence microscopy (CryoFM)/CryoFM: sub-100nm resolution, cryo-fixation, correlative with cryo-EM.\n- 0f17785e:Deconvolution widefield microscopy (DWM)/Enhanced contrast, 3D optical sections, low phototoxicity for live cells.\n- 1b07352e:EM tomography (ET)/3D reconstruction from thick sections, up to 70\u00b0 tilt, serial imaging.\n- cbceae85:Elemental analysis (EDX)*/2D/3D elemental mapping, nm-\u00b5m resolution, sensitive to light/heavy elements.\n- 729cb68e:Elemental analysis Correlative Light and Electron Microscopy (EDX-CLEM)*/Simultaneous elemental detection, EM resolution, correlated light imaging.\n- ecf5c9b0:Expansion Microscopy (ExM)*/Sub-50nm resolution, 4-color imaging, large sample compatibility\n- 0ff9b602:Feedback microscopy (FDBKM)*/Automated image acquisition, high-throughput, responsive analysis for rare phenotypes.\n- eb873627:Fluorescence (cross)-correlation spectroscopy (FCS/FCCS)/Real-time binding analysis, dual-color correlation, molecular dynamics.\n- 252e9801:Fluorescence Lifetime Imaging (FLIM)/Quantitative imaging of fluorescence decay for FRET, pH, and polarity.\n- 00b1261b:Fluorescence Recovery after Photobleaching (FRAP)/Quantifies lateral diffusion in membranes; assesses mobile/immobile fractions.\n- 471b68b9:Fluorescence Resonance Energy Transfer (FRET)/Proximity sensing, nanometer resolution, biomolecular interactions, energy transfer\n- f5e39047:Focussed Ion beam SEM (FIB-SEM) /Sub-5nm 3D imaging, FIB slicing, ultrastructural cell analysis\n- 4f0cc8fb:Fourier transform infrared imaging (FTIR)/Simultaneous spectral data collection, wide range, diverse applications.\n- 530b1e76:Genetic encoded EM probes (GE probes)/Genetically encoded EM probes for protein localization, sub-10nm resolution.\n- 9f450547:High throughput microscopy/high content screening (HTM/HCS)/Automated genome screening, multi-well plates, high-content analysis.\n- 5a81f626:High-speed Imaging (HSI)*/High frame rate data capture for fast biological processes.\n- 6d696ea1:I don't know which technology/Guidance for technology selection, tailored support, application-focused.\n- cdeccebb:Image Analysis -bio (IA bio)*/Automated analysis for complex bio-imaging datasets, expert support.\n- b4954477:Image Scanning microscopy (ISM)/Sub-100nm resolution, array detector, enhanced confocal imaging.\n- ffd8e287:Image analysis - med (IA med)*/Automated analysis for complex multimodal datasets, expert support available.\n- 4ab88187:Imaging Flow Cytometry (IFC)*/Quantitative imaging of 1000 cells/sec, spatial insights, rare population analysis\n- d9de2d08:Imaging at Biosafety Level >1 (BSL>1)/BSL>1 imaging: BSL2/3 access for pathogens, specialized safety environments.\n- 8d7cbce7:Imaging for Plant Phenotyping (PHENO)*/High-throughput, non-invasive phenotyping for small to mid-size crops.\n- 2b21bc78:Immuno-gold EM on resin sections (resin-EM)/Resin-embedded immuno-gold EM: high-resolution protein localization.\n- 5309b875:Immuno-gold EM on thawed cryo-sections (Tokuyasu-EM)/Cryo-sectioned samples, gold labeling, protein localization, high resolution\n- 910278ba:Intravital Microscopy (IVM)/Real-time cellular imaging in live models; multi-modal, high-resolution.\n- f3f09006:Large scale EM (lsTEM)/Large datasets, large fields of view, high-resolution sectioned samples.\n- 562466e5:Laser scanning confocal microscopy (LSCM/CLSM)/High-resolution optical imaging with depth selectivity, 3D reconstructions.\n- 70c2eacc:Lattice light-sheet (LLS)/Sub-300fps, <1\u00b5m sectioning, low phototoxicity, live cell imaging\n- e8fda5d9:Light-sheet mesoscopic imaging (SPIM/dSLSM)/3D imaging of live tissues, multi-angle, high-resolution, minimal photodamage.\n- 25f497be:Long-term vertical-stage confocal/Airyscan microscopy/High-resolution vertical-stage for live cell imaging, minimal drift\n- e9723d75:MRI/MRS (< 7T)/<7T MRI/MRS: High-res soft tissue imaging, dynamic perfusion, novel contrast agents.\n- 82086490:MRI/MRS (>= 7T)/High-field MRI/MRS (>= 7T): superior resolution, advanced contrast agents, functional mapping.\n- 1283373b:Macro Serial Blockface Fluorescence imaging* (S-BFI)/3D reconstruction via serial imaging, detects autofluorescence in paraffin.\n- 04571361:Magnetic Particle Imaging (MPI)*/High-resolution MPI with no background, ideal for tracer imaging.\n- 5ebda8f7:MagnetoEncephaloGraphy (MEG)/Noninvasive, ms temporal, mm spatial resolution; neuronal dynamics mapping.\n- 64e7671a:Mass spectrometry-based imaging - bio (MSI - bio)*/Spatially resolved metabolite and protein analysis for drug studies.\n- d5eb2582:Mass spectrometry-based imaging - med (MSI - med)*/Spatially resolved metabolite and drug analysis for cancer diagnostics.\n- 0104d878:Micro X-ray Fluorescence Spectrometry (XRF)*/Elemental mapping, 2D distribution, high-energy X-ray analysis, solid samples\n- 53171b0b:Micro-Particle Induced X-ray Emmission (\u00b5-PIXE)*/Elemental mapping, sub-micron resolution, non-destructive analysis, versatile samples\n- cb144e3c:Microdissection (\u00b5Dis)*/High-purity cell isolation, FFPE/frozen samples, non-contact LMPC.\n- 9a0a4983:Minimal Photon Fluxes Microscopy (MINFLUX)*/Single-nanometer resolution, live cell tracking, 10 kHz sampling rate.\n- 39b98b55:Multiplexing imaging (MXI)*/50+ biomarkers, single-cell resolution, minimal sample use, customizable assays.\n- b904b395:Objective-coupled planar illumination (OCPI)/High-speed 3D imaging with low photobleaching, ideal for neurons.\n- 7bf25f6b:Optical projection tomography (OPT)/3D imaging of unlabeled samples, larger volumes, isometric datasets\n- df467a40:PET/High sensitivity, quantitative molecular imaging, radiotracer applications.\n- a1b1217f:PET-MRI/Hybrid imaging: high-resolution soft tissue & molecular insights.\n- 93d83460:PET/CT */High-resolution PET/CT: 3D molecular imaging, oncology, cardiac, neurology.\n- 20a5c7f2:Phase Contrast Imaging (PCI)/Sub-diffraction resolution, live cell analysis, phase shift detection\n- 5cc705ef:Phosphorescence Lifetime imaging (PLIM)*/Millisecond-scale phosphorescence decay, ideal for dynamic processes.\n- 75fecd0f:PhotoAcoustic Imaging (PAI) - med/Non-invasive imaging with high resolution for chromophore detection.\n- 6c954176:Photoacoustic imaging (PAI - bio)*/Combines optical & ultrasound for high-res imaging of chromophores.\n- 2e937c71:Photomanipulation (Pmanip)/Targeted laser interactions for cellular injury, tracking, and optogenetics.\n- 953136e1:Plant Phenotyping (PHENOPlant)*/High-throughput, non-invasive phenotyping for small to mid-size plants.\n- 5328ca5a:Polarization microscopy (PM)/Optically anisotropic contrast, mineral identification, birefringence analysis\n- f45dd1f2:Population imaging (PI data)/Cohort-level analysis, early disease detection, imaging biomarkers, systemic risk.\n- 9f564150:Population imaging (PI)/Cohort-based analysis for early disease detection via imaging biomarkers.\n- bf8f3046:Quantitative Phase Imaging (QPI)*/Label-free, high-contrast phase delay measurement for live cell analysis.\n- 7b171d76:Raman Spectroscopy (RS)/Inelastic scattering, molecular fingerprinting, non-destructive analysis\n- ec36687c:Random Illumination Microscopy (RIM)*/Super-resolution, thick samples, z-sectioning, blindSIM reconstruction.\n- 6e1e99fe:Reversible optical fluorescence transitions (RESOLFT)/Sub-50nm resolution, reversible transitions, live-cell imaging, minimal phototoxicity\n- 32ad7212:STEM tomography (STEM)/3D reconstruction from 2D images, high-resolution, thick sections.\n- fd8c21c6:Scanning Electron Microscopy (SEM)/Sub-10nm resolution, cryo-SEM, surface & internal imaging, automated.\n- 959ae68e:Second/Third Harmonic Generation (SHG/THG)/Label-free imaging of collagen, myosin, and interfaces; no phototoxicity.\n- 8363ea8c:Secondary Ion Mass Spectrometry with MeV ions (MeV-SIMS)*/High-resolution elemental analysis, sub-10nm depth profiling, MeV ions\n- d08e8fee:Serial Blockface SEM (SBF-SEM)/25 nm resolution, 3D imaging, automated serial sectioning, large samples\n- 30baefb1:Single Molecule localization microscopy (SMLM)/Sub-20nm resolution, single molecule tracking, live cell applications\n- 6c0f4a55:Single Particle Tracking (SPT)*/Real-time tracking of individual particles in live cells, high precision.\n- 3ebad6e3:Single molecule FRET (smFRET)*/Measure Angstrom-scale distances in biomolecules, real-time dynamics.\n- 6804eaba:Spatial Transcriptomics (ST)*/High-resolution gene expression mapping, tissue architecture analysis\n- 05c94d3a:Spinning disk confocal microscopy (SDCM)/High-speed fluorescence imaging, low photo-toxicity, live-cell applications.\n- c86e05f6:Stimulated Raman Scattering (SRS)*/Fast, label-free imaging of vibrational species with high sensitivity.\n- 33ca4459:Stimulated emission depletion microscopy (STED)/Sub-50nm resolution, selective fluorophore depletion, 3D datasets\n- e8eba737:Structured illumination microscopy* (SIM)/High-speed, low-light live-cell imaging with reduced phototoxicity.\n- 0fa424bf:Super-resolution radial fluctuations (SRRF)*/Sub-50nm resolution, live cell imaging, radial fluctuation analysis\n- a0938ca6:TEM of chemical fixed samples (TEM)/Sub-100nm resolution, chemically fixed samples, resin embedding, ultrastructure.\n- f90b8d52:TEM of cryo-immobilized samples (TEM cryo samples)*/Sub-100nm resolution, cryo-immobilization, native state preservation\n- 4b92bb38:TEM of immobilized particles (TEM neg stain)*/Negative staining for high-resolution imaging of immobilized particles.\n- bb23122d:Terahertz Plant Imaging (THzI)*/Non-invasive THz imaging for plant health, moisture detection, and growth analysis.\n- 14ce1823:Tissue Clearing (TC)*/Transparent biological tissues, enabling deep imaging in 3D.\n- 328c0024:Total internal reflection fluorescence microscopy (TIRF)/Sub-200nm resolution, selective surface imaging, live cell studies.\n- ae5d18b3:Traction Force Microscopy (TFM)*/Sub-cellular force mapping, live cell tracking, drug effects, high resolution\n- 9d23ceda:Two-photon microscopy (2P)/Infrared excitation, deep tissue imaging, low background fluorescence.\n- 278df125:Voltage/pH/Ion Imaging */High-resolution imaging of voltage, pH, and ion dynamics in live cells.\n- 417f54ba:ex-vivo micro-CT/High-resolution ex-vivo micro-CT for small animal anatomical studies.\n- c6a54fc5:immunolabeling on immobilized particles (immunolocal)*/High-resolution immunolabeling on fixed particles, versatile applications.\n- aa1ab4ec:in vivo optical imaging (OI)/Non-ionizing, high-resolution imaging for live cells, gene therapy monitoring.\n- c8b3344c:intravital microscopy (IVM-med)/Real-time, multi-modal imaging of live animal models, high resolution.\n- ed85feed:live-cell Correlative Light and Electron Microscopy (live-cell CLEM)/Live-cell imaging, high-res EM, molecular localization, CLEM protocols\n- 7cb0a86c:micro-CT/High-resolution in-vivo micro-CT for small animal studies, <100\u00b5m voxel.\n- 9aeea8d8:micro-MRI/MRS (<7 T)ex-vivo/Ex-vivo micro-MRI at 7T: high-resolution tissue analysis, metabolic insights.\n- da4da08c:micro-MRI/MRS (>= 7 T)ex-vivo/Ex-vivo micro-MRI at 7 T+, high-resolution tissue analysis, metabolic mapping.\n- 253221bf:micro-MRI/MRS (Field < 7 T)/High-resolution micro-MRI/MRS for in vivo soft tissue analysis under 7 T.\n- 1b871ed4:micro-MRI/MRS (Field >= 7 T)/High-res micro-MRI/MRS (\u22657 T) for soft tissue, metabolic imaging, perfusion.\n- a5c9e0c2:micro-PET/High-resolution micro-PET for small animal imaging, tracer quantification.\n- 88686629:micro-PET/CT/High-resolution micro-PET/CT for small animal imaging, tracer quantification.\n- 118b6cf4:micro-PET/MRI/Hybrid imaging: high-resolution soft tissue & molecular insights.\n- 5c68f872:micro-SPECT/High-resolution micro-SPECT: 3D imaging, small animal studies, radiotracer quantification.\n- 82291658:micro-SPECT-CT/High-resolution micro-SPECT-CT for small animal imaging, 3D quantification.\n- a94de01a:micro-US/High-res micro-US for small animal studies, optimized transducer selection.\n- 7baace59:post-embed Correlative Light and Electron Microscopy (on-section CLEM)/Fluorescence-preserving CLEM: ultrastructure, fiducial markers, post-embedding.\n- 2d7feee1:post-embedding CLEM (post-emb CLEM)/Fluorescence retention in EM, precise localization via fiducial markers.\n- 7b77b8f2:pre-embed Correlative Light and Electron Microscopy (pre-embed CLEM)/Pre-embed CLEM: optimal fluorescence pre-EM, cellular structure correlation.\n- 279592df:pre-embedding CLEM (pre-emb CLEM)/Fluorescence before EM, optimal signal, challenges in correlation.\n- b3f497d1:pre-embedding immunolabelling (pre-embed IL)/Enhanced antibody recognition pre-EM, optimized for target specificity.\n- 6746de06:serial section TEM (ssTEM)/3D reconstruction from serial thin sections, high-resolution TEM imaging.\n\n## Available Nodes by Country (with ISO codes):\n\n**Austria (AT):**\n  - bacc207f:Austrian BioImaging Node/CMI/Austria 8-site: multimodal imaging, cryo-EM, microCT, data analysis support\n\n**Belgium (BE):**\n  - a6ae284f:Flanders Bioimaging Imaging Node/Multi-site, multi-modality node: molecular to clinical imaging expertise.\n\n**Bulgaria (BG):**\n  - 41e07c14:Sofia BioImaging Node - Advanced Light Microscopy Node Sofia Bulgaria\u200b/Multimodal imaging, fast live-cell, high-res, laser disruption expertise.\n\n**Czech Republic (CZ):**\n  - 7fbef150:Advanced Light Microscopy and Medical Imaging Node Brno CZ/Multi-modal imaging: 9.4T MR, training, data analysis, open access.\n  - 46c2f926:Advanced Light and Electron Microscopy Node Prague CZ/Multi-modal imaging: super-resolution, intravital, training courses.\n  - 34a7391d:Center for Advanced Preclinical Imaging (CAPI)/CAPI: Multimodal preclinical imaging, in vivo research, co-registration expertise.\n\n**Denmark (DK):**\n  - cc0560e1:Danish BioImaging/Multi-sited Node: pre-clinical imaging, cryo-EM, diverse applications.\n\n**EMBL (EM):**\n  - f04ae578:Euro-BioImaging EMBL-Node/EMBL Node: advanced imaging, project planning, training, high-end tools.\n\n**Finland (FI):**\n  - 60be0c5f:Finnish Advanced Microscopy Node/Sub-10nm resolution, cryo-electron, high-throughput, multi-modal capabilities\n  - 8d90cf75:Finnish Biomedical Imaging Node/Multi-modal imaging from mice to humans, focusing on PET, MRI, MEG.\n\n**France (FR):**\n  - 9ba9c26b:French BioImaging Node/30 facilities, 80 labs, multi-modal imaging, bioinformatics integration\n\n**Hungary (HU):**\n  - e6b05cd1:Cellular Imaging Hungary/Multi-modal node for infectious disease research, LSCM, ISIDORe support.\n  - 651d1d8b:Medical and Preclinical Imaging Hungary/Multi-modal Node: functional imaging, high expertise, M3 concept.\n\n**Israel (IL):**\n  - a75cea97:Israel BioImaging/Cross-modality imaging: single-molecule to clinical, advanced analysis.\n\n**Italy (IT):**\n  - 715483f6:Advanced Light Microscopy Italian Node/Multi-site Italian Node: advanced imaging, live cell, high-resolution.\n  - 84f2b05f:Digital Imaging Multimodal Platform Neuromed \u2013  DIMP NEUROMED/Integrated multimodal platform for neuroscience studies, high-res imaging.\n  - 4a6014b7:Molecular Imaging Italian Node/Italy's multi-site Node: in vivo imaging, diverse modalities, human pathology models.\n  - 7e7650ab:Phase Contrast Imaging Flagship Node Trieste/High-intensity phase contrast for soft tissue imaging, unique synchrotron source.\n\n**Netherlands (NL):**\n  - cf1ca682:Challenges Framework Flagship Node/Open-source platform for collaborative medical image analysis challenges.\n  - 0686d3f6:Correlative Light Microscopy Dutch Flagship Node/CLEM Node: Live-cell imaging, open access, multi-lab collaboration, Netherlands.\n  - 63c80f43:Dutch High Field Imaging Hub/Ultra-high field MRI: precision imaging for brain, spine, heart, and more.\n  - 30a92e22:Erasmus MC OIC - Advanced Light Microscopy Rotterdam Node/Quantitative live cell imaging, FRAP, FRET, high resolution, drug delivery.\n  - 9755d8f6:Facility of Multimodal Imaging - AMMI Maastricht/Multimodal imaging: light/electron microscopy, mass spectrometry, non-invasive.\n  - afb3789a:High Throughput Microscopy Dutch Flagship Node/Integrated Dutch Node: high-throughput, live-cell, advanced screening expertise.\n  - 42516efb:Population Imaging Flagship Node Rotterdam/Epidemiological imaging node: biomarkers, risk assessment, data analysis.\n  - d0390f02:Preclinical Imaging Centre (PRIME) - Molecular Imaging Dutch Node/Multi-modal small animal imaging, unique genetic models, advanced intravital microscopy.\n  - d0a2919a:The Van Leeuwenhoek Center for Advanced Microscopy (LCAM) - Functional Imaging Flagship Node Amsterdam/Amsterdam's LCAM: advanced live cell imaging, FRET, FCCS, FLIM expertise.\n  - 2bd802ed:Wageningen Imaging and Spectroscopy Hub (WISH) - ALM and Molecular Imaging Node Wageningen/Ultrafast fluorescence for in vivo plant photosynthesis studies.\n\n**Norway (NO):**\n  - 84bf85cf:NORMOLIM, Norwegian Molecular Imaging Infrastructure/In vivo molecular imaging for disease models, clinical research collaboration.\n  - 2e34e2e4:NorMIC Oslo - Advanced Light Microscopy Node Oslo/Live imaging, sub-cellular resolution, vesicle dynamics, cell interactions.\n\n**Poland (PL):**\n  - e8c5fe62:Advanced Light Microscopy Node Poland/Multi-modal imaging: super-resolution, CLEM, high-throughput, training.\n\n**Portugal (PT):**\n  - 89f8e8fc:Brain Imaging Network (BIN)/Open access PET/MR, neuroimaging focus, novel tracers, preclinical testing.\n  - d3a760f4:Portuguese Platform of BioImaging (PPBI)/Multi-site Euro-BioImaging Node: live cell, high-throughput, nano to meso.\n\n**Slovenia (SI):**\n  - fa7657e3:SiMBION Node/National consortium offering diverse bioimaging access, training, and support.\n\n**Spain (ES):**\n  - 9939c801:Barcelona Live and Intravital Node/Live-cell imaging, multi-modal techniques, high-resolution, in vivo support\n  - 6444b087:Barcelona Mesoscopic Imaging Node/Barcelona Node: LSFM for 50\u00b5m-5cm, live imaging, multiview, cellular resolution.\n  - b7b816dd:Barcelona Super-resolution Light and Nanoscopy Node/Multi-site bioimaging Node: super-resolution, custom analysis, training.\n  - c77f3a81:Population Imaging Valencia/AI-driven biomarkers, predictive models, structured image repositories\n\n**Sweden (SE):**\n  - a52d8c19:Swedish National Microscopy Infrastructure (NMI)/Distributed Swedish network: super-resolution, intravital, live imaging access.\n\n**United Kingdom (GB):**\n  - 59eb02aa:The UK Node/UK Node: Multi-site access to super-resolution, high-content, and correlative imaging.\n\n**Unknown (UN):**\n  - fb910032:No Node preference/Guidance for selecting optimal node and technology for projects\n\n**IMPORTANT**: Each entry in the indexes above follows the format `- ID: Name / Description`\n\n- For **Technologies**: `- tech_id: Technology Name/Brief description`\n- For **Nodes**: `- node_id: Node Name/Brief description` \n- For **Website Pages**: `- page_id: Page Title/Brief description`\n\nFor any matched topics, you can call the utility functions to get more details by the ID.\n\n**To use the utility functions**: Extract the ID (the part after the dash and before the colon) and pass it to the appropriate function:\n- Use `tech_id` with `read_tech_details(tech_id)`\n- Use `node_id` with `read_node_details(node_id)` \n- Use `page_id` with `read_website_page_details(page_id)`\n\nThese utilities are available under the current execution context, and no need to use await to call them. For example:\n\n```python\n# Example: Get details of a specific technology\ntech_details = read_tech_details(\"02e4459a\")\nprint(f\"Technology: {tech_details.name}\")\nprint(f\"Description: {tech_details.description}\")\n```\n\nImprtantly, they are not under api.* namespace, so you can call them directly.\n\n\n## \ud83d\udee0\ufe0f Available Utility Functions\n\n**IMPORTANT**: Call these functions directly - NO `await`, NO `api.` prefix, NO keyword arguments!\n\n### Detail Retrieval Functions\n- `read_tech_details(tech_id)` \u2192 `TechDetail(id, name, original_id, description, keywords, documentation, category, provider_node_ids, abbr)` or `None`\n- `read_node_details(node_id)` \u2192 `NodeDetail(id, name, original_id, description, keywords, documentation, country, offer_technology_ids)` or `None`  \n- `read_nodes_by_country(country_code)` \u2192 `List[NodeDetail(id, name, original_id, description, keywords, documentation, country, offer_technology_ids)]`\n- `read_website_page_details(page_id)` \u2192 `WebsitePageDetail(id, url, title, description, keywords, documentation, headings, page_type)` or `None`\nThe returned objects are pydantic models, so you can access the attributes directly. For example: tech_details.name, node_details.country['name'], etc.\n\n### Search Functions\n- `fulltext_search(query, k=5)` \u2192 `List[Dict]` (full-text search across all content types)\n- `get_country_codes()` \u2192 `Dict[str, str]` (country_name \u2192 ISO_code)\n\n\n## \u2705 Correct Function Call Examples\n\n```python\n# CORRECT: Get node details\nnode_details = read_node_details(\"48c78d41\")\nprint(f\"Node: {node_details.name}\")\nprint(f\"Country: {node_details.country['name']}\")\nprint(f\"Description: {node_details.description}\")\n\n# CORRECT: Get technology details  \ntech_details = read_tech_details(\"02e4459a\")\nprint(f\"Technology: {tech_details.name}\")\nprint(f\"Category: {tech_details.category['name']}\")\nprint(f\"Available at {len(tech_details.provider_node_ids)} nodes\")\n\n# CORRECT: Get all nodes in Germany\ngerman_nodes = read_nodes_by_country(\"DE\")\nfor node in german_nodes:\n    print(f\"Node: {node.name}\")\n    print(f\"Technologies: {len(node.offer_technology_ids)} available\")\n\n# CORRECT: Full-text search across all content\nresults = fulltext_search(\"super resolution microscopy\", k=5)\nfor result in results:\n    print(f\"Score: {result['score']:.2f} - Type: {result['type']} - Name: {result['name']}\")\n    print(f\"Description: {result['description']}\")\n```\n\n## \u274c WRONG Function Call Examples\n\n```python\n# WRONG: Don't use await\nnode_details = await read_node_details(\"48c78d41\")  # \u274c\n\n# WRONG: Don't use api prefix\nnode_details = api.read_node_details(\"48c78d41\")  # \u274c\n\n# WRONG: Don't use keyword arguments\nnode_details = read_node_details(node_id=\"48c78d41\")  # \u274c\n\n# WRONG: Don't combine await + api\nnode_details = await api.read_node_details(node_id=\"48c78d41\")  # \u274c\n```\n\n## \ud83e\udde0 How to Answer User Queries\n\nFollow this systematic approach:\n\n### 1. **Analyze the Query Type**\n- **Geographic queries** (e.g., \"facilities in Germany\"): Focus on specific countries/regions\n- **Technology queries** (e.g., \"super-resolution microscopy\"): Focus on specific techniques or instruments  \n- **General information** (e.g., \"how to access services\"): Focus on website pages and general guidance\n- **Listing queries** (e.g., \"all available nodes\"): Provide comprehensive listings\n\n### 2. **Select Relevant IDs**\nFrom the indexes above, identify the specific IDs you need by looking at the summaries:\n- **Technology IDs**: Look for relevant techniques in the technology list, extract the ID before the colon\n- **Node IDs**: Look for relevant facilities in the node list, extract the ID before the colon\n- **Country codes**: Use the ISO codes in parentheses (e.g., DE, SE, FR)\n- **Page IDs**: Look for relevant information pages, extract the ID before the colon\n\n**Example**: If you see `tech_super_res_microscopy: Super-Resolution Microscopy (available at 15 nodes)`, use `tech_super_res_microscopy` as the ID.\n\n### 3. **Retrieve Detailed Information**\nUse the utility functions systematically:\n\n**For Technology Queries:**\n```python\n# Example: \"Where can I find MINFLUX?\"\n# Step 1: Get the specific technology details\nminflux_details = read_tech_details(\"4bf1cfdd\")  # Extract ID from index\nprint(f\"Technology: {minflux_details.name}\")\n\n# Step 2: Get nodes where it's available (don't list all their technologies)\nfor node_id in minflux_details.provider_node_ids:\n    node_details = read_node_details(node_id)\n    print(f\"Available at: {node_details.name} in {node_details.country['name']}\")\n```\n\n**For Geographic Queries:**\n```python\n# Example: \"What imaging facilities are in Germany?\"\ncountry_nodes = read_nodes_by_country(\"DE\")  # Germany\nfor node in country_nodes:\n    print(f\"Node: {node.name}\")\n    print(f\"Description: {node.description}\")\n    print(f\"Technologies available: {len(node.offer_technology_ids)} total\")\n    # Only list technologies if specifically asked, don't retrieve all details\n```\n\n**For General Full-text Search:**\n```python\n# Use full-text search to find relevant content\nresults = fulltext_search(\"access services application\", k=5)\nfor result in results:\n    if result['type'] == 'page':\n        page_details = read_website_page_details(result['id'])\n        print(f\"Page: {page_details.title}\")\n        print(f\"URL: {page_details.url}\")\n        print(f\"Description: {page_details.description}\")\n```\n\n```python\n# Example: \"Find super-resolution microscopy techniques\"\nresults = fulltext_search(\"super resolution microscopy\", k=3)\nfor result in results:\n    if result['type'] == 'tech':\n        print(f\"Technology: {result['name']} (Score: {result['score']:.2f})\")\n        print(f\"Description: {result['description']}\")\n        # Get provider nodes if needed\n        tech_details = read_tech_details(result['id'])\n        for node_id in tech_details.provider_node_ids:\n            node_details = read_node_details(node_id)\n            print(f\"  Available at: {node_details.name} in {node_details.country['name']}\")\n```\n\n### 4. **Be Focused and Efficient**\n- Only retrieve information that directly answers the user's question\n- Don't list all technologies at a node unless specifically asked\n- Don't retrieve all details unless needed for the specific query\n- Answer the question, don't provide unnecessary comprehensive listings\n\n### 5. **Reason Across Results**\n- Integrate information from multiple search results if needed\n- Draw conclusions, extract availability details, instrument capabilities, node locations, and relevant contact information\n\n### 6. **Respond Factually and Comprehensively**\n- Ensure your final reply contains all key findings and actionable information\n- Always include all relevant details in your final answer, the intermediate script output won't be seen by the user\n- Avoid vague summaries\u2014be precise and specific based on the returned context\n\n## \ud83d\udccb Query Pattern Examples\n\n**Geographic Query**: \"What imaging facilities are available in Germany?\"\n1. Use `read_nodes_by_country(\"DE\")` to get all German nodes\n2. For each node, use `read_node_details()` to get full information\n3. For each technology at the nodes, use `read_tech_details()` to understand capabilities\n\n**Technology Query**: \"Where can I access super-resolution microscopy?\"\n1. Use `fulltext_search(\"super resolution microscopy\", k=3)` to find relevant technologies and nodes\n2. Filter results by type to focus on technologies and nodes\n3. Use `read_tech_details()` and `read_node_details()` to get detailed information\n\n**General Information**: \"How do I access Euro-BioImaging services?\"\n1. Use `fulltext_search(\"access services application procedures\", k=3)` to find relevant content\n2. Filter results for website pages that contain access information\n3. Use `read_website_page_details()` for each relevant page to get detailed information\n\n## \ud83c\udfaf Response Quality Guidelines\n0. When generating the thoughts, limit each thought to 5 words maximum.\n1. **Use the indexes above** to identify relevant resources by their summaries\n2. **Extract IDs correctly** (the part before the colon) from the index entries\n3. **Call functions directly** without await, api prefix, or keyword arguments\n4. **Be systematic** in retrieving details for all relevant items\n5. **Include geographic context** (country names and codes)\n6. **Provide comprehensive information** which corresponds to the user query, try to be helpful and comprehensive.\n7. Since we are targeting non-technical users, unless asked, you can generate and execute scripts, but no need to commit code during the final response.\n\nRemember: Scan the indexes for relevant entries, extract the correct IDs, then call the utility functions directly to get detailed information.\n\n",
                            "attrs": {
                              "className": "output-area"
                            }
                          }
                        ],
                        "executionCount": 55
                      }
                    ]
                  },
                  "_security": {
                    "sanitized": true,
                    "sanitizedAt": "2025-06-29T18:56:59.703Z",
                    "version": "1.0",
                    "note": "All API keys and sensitive data have been automatically removed"
                  }
                }
              }
            },
            "cells": [
              {
                "id": "9044a6d4-58e5-4b7a-905a-fe60777a9891",
                "type": "code",
                "content": "import micropip\nawait micropip.install([\"httpx\", \"pydantic\", \"bm25s\"])\n\nimport httpx\nfrom typing import Dict, List, Any, Optional, Tuple\nfrom pydantic import BaseModel\nimport bm25s\nfrom pathlib import Path\nimport tempfile\nimport micropip\nimport pickle\n\nclass TechDetail(BaseModel):\n    \"\"\"Details of a specific technology\"\"\"\n    id: str\n    name: str\n    original_id: str\n    description: str\n    documentation: str\n    category: Dict[str, Any]\n    provider_node_ids: List[str]\n    abbr: str\n\nclass NodeDetail(BaseModel):\n    \"\"\"Details of a specific node\"\"\"\n    id: str\n    name: str\n    original_id: str\n    description: str\n    documentation: str\n    country: Dict[str, Any]\n    offer_technology_ids: List[str]\n\nclass WebsitePageDetail(BaseModel):\n    \"\"\"Details of a Euro-BioImaging website page\"\"\"\n    id: str\n    url: str\n    title: str\n    description: str\n    documentation: str\n    headings: List[str]\n    page_type: str\n\nclass SearchResponse(BaseModel):\n    \"\"\"Structured search response\"\"\"\n    answer: str\n    relevant_technologies: List[str] = []\n    relevant_nodes: List[str] = []\n    relevant_pages: List[str] = []\n    summary: str = \"\"\n\n# Global data storage\ntech_data: List[Dict[str, Any]] = []\nnodes_data: List[Dict[str, Any]] = []\nwebsite_data: List[Dict[str, Any]] = []\nbm25_retriever = None\nbm25_metadata = None\n\nasync def load_eurobioimaging_data():\n    \"\"\"\n    Load Euro-BioImaging data from remote index file.\n    This function fetches the combined index from the remote URL and populates the global data structures.\n    \n    Returns:\n    - dict: Metadata about the loaded dataset including counts and creation info\n    \"\"\"\n    global tech_data, nodes_data, website_data, bm25_retriever, bm25_metadata\n    \n    base_url = \"https://oeway.github.io/euro-bioimaging-finder\"\n    \n    try:\n        async with httpx.AsyncClient(timeout=30.0) as client:\n            # Load main index\n            response = await client.get(f\"{base_url}/eurobioimaging_index.json\")\n            response.raise_for_status()\n            combined_data = response.json()\n            \n            # Extract data from combined index\n            tech_data = combined_data.get('technologies', [])\n            nodes_data = combined_data.get('nodes', [])\n            website_data = combined_data.get('website_pages', [])\n            bm25_metadata = combined_data.get('bm25_metadata', [])\n            \n            # Download and load BM25 pickle file\n            bm25_response = await client.get(f\"{base_url}/eurobioimaging_bm25_index.pkl\")\n            bm25_response.raise_for_status()\n            \n            # Save to temp file and load\n            with tempfile.NamedTemporaryFile(suffix='.pkl', delete=False) as temp_file:\n                temp_file.write(bm25_response.content)\n                temp_file.flush()\n                \n                with open(temp_file.name, 'rb') as f:\n                    bm25_retriever = pickle.load(f)\n            \n            # Get metadata\n            metadata = combined_data.get('metadata', {})\n            dataset_info = {\n                'dataset_type': metadata.get('dataset_type', 'unknown'),\n                'created_at': metadata.get('created_at', 'unknown'),\n                'technologies_count': len(tech_data),\n                'nodes_count': len(nodes_data),\n                'website_pages_count': len(website_data),\n                'total_entries': len(tech_data) + len(nodes_data) + len(website_data),\n                'bm25_documents': len(bm25_metadata) if bm25_metadata else 0\n            }\n            \n            return dataset_info\n            \n    except Exception as e:\n        print(f\"Error loading data: {e}\")\n        tech_data = []\n        nodes_data = []\n        website_data = []\n        bm25_retriever = None\n        bm25_metadata = None\n        raise e\n\ndef read_tech_details(tech_id: str):\n    \"\"\"\n    Read details of a specific technology by ID.\n    \n    Parameters:\n    - tech_id (str): The technology ID\n    \n    Returns:\n    - Optional[TechDetail]: Technology details or None if not found\n    \"\"\"\n    for tech in tech_data:\n        if tech['id'] == tech_id:\n            return TechDetail(**tech)\n    raise Exception(f\"Technology with ID {tech_id} not found\")\n\ndef read_node_details(node_id: str):\n    \"\"\"\n    Read details of a specific node by ID.\n    \n    Parameters:\n    - node_id (str): The node ID\n    \n    Returns:\n    - Optional[NodeDetail]: Node details or None if not found\n    \"\"\"\n    for node in nodes_data:\n        if node['id'] == node_id:\n            return NodeDetail(**node)\n    raise Exception(f\"Node with ID {node_id} not found\")\n\ndef read_nodes_by_country(country_code: str):\n    \"\"\"\n    Read all nodes in a specific country by ISO country code.\n    \n    Parameters:\n    - country_code (str): ISO country code (e.g., 'PL', 'SE', 'DE')\n    \n    Returns:\n    - List[NodeDetail]: List of all nodes in the specified country\n    \"\"\"\n    country_nodes = []\n    for node in nodes_data:\n        node_country = node.get('country', {})\n        if node_country.get('iso_a2', '').upper() == country_code.upper():\n            try:\n                country_nodes.append(NodeDetail(**node))\n            except Exception as e:\n                print(f\"Warning: Could not parse node {node.get('name', 'Unknown')}: {e}\")\n    return country_nodes\n\ndef read_website_page_details(page_id: str):\n    \"\"\"\n    Read details of a specific website page by ID.\n    \n    Parameters:\n    - page_id (str): The website page ID\n    \n    Returns:\n    - Optional[WebsitePageDetail]: Website page details or None if not found\n    \"\"\"\n    for page in website_data:\n        if page['id'] == page_id:\n            return WebsitePageDetail(**page)\n    raise Exception(f\"Website page with ID {page_id} not found\")\n\ndef get_country_codes():\n    \"\"\"\n    Get mapping of country names to ISO codes from the data.\n    \n    Returns:\n    - Dict[str, str]: Mapping of country names to ISO codes\n    \"\"\"\n    country_mapping = {}\n    for node in nodes_data:\n        country = node.get('country', {})\n        country_name = country.get('name', '')\n        country_code = country.get('iso_a2', '')\n        if country_name and country_code:\n            country_mapping[country_name.lower()] = country_code.upper()\n    return country_mapping\n\ndef create_search_prompt():\n    \"\"\"Create the search prompt with all available data indexes\"\"\"\n    \n    def truncate_line(line: str, max_length: int = 256) -> str:\n        \"\"\"Truncate line to max_length, preserving the format\"\"\"\n        if len(line) <= max_length:\n            return line\n        return line[:max_length-3] + \"...\"\n    \n    # Create technology index with \"- id: name / description\" format\n    tech_index = []\n    for tech in tech_data:\n        name = tech.get('name', '')\n        description = tech.get('description', '').replace('\\n', ' ').strip()\n        line = f\"- {tech['id']}:{name}/{description}\"\n        tech_index.append(truncate_line(line))\n    \n    # Create nodes index with \"- id:name/description\" format, grouped by country\n    nodes_by_country = {}\n    country_codes_info = {}\n    for node in nodes_data:\n        country = node['country']['name']\n        country_code = node['country'].get('iso_a2', 'XX')\n        if country not in nodes_by_country:\n            nodes_by_country[country] = []\n            country_codes_info[country] = country_code\n        \n        name = node.get('name', '')\n        description = node.get('description', '').replace('\\n', ' ').strip()\n        line = f\"- {node['id']}:{name}/{description}\"\n        nodes_by_country[country].append(truncate_line(line))\n    \n    nodes_index = []\n    for country, country_nodes in sorted(nodes_by_country.items()):\n        country_code = country_codes_info[country]\n        nodes_index.append(f\"\\n**{country} ({country_code}):**\")\n        nodes_index.extend([f\"  {node}\" for node in country_nodes])\n    \n    # Create website pages index with \"- id: title / description\" format\n    website_index = []\n    for page in website_data:\n        title = page.get('title', '')\n        description = page.get('description', '').replace('\\n', ' ').strip()\n        line = f\"- {page['id']}:{title}/{description}\"\n        website_index.append(truncate_line(line))\n    \n    prompt = f\"\"\"\nHere is a list of all the available resources associated with their IDs.\n\n## Available General Website Pages:\n{chr(10).join(website_index)}\n\n## Available Technologies: \n{chr(10).join(tech_index)}\n\n## Available Nodes by Country (with ISO codes):\n{chr(10).join(nodes_index)}\n\n**IMPORTANT**: Each entry in the indexes above follows the format `- ID: Name / Description`\n\n- For **Technologies**: `- tech_id: Technology Name/Brief description`\n- For **Nodes**: `- node_id: Node Name/Brief description` \n- For **Website Pages**: `- page_id: Page Title/Brief description`\n\nFor any matched topics, you can call the utility functions to get more details by the ID.\n\n**To use the utility functions**: Extract the ID (the part after the dash and before the colon) and pass it to the appropriate function:\n- Use `tech_id` with `read_tech_details(tech_id)`\n- Use `node_id` with `read_node_details(node_id)` \n- Use `page_id` with `read_website_page_details(page_id)`\n\nThese utilities are available under the current execution context, and no need to use await to call them. For example:\n\n```python\n# Example: Get details of a specific technology\ntech_details = read_tech_details(\"02e4459a\")\nprint(f\"Technology: {{tech_details.name}}\")\nprint(f\"Description: {{tech_details.description}}\")\n```\n\nImprtantly, they are not under api.* namespace, so you can call them directly.\n\n\"\"\"\n\n    return prompt\n\ndef fulltext_search(query: str, k: int = 5) -> List[Dict[str, Any]]:\n    \"\"\"\n    Perform full-text search using BM25 index\n    \n    Parameters:\n    - query (str): The search query\n    - k (int): Number of results to return (default: 5)\n    \n    Returns:\n    - List[Dict]: List of matching documents with metadata\n    \"\"\"\n    if not bm25_retriever or not bm25_metadata:\n        raise Exception(\"Error: BM25 index not loaded\")\n    \n    # Tokenize query\n    query_tokens = bm25s.tokenize(query)\n    \n    # Get results\n    results, scores = bm25_retriever.retrieve(query_tokens, k=k)\n    \n    # Format results\n    search_results = []\n    for i in range(results.shape[1]):\n        doc_idx = results[0, i]\n        score = scores[0, i]\n        \n        # Get metadata for the document\n        metadata = bm25_metadata[doc_idx]\n        doc_type = metadata['type']\n        doc_id = metadata['id']\n        \n        # Get full details based on type\n        if doc_type == 'tech':\n            details = read_tech_details(doc_id)\n            if details:\n                search_results.append({\n                    'type': doc_type,\n                    'id': doc_id,\n                    'name': details.name,\n                    'description': details.description,\n                    'score': float(score),\n                    'documentation': details.documentation,\n                    'category': details.category,\n                    'provider_node_ids': details.provider_node_ids,\n                })\n        elif doc_type == 'node':\n            details = read_node_details(doc_id)\n            if details:\n                search_results.append({\n                    'type': doc_type,\n                    'id': doc_id,\n                    'name': details.name,\n                    'description': details.description,\n                    'score': float(score),\n                    'documentation': details.documentation,\n                    'country': details.country,\n                    'offer_technology_ids': details.offer_technology_ids,\n                })\n        elif doc_type == 'page':\n            details = read_website_page_details(doc_id)\n            if details:\n                search_results.append({\n                    'type': doc_type,\n                    'id': doc_id,\n                    'name': details.title,\n                    'description': details.description,\n                    'score': float(score),\n                    'url': details.url,\n                    'documentation': details.documentation,\n                    'headings': details.headings,\n                    'page_type': details.page_type,\n                })\n    \n    return search_results\n\n# Initialize data and create the search prompt\ndata_loaded = await load_eurobioimaging_data()\n\nif not data_loaded:\n    print(\"WARNING: \u274c Failed to load Euro-BioImaging data, none of the following functions will work properly.\")\n\nprint(\"\"\"\nYou are an AI assistant specialized in helping users discover imaging technologies, instruments, and services provided by the Euro-BioImaging network.\nYou have access to several utility functions for retrieving specific information about Euro-BioImaging facilities. Below are all the available resources in the Euro-BioImaging network:\n\"\"\")\n\n# Print the search context with all available data\nsearch_context = create_search_prompt()\nprint(search_context)\n\n# The printed text will be used for the LLM agent as prompt.\nprint(\"\"\"## \ud83d\udee0\ufe0f Available Utility Functions\n\n**IMPORTANT**: Call these functions directly - NO `await`, NO `api.` prefix, NO keyword arguments!\n\n### Detail Retrieval Functions\n- `read_tech_details(tech_id)` \u2192 `TechDetail(id, name, original_id, description, documentation, category, provider_node_ids, abbr)` or `None`\n- `read_node_details(node_id)` \u2192 `NodeDetail(id, name, original_id, description, documentation, country, offer_technology_ids)` or `None`  \n- `read_nodes_by_country(country_code)` \u2192 `List[NodeDetail(id, name, original_id, description, documentation, country, offer_technology_ids)]`\n- `read_website_page_details(page_id)` \u2192 `WebsitePageDetail(id, url, title, description, documentation, headings, page_type)` or `None`\nThe returned objects are pydantic models, so you can access the attributes directly. For example: tech_details.name, node_details.country['name'], etc.\n\n### Search Functions\n- `fulltext_search(query, k=5)` \u2192 `List[Dict]` (full-text search across all content types)\n- `get_country_codes()` \u2192 `Dict[str, str]` (country_name \u2192 ISO_code)\n\n\n## \u2705 Correct Function Call Examples\n\n```python\n# CORRECT: Get node details\nnode_details = read_node_details(\"48c78d41\")\nprint(f\"Node: {node_details.name}\")\nprint(f\"Country: {node_details.country['name']}\")\nprint(f\"Description: {node_details.description}\")\n\n# CORRECT: Get technology details  \ntech_details = read_tech_details(\"02e4459a\")\nprint(f\"Technology: {tech_details.name}\")\nprint(f\"Category: {tech_details.category['name']}\")\nprint(f\"Available at {len(tech_details.provider_node_ids)} nodes\")\n\n# CORRECT: Get all nodes in Germany\ngerman_nodes = read_nodes_by_country(\"DE\")\nfor node in german_nodes:\n    print(f\"Node: {node.name}\")\n    print(f\"Technologies: {len(node.offer_technology_ids)} available\")\n\n# CORRECT: Full-text search across all content\nresults = fulltext_search(\"super resolution microscopy\", k=5)\nfor result in results:\n    print(f\"Score: {result['score']:.2f} - Type: {result['type']} - Name: {result['name']}\")\n    print(f\"Description: {result['description']}\")\n```\n\n## \u274c WRONG Function Call Examples\n\n```python\n# WRONG: Don't use await\nnode_details = await read_node_details(\"48c78d41\")  # \u274c\n\n# WRONG: Don't use api prefix\nnode_details = api.read_node_details(\"48c78d41\")  # \u274c\n\n# WRONG: Don't use keyword arguments\nnode_details = read_node_details(node_id=\"48c78d41\")  # \u274c\n\n# WRONG: Don't combine await + api\nnode_details = await api.read_node_details(node_id=\"48c78d41\")  # \u274c\n```\n\n## \ud83e\udde0 How to Answer User Queries\n\nFollow this systematic approach:\n\n### 1. **Analyze the Query Type**\n- **Geographic queries** (e.g., \"facilities in Germany\"): Focus on specific countries/regions\n- **Technology queries** (e.g., \"super-resolution microscopy\"): Focus on specific techniques or instruments  \n- **General information** (e.g., \"how to access services\"): Focus on website pages and general guidance\n- **Listing queries** (e.g., \"all available nodes\"): Provide comprehensive listings\n\n### 2. **Select Relevant IDs**\nFrom the indexes above, identify the specific IDs you need by looking at the summaries:\n- **Technology IDs**: Look for relevant techniques in the technology list, extract the ID before the colon\n- **Node IDs**: Look for relevant facilities in the node list, extract the ID before the colon\n- **Country codes**: Use the ISO codes in parentheses (e.g., DE, SE, FR)\n- **Page IDs**: Look for relevant information pages, extract the ID before the colon\n\n**Example**: If you see `tech_super_res_microscopy: Super-Resolution Microscopy (available at 15 nodes)`, use `tech_super_res_microscopy` as the ID.\n\n### 3. **Retrieve Detailed Information**\nUse the utility functions systematically:\n\n**For Technology Queries:**\n```python\n# Example: \"Where can I find MINFLUX?\"\n# Step 1: Get the specific technology details\nminflux_details = read_tech_details(\"4bf1cfdd\")  # Extract ID from index\nprint(f\"Technology: {minflux_details.name}\")\n\n# Step 2: Get nodes where it's available (don't list all their technologies)\nfor node_id in minflux_details.provider_node_ids:\n    node_details = read_node_details(node_id)\n    print(f\"Available at: {node_details.name} in {node_details.country['name']}\")\n```\n\n**For Geographic Queries:**\n```python\n# Example: \"What imaging facilities are in Germany?\"\ncountry_nodes = read_nodes_by_country(\"DE\")  # Germany\nfor node in country_nodes:\n    print(f\"Node: {node.name}\")\n    print(f\"Description: {node.description}\")\n    print(f\"Technologies available: {len(node.offer_technology_ids)} total\")\n    # Only list technologies if specifically asked, don't retrieve all details\n```\n\n**For General Full-text Search:**\n```python\n# Use full-text search to find relevant content\nresults = fulltext_search(\"access services application\", k=5)\nfor result in results:\n    if result['type'] == 'page':\n        page_details = read_website_page_details(result['id'])\n        print(f\"Page: {page_details.title}\")\n        print(f\"URL: {page_details.url}\")\n        print(f\"Description: {page_details.description}\")\n```\n\n```python\n# Example: \"Find super-resolution microscopy techniques\"\nresults = fulltext_search(\"super resolution microscopy\", k=3)\nfor result in results:\n    if result['type'] == 'tech':\n        print(f\"Technology: {result['name']} (Score: {result['score']:.2f})\")\n        print(f\"Description: {result['description']}\")\n        # Get provider nodes if needed\n        tech_details = read_tech_details(result['id'])\n        for node_id in tech_details.provider_node_ids:\n            node_details = read_node_details(node_id)\n            print(f\"  Available at: {node_details.name} in {node_details.country['name']}\")\n```\n\n### 4. **Be Focused and Efficient**\n- Only retrieve information that directly answers the user's question\n- Don't list all technologies at a node unless specifically asked\n- Don't retrieve all details unless needed for the specific query\n- Answer the question, don't provide unnecessary comprehensive listings\n\n### 5. **Reason Across Results**\n- Integrate information from multiple search results if needed\n- Draw conclusions, extract availability details, instrument capabilities, node locations, and relevant contact information\n\n### 6. **Handle AI-Enhanced Content Transparently**\n- **Check for AI enhancement markers** in technology documentation:\n  - Look for \"## AI Generated Documentation\" sections\n  - Look for \"## References\" sections with sources\n- **When using AI-enhanced content**:\n  - Mention that information is AI-enhanced: \"Based on AI-enhanced documentation...\"\n  - Cite sources from References sections: \"According to sources including [source name](url)...\"\n\n### 7. **Respond Factually and Comprehensively**\n- Ensure your final reply contains all key findings and actionable information\n- Always include all relevant details in your final answer, the intermediate script output won't be seen by the user\n- Avoid vague summaries\u2014be precise and specific based on the returned context\n- **Be transparent about information sources** throughout your response\n\n## \ud83d\udccb Query Pattern Examples\n\n**Geographic Query**: \"What imaging facilities are available in Germany?\"\n1. Use `read_nodes_by_country(\"DE\")` to get all German nodes\n2. For each node, use `read_node_details()` to get full information\n3. For each technology at the nodes, use `read_tech_details()` to understand capabilities\n\n**Technology Query**: \"Where can I access super-resolution microscopy?\"\n1. Use `fulltext_search(\"super resolution microscopy\", k=3)` to find relevant technologies and nodes\n2. Filter results by type to focus on technologies and nodes\n3. Use `read_tech_details()` and `read_node_details()` to get detailed information\n\n**General Information**: \"How do I access Euro-BioImaging services?\"\n1. Use `fulltext_search(\"access services application procedures\", k=3)` to find relevant content\n2. Filter results for website pages that contain access information\n3. Use `read_website_page_details()` for each relevant page to get detailed information\n\n## \ud83c\udfaf Response Quality Guidelines\n0. When generating the thoughts, limit each thought to 5 words maximum.\n1. **Use the indexes above** to identify relevant resources by their summaries\n2. **Extract IDs correctly** (the part before the colon) from the index entries\n3. **Call functions directly** without await, api prefix, or keyword arguments\n4. **Be systematic** in retrieving details for all relevant items\n5. **Include geographic context** (country names and codes)\n6. **Provide comprehensive information** which corresponds to the user query, try to be helpful and comprehensive.\n7. Since we are targeting non-technical users, unless asked, you can generate and execute scripts, but no need to commit code during the final response.\n\nRemember: Scan the indexes for relevant entries, extract the correct IDs, then call the utility functions directly to get detailed information.\n\"\"\") \n",
                "executionState": "success",
                "role": "system",
                "metadata": {
                  "collapsed": false,
                  "trusted": true,
                  "isNew": true,
                  "isEditing": false,
                  "isCodeVisible": false,
                  "isOutputVisible": true,
                  "parent": null,
                  "userModified": true,
                  "hasOutput": true
                },
                "output": [
                  {
                    "type": "stdout",
                    "content": "\nYou are an AI assistant specialized in helping users discover imaging technologies, instruments, and services provided by the Euro-BioImaging network.\nYou have access to several utility functions for retrieving specific information about Euro-BioImaging facilities. Below are all the available resources in the Euro-BioImaging network:\n\n\nHere is a list of all the available resources associated with their IDs.\n\n## Available General Website Pages:\n- b5de18fa:Euro-BioImaging/Access imaging technologies, expert training, data services across 41 Nodes in Europe.\n- 49348cd7:Image data events - Euro-BioImaging/Events on image data management, FAIR principles, and innovative solutions for researchers.\n- 2624ded3:SME and Industry Access - Euro-BioImaging/Access 240+ imaging facilities, 120+ technologies, expert consultations, competitive pricing.\n- 405363bb:News - Euro-BioImaging/Updates on imaging projects, job openings, AI events, and new imaging techniques.\n- ea1e2fc2:Funding - Euro-BioImaging/Funding for researchers, including i4A, canSERV, AgroServ; application details available.\n- 43a17e65:FEBS Congress 2025 - Euro-BioImaging/49th FEBS Congress, Istanbul, July 5-9, 2025; poster sessions, bursary for early-career researchers.\n- 171032e0:Tech Exchange webinar for companies - Euro-BioImaging/Monthly Tech Exchange webinars for imaging tech; register for updates and presentations.\n- a7f92ac1:Our Team - Euro-BioImaging/Team roles, contact info, training management, legal services, imaging tools development.\n- 6013fa00:Conferences - Euro-BioImaging/Upcoming conferences: mmc 2025, FEBS, Immunology Congress, SPAOM 2025; contact for more info.\n- 8c85202b:How companies can engage with us - Euro-BioImaging/Access 120+ imaging technologies, expert consultations, industry board, and collaboration opportunities.\n- 8bc4f0d5:Mentoring - Euro-BioImaging/Mentoring Program: Apply for peer support in career development, data management, and soft skills.\n- 58f7e252:EU Project CANDLE starts building National Cancer Data Nodes - Euro-BioImaging/CANDLE project builds EU cancer data nodes, enhancing research and data sharing.\n- 8a985e6c:Data services - Euro-BioImaging/Image Data Services, IDA, FAIR support, technical assistance, community initiatives.\n- 5eaeed05:Our events - Euro-BioImaging/Events: All Hands Nodes Meeting, User Forum, Tech Exchange, image data events.\n- 141899a8:Cross-Node Job Shadowing - Euro-BioImaging/Job shadowing program details: application deadlines, funding, training plans, contact info.\n- cf5eaec8:Contact us - Euro-BioImaging/Contact info, virtual meetings, newsletter sign-up for bioimaging updates.\n- c0c28a84:Euro-BioImaging Training Courses - Euro-BioImaging/Training for Node staff: skills, financial support, Train-the-Trainer course details.\n- 1fe54112:Special Edition Virtual Pubs - Euro-BioImaging/Special Edition Virtual Pubs on imaging tech, applications in research, and collaboration opportunities.\n- 554ab121:ISCaM Annual Meeting - Euro-BioImaging/ISCaM2025: July 2-4, 2025, Brussels; focus on tumor metabolism, networking, and presentations.\n- 8da7c083:Community services - Euro-BioImaging/FAIR data services, technical support, training, tools, and community coordination.\n- 56d1794d:Training for Node Staff - Euro-BioImaging/Training for Node staff under EVOLVE project; focuses on skill development and service quality.\n- ec39fc98:User Forum - Euro-BioImaging/User Forum events on imaging in immunology, plant biology, and cardiovascular research.\n- 41a3855d:EU projects - Euro-BioImaging/Details on 12 EU projects enhancing imaging, AI, and data access in life sciences.\n- f59cac35:Upcoming events - Euro-BioImaging/Events: Training, meetings, virtual pubs on imaging, cancer metabolism, and more.\n- a0f8dc59:EVOLVE News - Euro-BioImaging/News on training, job openings, mentoring masterclasses, and Node participation calls.\n- 1d6a8109:Strategic Goals - Euro-BioImaging/Strategic goals for 2024-2028: imaging services, FAIR data, training, stakeholder engagement.\n- d86b29a7:Governance - Euro-BioImaging/Governance structure, 41 Nodes, 192 imaging facilities, contact for membership queries.\n- 0b3d4d4a:Sponsorship Programme - Euro-BioImaging/Sponsorship for events enhancing biomedical imaging; application link included.\n- d31aa4c2:Documents - Euro-BioImaging/Access annual reports, equality plan, statutes, strategic plan, and policies.\n- b6dde532:FAQ - Euro-BioImaging/Access imaging technologies, training, proposal submission, contact info for assistance.\n- 3d22f118:Who are we? - Euro-BioImaging/Access cutting-edge imaging services, training, and support across Europe.\n- 70d0fdd6:Our Node list per member state - Euro-BioImaging/41 renowned imaging nodes across Europe with diverse services and training opportunities.\n- ce0faa17:From our Nodes - Euro-BioImaging/Training in imaging tech, sample prep, data analysis; courses taught in English, remote options.\n- 7006b8fe:The Four Seasons of the Invisible - Euro-BioImaging/Imaging contest details: eligibility, submission rules, quarterly sessions, prizes up to \u20ac1000.\n- b2a39ac1:EVOLVE Job Shadowing series - Euro-BioImaging/Job shadowing insights, Node collaborations, imaging advancements, and unique experiences shared.\n- 9d522de2:Master\u2019s programmes - Euro-BioImaging/MSc programs in imaging, internships, contacts for Cell Biology, Imaging, and Biomedical Imaging.\n- bb43378b:Partners - Euro-BioImaging/Details on partner infrastructures, access to resources, and global collaboration contacts.\n- 71450ac0:User services - Euro-BioImaging/Image Data Analysis services, access steps, Node connections, contact info.\n- a0c9bd9e:Technologies - Euro-BioImaging/Access to advanced imaging tech: cryo-EM, light microscopy, multimodal imaging for research.\n- cad295ba:EVOLVE - Euro-BioImaging/Opportunities: job shadowing, training, mentoring; focus on Open Science data services.\n- 98dd78d0:Euro-BioImaging Industry Board members/Membership offers access to imaging facilities, networking, and funding insights.\n- f9b8978e:Scientific Ambassadors - Euro-BioImaging/Join as a Scientific Ambassador for training, networking, travel grants, and advocacy materials.\n- 352d7b66:How to access - Euro-BioImaging/Access procedures, expert consultations, proposal requests, and contact info for imaging services.\n- 3cb9f1e9:Technology validation at Euro-BioImaging Nodes/Validation services, 240+ imaging facilities, EP PerMed funding up to \u20ac80,000.\n- 794e897b:FAIR image data - Euro-BioImaging/FAIR data training, resources, 1-on-1 guidance, contact fairdata@eurobioimaging.eu.\n- 7cc0db67:AgroSERV\u2019s 4th call for access is open - Euro-BioImaging/Funding for agroecology projects; apply by Oct 15, 2025; contact agroservprojects@eurobioimaging.eu.\n- 5a24f1ad:New technologies - Euro-BioImaging/Details on showcasing, proof-of-concept, and new imaging technologies access.\n- bf0d07e1:Euro-BioImaging Industry Board activities/Tech Exchange webinars, Board meetings, industry events, and new member announcements.\n- 265320da:Global BioImaging - Euro-BioImaging/Global BioImaging offers international workshops, training, and support for imaging facilities.\n- fd91e441:Research infrastructures - Euro-BioImaging/Access to biobanks, imaging, ELIXIR, EU-OPENSCREEN, Instruct-ERIC services and collaborations.\n\n## Available Technologies: \n- 73094724:3D Correlative Light and Electron Microscopy (3D-CLEM)*/In 3D CLEM, 3D or volume EM methods are combined with 3D light microscopy techniques. Registration between the modalities has to be done in all 3 dimensions, making 3D CLEM a challenging...\n- f68070c5:4Pi microscopy/Dual-objective microscopy achieving 100nm resolution for live-cell imaging.\n- b015d920:Anisotropy/Polarization Microscopy (AM)/Biomolecular interactions and conformational changes, both in vivo and in vitro, can be followed by fluorescence polarization/anisotropy imaging, which uses polarized excitation and polarization sensiti...\n- 63775639:Array tomography (AT)/Many biological functions depend critically upon fine details of tissue\u2019s molecular architecture that have resisted exploration by existing imaging techniques. Array tomography (AT) encompasses electron microscopy modali...\n- a9f0fcad:Atomic Force Microscopy (AFM)*/Atomic Force Microscopy (AFM) is a technique allowing the characterization of sample morphology at nanoscale. Images are acquired by raster scanning a nanometric tip in gentle contact or intermittent contact wit...\n- eeee8c89:Brillouin Scattering Microscopy (BSM) */Non-invasive, label-free imaging of mechanical properties at sub-cellular resolution.\n- 89bab6f3:Challenges Framework/Multimodal imaging integration, advanced algorithms, 3D fusion, cancer diagnostics.\n- 53fc2771:Coherent Anti-Stokes Raman Scattering microscopy (CARS)*/Label-free, high-resolution vibrational imaging for live cells and tissues.\n- 6709f67e:Correlated Optical Coherence Tomography/PhotoAcoustic Tomography (OCT/PAT)/Multimodal imaging: OCT/PAT combines high-res structural and functional insights.\n- 8597af30:Correlative Array Tomography (CAT)/Many biological functions depend critically upon fine details of tissue\u2019s molecular architecture that have resisted exploration by existing imaging techniques. Array tomography (AT) encompasses light and ele...\n- 59bcd971:Correlative X-ray and EM (CXEM)*/In correlative X-ray and EM, X-ray imaging can be used to gain insights into the structure and position of the sample inside the resin block, as prepared for EM. This allows for more precise targeting of the s...\n- 593e3440:Cryo Correlative Light and Electron Microscopy (Cryo-CLEM)*/Cryo-CLEM combines cryo-fixation and cryo-fluorescence microscopy with subsequent cryo-FIB, cryo-TEM, cryo-SEM, or cryo-ET. Alternatively after cryo-fluorescence microscopy samples c...\n- a7128dd1:Cryo Electron Tomography (Cryo-ET)*/Cryo-electron tomography (cryoET) is a specialized transmission electron microscopy technique in which samples are tilted and imaged under cryogenic conditions, resulting in a series of 2D images that can b...\n- 4b452472:Cryo Focussed Ion beam (Cryo-FIB)*/Cryo-electron tomography of structures inside thick cells requires the preparation of thin lamella, which are thin enough to be used in cryoET. Cryo-FIB milling is the method of choice to prepare these lamel...\n- 904149e2:Cryo Scanning Electron Microscopy (Cryo-SEM)*/Cryo-SEM is an excellent technique for imaging of liquid and semi-liquid  materials surfaces, hydrated biological specimens (e.g. biofilms, extracellular  matrix, hyphae, etc.) in close-to native ...\n- cb003121:Cryo Transmission Electron Microscopy* (Cryo-TEM)/This is transmission electron microscopy performed under cryogenic conditions on cryo-preserved samples. It can be used to determine the structure of protein and viruses to atomic resolution.\n- 60f50c0f:Cryo fluorescence microscopy (CryoFM)/CryoFM enables high-resolution imaging of vitrified samples at sub-200nm.\n- 7cb8eeaf:Deconvolution widefield microscopy (DWM)/Deconvolution is a computational technique for improving the contrast and resolution of digital images. It includes a suite of methods that seek to remove or reverse the blurring present in microscopes...\n- df1896a3:EM tomography (ET)/EM tomography allows the gathering of 3D information from individual thick sections of samples, previously fixed for sectioning. \r In TEM tomography thick plastic sections (typically 200-300 nm) are placed on an EM grid and...\n- 3965a906:Elemental analysis (EDX)*/Energy-dispersive X-ray spectroscopy (EDX) is a form of elemental analysis which is performed in combination with electron microscopy. EDX has so far not been routinely used in the life sciences, but thanks to new ge...\n- 60335007:Elemental analysis Correlative Light and Electron Microscopy (EDX-CLEM)*/Light microscopy helps to identify features in ultrastructural maps, but does not have EM resolution, therefore light and electron microscopy are correlated and in EDX-C...\n- 3a4d793f:Expansion Microscopy (ExM)*/Expansion microscopy (ExM) is a super-resolution approach that achieves sub-diffraction information by physically expanding the specimen. This allows it to seamlessly obtain resolutions of ~50 nm (up to 10 nm) in f...\n- 1f3001ca:Feedback microscopy (FDBKM)*/Biological systems are inherently complex, and the response of even the more stable model can be highly heterogeneous. Therefore, many samples must be imaged to achieve statistically meaningful results. In microsc...\n- 5a688552:Fluorescence (cross)-correlation spectroscopy (FCS/FCCS)/Fluorescence correlation spectroscopy (FCS) is a correlation analysis of fluctuations in the fluorescence intensity. The analysis provides information on physical parameters of the fluo...\n- 0de0802c:Fluorescence Lifetime Imaging (FLIM)/Fluorescence-lifetime imaging microscopy (FLIM) is an imaging technique for producing an image based on differences in the fluorescence-lifetime rather than its intensity. By quantifying variations in the ...\n- 018d2770:Fluorescence Recovery after Photobleaching (FRAP)/Fluorescence recovery after photobleaching (FRAP) denotes an optical technique capable of quantifying the two dimensional lateral diffusion of a molecularly thin film containing fluorescently ...\n- e9910d1c:Fluorescence Resonance Energy Transfer (FRET)/Fluorescence resonance energy transfer (FRET) is a mechanism describing energy transfer between two light-sensitive molecules (chromophores). A donor chromophore, initially in its electronic excit...\n- eebba7a7:Focussed Ion beam SEM (FIB-SEM) /A full understanding of the fine organization of cells and tissues requires their high-resolution visualization in three dimensions (3D). Plastic embedded cells can be imaged with automated focused ion beam (F...\n- 745fa0d0:Fourier transform infrared imaging (FTIR)/Rapid, non-destructive molecular analysis; high sensitivity, versatile applications.\n- 04562797:Genetic encoded EM probes (GE probes)/Localising specific proteins of interest represents a challenge in electron microscopy, compared to fluorescence microscopy where the target of interest is normally visualised via fluorescent tags or prob...\n- 722bb380:High throughput microscopy/high content screening (HTM/HCS)/High-throughput microscopy has created new opportunities for studying biological phenomena in an unbiased manner. Using automated cell manipulations and microscopy platforms, it is p...\n- d6cec7b4:High-speed Imaging (HSI)*/High-speed imaging includes all imaging techniques capable of gathering data at very high frame rates. The commonly considered cut-off is an exposure time of 1/1000 sec or >250 frames per second. High-speed imaging a...\n- 4e5bcb9e:I don't know which technology/Real-time multi-modal imaging: MRI, CT, fluorescence, high-resolution cell dynamics.\n- 22875d0d:Image Analysis -bio (IA bio)*/AI-driven, scalable image analysis for complex biological data interpretation.\n- 31d30c68:Image Scanning microscopy (ISM)/Super-resolution imaging with 2x confocal resolution, SPAD detection, live-cell compatible.\n- 639a72d3:Image analysis - med (IA med)*/AI-driven medical imaging: automated detection, segmentation, real-time analysis.\n- a2a0f4a8:Imaging Flow Cytometry (IFC)*/Imaging Flow Cytometry combines the speed, sensitivity and strong statistical power of conventional flow cytometry with the detailed imagery, spatial information and functional insight of microscopy all in a sing...\n- f65a70b8:Imaging at Biosafety Level >1 (BSL>1)/Imaging at Biosafety Levels >1 is offered at several Euro-BioImaging Nodes. Several Nodes offer imaging at BSL2 and select facilities at BSL3 are also available. In these cases the imaging systems are pla...\n- a97f4fa4:Imaging for Plant Phenotyping (PHENO)*/Multi-sensor imaging: RGB, hyperspectral, thermal; high-throughput phenotyping.\n- 3f84bc36:Immuno-gold EM on resin sections (resin-EM)/Immuno-gold is a variant of immunohistochemistry where antibodies tagged with gold particles (of different sizes) are used to visualise the localisation of proteins of interest in EM samples. Due to...\n- e32e05f1:Immuno-gold EM on thawed cryo-sections (Tokuyasu-EM)/Immuno-gold is a variant of immunohistochemistry where antibodies tagged with gold particles (of different sizes) are used to visualise the localisation of proteins of interest in EM sample...\n- a673b6b7:Intravital Microscopy (IVM)/Intravital imaging covers a range of microscopy modalities used for the long term imaging of living animal models (e.g. zebrafish larvae, mice, rats), in various organs or tissues, or as a whole for smaller models....\n- de231b3c:Large scale EM (lsTEM)/In large scale EM, either scanning electron microscopy or transmission electron microscopy are performed on samples that have been sectioned. In particular the focus here is to acquire large datasets spanning big fields...\n- 019f553c:Laser scanning confocal microscopy (LSCM/CLSM)/Confocal laser scanning microscopy (CLSM) or laser scanning confocal [LSCM]), often colloquially referred to  simply as \u201cconfocal\u201d, is a technique for obtaining high resolution optical images wit...\n- d2871017:Lattice light-sheet (LLS)/Ultra-thin light sheet, isotropic 3D resolution, minimal phototoxicity, 4D imaging.\n- e7adfd19:Light-sheet mesoscopic imaging (SPIM/dSLSM)/Light sheet microscopy is a mesoscopic imaging technology that combines optical sectioning with multiple-view imaging to observe tissues and living organisms with impressive resolution. This method ...\n- b773e740:Long-term vertical-stage confocal/Airyscan microscopy/90 nm resolution, long-term live-cell imaging, enhanced signal detection.\n- 4707da44:MRI/MRS (< 7T)/\n- 6324bef6:MRI/MRS (>= 7T)/7T MRI/MRS: ultra-high resolution, dual-mode, advanced neuroscience applications.\n- 83b4baea:Macro Serial Blockface Fluorescence imaging* (S-BFI)/Serial block face imaging (SFBI) is a method used to generate 3-dimensional (3D) reconstruction of a sample via serial image acquisition, here on a microtome. The system can detect the endo...\n- 0d8de032:Magnetic Particle Imaging (MPI)*/Real-time, high-resolution imaging using superparamagnetic nanoparticles.\n- b5cb68ca:MagnetoEncephaloGraphy (MEG)/Non-invasive, high temporal resolution, direct neuronal activity mapping.\n- 4b561f4f:Mass spectrometry-based imaging - bio (MSI - bio)*/Spatially resolved analysis of metabolites, proteins, lipids, peptides, glycans and even drugs has become feasible with the development of mass spectrometry-based imaging strategies. Developm...\n- 9c814a85:Mass spectrometry-based imaging - med (MSI - med)*/High-resolution MSI for spatial molecular mapping in tissues, untargeted analysis.\n- afeaed8d:Micro X-ray Fluorescence Spectrometry (XRF)*/Micro-X-Ray Fluorescence Spectrometry (XRF) allows the qualitative analysis of the elemental composition of solid samples. The detected signal results from the emission of element-characteristic fl...\n- 0a49ed44:Micro-Particle Induced X-ray Emmission (\u00b5-PIXE)*/High-resolution (1\u00b5m), non-destructive elemental mapping for diverse samples.\n- b5ef918c:Microdissection (\u00b5Dis)*/Laser microdissection is a useful technique that enables the precise isolation of cells or tissue regions out of a tissue specimen, allowing the isolation of high-purity biomolecules. The technique can be used on fixed...\n- fc6e9ebb:Minimal Photon Fluxes Microscopy (MINFLUX)*/Sub-2nm resolution, minimal photon use, live-cell tracking, 3D imaging.\n- 3ba9fb09:Multiplexing imaging (MXI)*/Multiplexing is the ability to stain the same sample many times. Today we are limited to 7 stains on the same slide but researchers want to go further and to be able to use more than 50 dyes to map their samples. T...\n- a7c09ccd:Objective-coupled planar illumination (OCPI)/High-speed, low-phototoxicity 3D imaging of large biological samples.\n- 17dd34eb:Optical projection tomography (OPT)/Optical projection tomOptical projection tomography (OPT) is in many ways the optical equivalent of x-ray computed tomography (CT) or the medical CT scan. OPT differs in the way that it often uses ultraviol...\n- a9c43bba:PET/High-resolution metabolic imaging; oncology, neurology, cardiology applications.\n- 3a2f2c38:PET-MRI/Hybrid imaging: combines PET's metabolic data with MRI's high-resolution anatomy.\n- 0f1e5f18:PET/CT */Hybrid imaging combining metabolic PET with anatomical CT for precise diagnostics.\n- 413a548d:Phase Contrast Imaging (PCI)/High-resolution imaging of soft tissues via X-ray phase shifts, enhancing diagnostics.\n- 47c84335:Phosphorescence Lifetime imaging (PLIM)*/Phosphorescence Lifetime Imaging works on a similar principle as fluorescence lifetime imaging (FLIM), but rather makes use of the phosphorescence induced by the excitation rather than the fluorescence...\n- d54d34a2:PhotoAcoustic Imaging (PAI) - med/Non-invasive imaging combining optical and ultrasound for high-res tissue analysis.\n- f4eef350:Photoacoustic imaging (PAI - bio)*/Non-invasive imaging with sub-mm resolution, real-time vascular and tumor analysis.\n- b5333ef4:Photomanipulation (Pmanip)/Photomanipulation includes a variety of techniques in which lasers (or other light sources) are used to interact with the sample in a targeted fashion. This includes laser ablation to induce cellular injuries and me...\n- 3ef7ea02:Plant Phenotyping (PHENOPlant)*/High-throughput, multi-sensor phenotyping for crops, Arabidopsis, stress studies.\n- 4ba07d0c:Polarization microscopy (PM)/Polarization Microscopy or Polarized Light Microscopy involve the use of polarized light in illuminating the sample and make use of the samples optically anisotropic character to generate contrast.\n- fd0e8053:Population imaging (PI data)/Advanced imaging for large cohorts: AI analysis, biomarker tracking, multi-modal.\n- 1fe88685:Population imaging (PI)/Large-scale imaging of populations for early disease detection and prevention.\n- f6b01df1:Quantitative Phase Imaging (QPI)*/Label-free imaging of live cells with nanoscale resolution and quantitative analysis.\n- dcb85d5e:Raman Spectroscopy (RS)/Non-destructive molecular fingerprinting, high sensitivity, rapid analysis.\n- b51478b1:Random Illumination Microscopy (RIM)*/Speckled illumination, super-resolution, fast imaging of thick biological samples.\n- a42333c3:Reversible optical fluorescence transitions (RESOLFT)/Sub-100nm resolution, live cell imaging, reversible fluorescent switching.\n- 995a6055:STEM tomography (STEM)/Scanning transmission electron microscopy (STEM) is a type of transmission electron microscopy in which the focussed electron beam is rastered or scanned across the samples. \r \r In STEM tomography, similar to TEM tomogr...\n- c60b4a73:Scanning Electron Microscopy (SEM)/In Scanning Electron Microscopy, a focussed beam of accelerated electrons is scanned across the surface of the sample and the scanned and secondary electrons are used to generate the SEM image.\r SEM can be u...\n- d52b6d15:Second/Third Harmonic Generation (SHG/THG)/SHG is a label free technique to visualize specific structures e.g. fibrillar collagen, muscle myosin, and microtubules in vitro and in vivo. THG shows interfaces having local transitions of the refr...\n- c1a46958:Secondary Ion Mass Spectrometry with MeV ions (MeV-SIMS)*/High-resolution imaging of large biomolecules using MeV ions, low fragmentation.\n- c9ddc22b:Serial Blockface SEM (SBF-SEM)/A full understanding of the fine organization of cells and tissues requires their high-resolution visualization in three dimensions (3D). In this technique a miniaturized ultramicrotome, embedded in the chamber ...\n- d3d66a1d:Single Molecule localization microscopy (SMLM)/Achieves 20-50nm resolution, enabling detailed imaging of molecular dynamics.\n- 7add3aac:Single Particle Tracking (SPT)*/Real-time tracking of individual particles with nanometer precision in live cells.\n- 931ee18e:Single molecule FRET (smFRET)*/Single molecule FRET allows the measurement of distances and distance changes between two fluorescent molecules in a biomolecular complexes, down to the Angstrom and the microsecond timescales. smFRET measuremen...\n- 02c9e1e3:Spatial Transcriptomics (ST)*/High-resolution spatial gene expression mapping in tissues, enabling cell interaction insights.\n- 3cf0830c:Spinning disk confocal microscopy (SDCM)/Spinning disc confocal microscopy is one of the solutions for routine and high-performance fluorescence live-cell imaging applications. SDCM uses a series of moving pinholes on a disc to scan spots of ...\n- e480e528:Stimulated Raman Scattering (SRS)*/High-speed, label-free imaging with sub-10 nm resolution for live cells.\n- f1f735b6:Stimulated emission depletion microscopy (STED)/Sub-50nm resolution, live cell imaging, selective fluorophore deactivation\n- ff8ab803:Structured illumination microscopy* (SIM)/Spinning disc confocal microscopy is one of the solutions for routine and high-performance fluorescence live-cell imaging applications. SDCM uses a series of moving pinholes on a disc to scan spots of...\n- f45daf6b:Super-resolution radial fluctuations (SRRF)*/Sub-100nm resolution for live-cell imaging, low phototoxicity, accessible.\n- af33ff84:TEM of chemical fixed samples (TEM)/In transmission electron microscopy (TEM) the accelerated beam of electrons is transmitted through the sample and collected to form an image. To achieve this the specimen is usually sectioned into ultrathin...\n- 4ae7143c:TEM of cryo-immobilized samples (TEM cryo samples)*/In transmission electron microscopy (TEM) the accelerated beam of electrons is transmitted through the sample and collected to form an image. To achieve this the specimen is usually sectione...\n- ae6d3c51:TEM of immobilized particles (TEM neg stain)*/High-resolution TEM negative staining for biomolecules, viruses, and complexes.\n- b4d963a5:Terahertz Plant Imaging (THzI)*/Non-invasive THz imaging for plant hydration, quality assessment, high resolution.\n- f05d797c:Tissue Clearing (TC)*/The restitution of 3D images from samples becomes a major challenge for visualizing, exploring, analyzing and quantifying. The major problem with samples is their intrinsic composition which prevents correct observation....\n- 8399c5a7:Total internal reflection fluorescence microscopy (TIRF)/Total internal reflection fluorescence microscopy (TIRF)  is a microscopy technique with which a thin region of the cell, usually less than 200nm can be observed.  A TIRF microscope use...\n- 0534020c:Traction Force Microscopy (TFM)*/Traction Force Microscopy (TFM) has been extremely useful in the field of mechanobiology where it is applied to locally track the forces that cells exert on a particular substrate. Experiments can be performed...\n- 2fa1c4a2:Two-photon microscopy (2P)/Multiphoton microscopy - most commonly in the form of two-photon microscopy - is a fluorescence imaging technique that allows observation of living tissue up to about one millimeter in depth. It uses pulsed red-shif...\n- a6cee2e2:Voltage/pH/Ion Imaging */Real-time imaging of voltage, pH, and ions in live cells with high sensitivity.\n- c83c6c2b:ex-vivo micro-CT/High-resolution 3D imaging of excised tissues, sub-10\u00b5m resolution, vascular studies.\n- 4e2f1176:immunolabeling on immobilized particles (immunolocal)*/High-resolution immunolocalization via oriented antibody immobilization for diagnostics.\n- 59a33aed:in vivo optical imaging (OI)/Non-invasive, high-resolution imaging of live biological processes using light.\n- 3744dad8:intravital microscopy (IVM-med)/Real-time in vivo imaging with dual-mode confocal/two-photon, 100 fps.\n- c3302077:live-cell Correlative Light and Electron Microscopy (live-cell CLEM)/Cells are imaged live by light microscopy (e.g. wide field, confocal or light sheet). Following the light microscopy image acquisition, specific CLEM protocols enable the sc...\n- b4a6f749:micro-CT/High-resolution micro-CT: 100nm, 3D imaging, non-destructive, diverse applications.\n- d74face8:micro-MRI/MRS (<7 T)ex-vivo/High-resolution ex-vivo micro-MRI/MRS (<7 T) for detailed tissue analysis.\n- 4a91416e:micro-MRI/MRS (>= 7 T)ex-vivo/7T micro-MRI/MRS: 100\u00b5m resolution ex-vivo imaging for neuroanatomy and pathology.\n- fc3c255a:micro-MRI/MRS (Field < 7 T)/Cryogen-free micro-MRI/MRS < 7 T: high-resolution, multi-nuclear imaging for small animals.\n- 9c64e406:micro-MRI/MRS (Field >= 7 T)/7 T micro-MRI/MRS: sub-millimeter resolution, multi-nuclear imaging, advanced neurological diagnostics.\n- 4aa5d36d:micro-PET/High-resolution small-animal imaging: 1-2 mm, oncology, neurology, non-invasive.\n- c41fb0d1:micro-PET/CT/High-resolution micro-PET/CT: 1.4mm resolution, multimodal imaging for small animals.\n- 15ef9b0e:micro-PET/MRI/Hybrid imaging: simultaneous micro-PET/MRI, high-resolution, in vivo molecular imaging.\n- 36d4a2a7:micro-SPECT/Ultra-high-resolution micro-SPECT: 0.13 mm, dynamic imaging, multi-isotope capability.\n- 8fa56005:micro-SPECT-CT/High-res micro-SPECT-CT: 0.3mm, dynamic imaging, preclinical applications.\n- 2ce231cc:micro-US/29 MHz resolution, real-time imaging, prostate cancer diagnosis, biopsy guidance.\n- 0abb2c96:post-embed Correlative Light and Electron Microscopy (on-section CLEM)/Correlative Light and Electron Microscopy (CLEM) combines the advantages of both techniques, allowing scientists to spot cellular structures and processes of interest in w...\n- 90e98166:post-embedding CLEM (post-emb CLEM)/Correlative Light and Electron Microscopy (CLEM) combines the advantages of both techniques, allowing scientists to spot cellular structures and processes of interest in whole cell images with LM and then z...\n- 0dee2953:pre-embed Correlative Light and Electron Microscopy (pre-embed CLEM)/Correlative Light and Electron Microscopy (CLEM) combines the advantages of both techniques, allowing scientists to spot cellular structures and processes of interest in who...\n- 13e1b5d4:pre-embedding CLEM (pre-emb CLEM)/Correlative Light and Electron Microscopy (CLEM) combines the advantages of both techniques, allowing scientists to spot cellular structures and processes of interest in whole cell images with LM and then zoo...\n- 143e2504:pre-embedding immunolabelling (pre-embed IL)/In contrast to immuno-gold EM on sections, in pre-embedding immunolabeling, the sample is immunolabeled before the standard processing for EM takes place. This can offer the advantage of improved a...\n- d169e03b:serial section TEM (ssTEM)/ssTEM is performed on series of thin sections that are acquired by conventional ultramicrotomy, compared to the ribbons of sections in Array Tomography. The sections are collected on EM grids and imaged sequentially...\n\n## Available Nodes by Country (with ISO codes):\n\n**Austria (AT):**\n  - 2b34e271:Austrian BioImaging Node/CMI/Austria 8-site: cryo-EM, microCT, microPET, multimodal workflows, data analysis\n\n**Belgium (BE):**\n  - 0c8677f6:Flanders Bioimaging Imaging Node/Multi-site, multi-modality: molecular to clinical imaging, 9 facilities.\n\n**Bulgaria (BG):**\n  - 151b4761:Sofia BioImaging Node - Advanced Light Microscopy Node Sofia Bulgaria\u200b/Multimodal, high-res live-cell imaging, laser disruption, open access.\n\n**Czech Republic (CZ):**\n  - 638ca876:Advanced Light Microscopy and Medical Imaging Node Brno CZ/Brno CZ: 9.4T ultra-high field MR, multi-modal imaging, training programs.\n  - 90c8b0d6:Advanced Light and Electron Microscopy Node Prague CZ/Prague Node: Multi-modal, super-resolution, live imaging, training courses.\n  - e0395c6a:Center for Advanced Preclinical Imaging (CAPI)/CAPI: Multimodal preclinical imaging, in vivo research, contrast media expertise.\n\n**Denmark (DK):**\n  - 23f7a2fd:Danish BioImaging/Multi-site Danish Node: pre-clinical to cryo-EM, diverse applications, data analysis focus.\n\n**EMBL (EM):**\n  - b19711d3:Euro-BioImaging EMBL-Node/EMBL Node: state-of-the-art imaging, project planning, training, advanced methods.\n\n**Finland (FI):**\n  - 46ccfb38:Finnish Advanced Microscopy Node/Sub-20nm resolution, correlative workflows, advanced sample preparation.\n  - 3850f7eb:Finnish Biomedical Imaging Node/Multi-modal Node: PET, MRI, MEG, optical; targets cancer, neuroscience, metabolism.\n\n**France (FR):**\n  - fc1893d4:French BioImaging Node/30 facilities, 80 labs, bioimage informatics, advanced microscopy methods.\n\n**Hungary (HU):**\n  - ca2e3748:Cellular Imaging Hungary/Multi-modal node: LSCM, ISIDORe, infectious disease focus, pandemic readiness.\n  - cf8f008b:Medical and Preclinical Imaging Hungary/Multi-modal Node: functional imaging, PET/CT, microCT, unique M3 concept.\n\n**Israel (IL):**\n  - 9beefd47:Israel BioImaging/Cross-modality imaging: single-molecule to clinical, advanced analysis.\n\n**Italy (IT):**\n  - 522e8aaa:Advanced Light Microscopy Italian Node/Italy's multi-modal node: 5 sites, advanced imaging, diverse applications.\n  - 6319df36:Digital Imaging Multimodal Platform Neuromed \u2013  DIMP NEUROMED/Integrated multimodal platform for neuroscience, preclinical to clinical imaging.\n  - d2be2f9c:Molecular Imaging Italian Node/Italy 8-site: multi-modal, in vivo imaging, extensive tracer repository, advanced applications.\n  - d14abc55:Phase Contrast Imaging Flagship Node Trieste/Trieste: High-intensity phase contrast, soft tissue imaging, synchrotron source.\n\n**Netherlands (NL):**\n  - f68673b1:Challenges Framework Flagship Node/Open-source platform: algorithm evaluation, cloud collaboration, data repository\n  - d039b533:Correlative Light Microscopy Dutch Flagship Node/Dutch CLEM consortium: live-cell correlation, open access, multi-lab expertise.\n  - 4278635d:Dutch High Field Imaging Hub/Ultra-high field MRI, 7T+, precision neuroimaging, multi-site collaboration.\n  - 4f1ca4db:Erasmus MC OIC - Advanced Light Microscopy Rotterdam Node/Quantitative live cell imaging, FRAP, FRET, FCS, high resolution.\n  - 9c8d648e:Facility of Multimodal Imaging - AMMI Maastricht/Multimodal imaging: light/electron microscopy, mass spectrometry, non-invasive bioimaging.\n  - 6f0ef2b7:High Throughput Microscopy Dutch Flagship Node/NL flagship: high-throughput, live cell, advanced imaging, multi-site expertise.\n  - 84334573:Population Imaging Flagship Node Rotterdam/Epidemiological studies, imaging biomarkers, risk assessment, Rotterdam Node\n  - 706cb740:Preclinical Imaging Centre (PRIME) - Molecular Imaging Dutch Node/Dual-site, multimodal small animal imaging; unique genetic models, multiphoton.\n  - c4b25263:The Van Leeuwenhoek Center for Advanced Microscopy (LCAM) - Functional Imaging Flagship Node Amsterdam/Advanced live cell imaging, FRET, FCCS, FLIM, custom fluorophores.\n  - 66b1f7ec:Wageningen Imaging and Spectroscopy Hub (WISH) - ALM and Molecular Imaging Node Wageningen/Ultrafast fluorescence, in vivo photosynthesis, single-cell chloroplast imaging.\n\n**Norway (NO):**\n  - 3e52fd14:NORMOLIM, Norwegian Molecular Imaging Infrastructure/Norwegian in vivo imaging: disease models, transgenic systems, clinical translation.\n  - a44edc42:NorMIC Oslo - Advanced Light Microscopy Node Oslo/Live imaging, sub-cellular dynamics, incubators for CO2 control.\n\n**Poland (PL):**\n  - fcf6bac6:Advanced Light Microscopy Node Poland/Multi-modal imaging: super-resolution, CLEM, high-throughput, training.\n\n**Portugal (PT):**\n  - 6e382796:Brain Imaging Network (BIN)/Portugal Node: PET/MR, neuroimaging focus, multimodal expertise, radiotracer development.\n  - e5f30cac:Portuguese Platform of BioImaging (PPBI)/Multi-sited Euro-BioImaging Node: advanced light/electron microscopy, live cell imaging, high throughput.\n\n**Slovenia (SI):**\n  - 2103118f:SiMBION Node/Slovenian consortium: 15 centers, bioimaging access, training, TNA support.\n\n**Spain (ES):**\n  - e532f9cb:Barcelona Live and Intravital Node/Live-cell and in vivo imaging, multi-modal techniques, advanced fluorescence.\n  - 1fa342de:Barcelona Mesoscopic Imaging Node/Barcelona Node: LSFM, 50\u00b5m-5cm, live imaging, multiview, organ resolution.\n  - 161021f6:Barcelona Super-resolution Light and Nanoscopy Node/Multi-site: super-resolution, bioimage analysis, custom training, complex datasets.\n  - 6d068cfb:Population Imaging Valencia/AI-driven biomarkers, predictive models, structured image repositories.\n\n**Sweden (SE):**\n  - f1099f78:Swedish National Microscopy Infrastructure (NMI)/Swedish multi-site: super-resolution, intravital, live imaging, 500+ users.\n\n**United Kingdom (GB):**\n  - 09122290:The UK Node/UK multi-site: super-resolution, correlative, high-content imaging, open-access.\n\n**Unknown (UN):**\n  - 64543c53:No Node preference/Node selection assistance, tailored tech guidance, project optimization.\n\n**IMPORTANT**: Each entry in the indexes above follows the format `- ID: Name / Description`\n\n- For **Technologies**: `- tech_id: Technology Name/Brief description`\n- For **Nodes**: `- node_id: Node Name/Brief description` \n- For **Website Pages**: `- page_id: Page Title/Brief description`\n\nFor any matched topics, you can call the utility functions to get more details by the ID.\n\n**To use the utility functions**: Extract the ID (the part after the dash and before the colon) and pass it to the appropriate function:\n- Use `tech_id` with `read_tech_details(tech_id)`\n- Use `node_id` with `read_node_details(node_id)` \n- Use `page_id` with `read_website_page_details(page_id)`\n\nThese utilities are available under the current execution context, and no need to use await to call them. For example:\n\n```python\n# Example: Get details of a specific technology\ntech_details = read_tech_details(\"02e4459a\")\nprint(f\"Technology: {tech_details.name}\")\nprint(f\"Description: {tech_details.description}\")\n```\n\nImprtantly, they are not under api.* namespace, so you can call them directly.\n\n\n## \ud83d\udee0\ufe0f Available Utility Functions\n\n**IMPORTANT**: Call these functions directly - NO `await`, NO `api.` prefix, NO keyword arguments!\n\n### Detail Retrieval Functions\n- `read_tech_details(tech_id)` \u2192 `TechDetail(id, name, original_id, description, documentation, category, provider_node_ids, abbr)` or `None`\n- `read_node_details(node_id)` \u2192 `NodeDetail(id, name, original_id, description, documentation, country, offer_technology_ids)` or `None`  \n- `read_nodes_by_country(country_code)` \u2192 `List[NodeDetail(id, name, original_id, description, documentation, country, offer_technology_ids)]`\n- `read_website_page_details(page_id)` \u2192 `WebsitePageDetail(id, url, title, description, documentation, headings, page_type)` or `None`\nThe returned objects are pydantic models, so you can access the attributes directly. For example: tech_details.name, node_details.country['name'], etc.\n\n### Search Functions\n- `fulltext_search(query, k=5)` \u2192 `List[Dict]` (full-text search across all content types)\n- `get_country_codes()` \u2192 `Dict[str, str]` (country_name \u2192 ISO_code)\n\n\n## \u2705 Correct Function Call Examples\n\n```python\n# CORRECT: Get node details\nnode_details = read_node_details(\"48c78d41\")\nprint(f\"Node: {node_details.name}\")\nprint(f\"Country: {node_details.country['name']}\")\nprint(f\"Description: {node_details.description}\")\n\n# CORRECT: Get technology details  \ntech_details = read_tech_details(\"02e4459a\")\nprint(f\"Technology: {tech_details.name}\")\nprint(f\"Category: {tech_details.category['name']}\")\nprint(f\"Available at {len(tech_details.provider_node_ids)} nodes\")\n\n# CORRECT: Get all nodes in Germany\ngerman_nodes = read_nodes_by_country(\"DE\")\nfor node in german_nodes:\n    print(f\"Node: {node.name}\")\n    print(f\"Technologies: {len(node.offer_technology_ids)} available\")\n\n# CORRECT: Full-text search across all content\nresults = fulltext_search(\"super resolution microscopy\", k=5)\nfor result in results:\n    print(f\"Score: {result['score']:.2f} - Type: {result['type']} - Name: {result['name']}\")\n    print(f\"Description: {result['description']}\")\n```\n\n## \u274c WRONG Function Call Examples\n\n```python\n# WRONG: Don't use await\nnode_details = await read_node_details(\"48c78d41\")  # \u274c\n\n# WRONG: Don't use api prefix\nnode_details = api.read_node_details(\"48c78d41\")  # \u274c\n\n# WRONG: Don't use keyword arguments\nnode_details = read_node_details(node_id=\"48c78d41\")  # \u274c\n\n# WRONG: Don't combine await + api\nnode_details = await api.read_node_details(node_id=\"48c78d41\")  # \u274c\n```\n\n## \ud83e\udde0 How to Answer User Queries\n\nFollow this systematic approach:\n\n### 1. **Analyze the Query Type**\n- **Geographic queries** (e.g., \"facilities in Germany\"): Focus on specific countries/regions\n- **Technology queries** (e.g., \"super-resolution microscopy\"): Focus on specific techniques or instruments  \n- **General information** (e.g., \"how to access services\"): Focus on website pages and general guidance\n- **Listing queries** (e.g., \"all available nodes\"): Provide comprehensive listings\n\n### 2. **Select Relevant IDs**\nFrom the indexes above, identify the specific IDs you need by looking at the summaries:\n- **Technology IDs**: Look for relevant techniques in the technology list, extract the ID before the colon\n- **Node IDs**: Look for relevant facilities in the node list, extract the ID before the colon\n- **Country codes**: Use the ISO codes in parentheses (e.g., DE, SE, FR)\n- **Page IDs**: Look for relevant information pages, extract the ID before the colon\n\n**Example**: If you see `tech_super_res_microscopy: Super-Resolution Microscopy (available at 15 nodes)`, use `tech_super_res_microscopy` as the ID.\n\n### 3. **Retrieve Detailed Information**\nUse the utility functions systematically:\n\n**For Technology Queries:**\n```python\n# Example: \"Where can I find MINFLUX?\"\n# Step 1: Get the specific technology details\nminflux_details = read_tech_details(\"4bf1cfdd\")  # Extract ID from index\nprint(f\"Technology: {minflux_details.name}\")\n\n# Step 2: Get nodes where it's available (don't list all their technologies)\nfor node_id in minflux_details.provider_node_ids:\n    node_details = read_node_details(node_id)\n    print(f\"Available at: {node_details.name} in {node_details.country['name']}\")\n```\n\n**For Geographic Queries:**\n```python\n# Example: \"What imaging facilities are in Germany?\"\ncountry_nodes = read_nodes_by_country(\"DE\")  # Germany\nfor node in country_nodes:\n    print(f\"Node: {node.name}\")\n    print(f\"Description: {node.description}\")\n    print(f\"Technologies available: {len(node.offer_technology_ids)} total\")\n    # Only list technologies if specifically asked, don't retrieve all details\n```\n\n**For General Full-text Search:**\n```python\n# Use full-text search to find relevant content\nresults = fulltext_search(\"access services application\", k=5)\nfor result in results:\n    if result['type'] == 'page':\n        page_details = read_website_page_details(result['id'])\n        print(f\"Page: {page_details.title}\")\n        print(f\"URL: {page_details.url}\")\n        print(f\"Description: {page_details.description}\")\n```\n\n```python\n# Example: \"Find super-resolution microscopy techniques\"\nresults = fulltext_search(\"super resolution microscopy\", k=3)\nfor result in results:\n    if result['type'] == 'tech':\n        print(f\"Technology: {result['name']} (Score: {result['score']:.2f})\")\n        print(f\"Description: {result['description']}\")\n        # Get provider nodes if needed\n        tech_details = read_tech_details(result['id'])\n        for node_id in tech_details.provider_node_ids:\n            node_details = read_node_details(node_id)\n            print(f\"  Available at: {node_details.name} in {node_details.country['name']}\")\n```\n\n### 4. **Be Focused and Efficient**\n- Only retrieve information that directly answers the user's question\n- Don't list all technologies at a node unless specifically asked\n- Don't retrieve all details unless needed for the specific query\n- Answer the question, don't provide unnecessary comprehensive listings\n\n### 5. **Reason Across Results**\n- Integrate information from multiple search results if needed\n- Draw conclusions, extract availability details, instrument capabilities, node locations, and relevant contact information\n\n### 6. **Handle AI-Enhanced Content Transparently**\n- **Check for AI enhancement markers** in technology documentation:\n  - Look for \"## AI Generated Documentation\" sections\n  - Look for \"## References\" sections with sources\n- **When using AI-enhanced content**:\n  - Mention that information is AI-enhanced: \"Based on AI-enhanced documentation...\"\n  - Cite sources from References sections: \"According to sources including [source name](url)...\"\n\n### 7. **Respond Factually and Comprehensively**\n- Ensure your final reply contains all key findings and actionable information\n- Always include all relevant details in your final answer, the intermediate script output won't be seen by the user\n- Avoid vague summaries\u2014be precise and specific based on the returned context\n- **Be transparent about information sources** throughout your response\n\n## \ud83d\udccb Query Pattern Examples\n\n**Geographic Query**: \"What imaging facilities are available in Germany?\"\n1. Use `read_nodes_by_country(\"DE\")` to get all German nodes\n2. For each node, use `read_node_details()` to get full information\n3. For each technology at the nodes, use `read_tech_details()` to understand capabilities\n\n**Technology Query**: \"Where can I access super-resolution microscopy?\"\n1. Use `fulltext_search(\"super resolution microscopy\", k=3)` to find relevant technologies and nodes\n2. Filter results by type to focus on technologies and nodes\n3. Use `read_tech_details()` and `read_node_details()` to get detailed information\n\n**General Information**: \"How do I access Euro-BioImaging services?\"\n1. Use `fulltext_search(\"access services application procedures\", k=3)` to find relevant content\n2. Filter results for website pages that contain access information\n3. Use `read_website_page_details()` for each relevant page to get detailed information\n\n## \ud83c\udfaf Response Quality Guidelines\n0. When generating the thoughts, limit each thought to 5 words maximum.\n1. **Use the indexes above** to identify relevant resources by their summaries\n2. **Extract IDs correctly** (the part before the colon) from the index entries\n3. **Call functions directly** without await, api prefix, or keyword arguments\n4. **Be systematic** in retrieving details for all relevant items\n5. **Include geographic context** (country names and codes)\n6. **Provide comprehensive information** which corresponds to the user query, try to be helpful and comprehensive.\n7. Since we are targeting non-technical users, unless asked, you can generate and execute scripts, but no need to commit code during the final response.\n\nRemember: Scan the indexes for relevant entries, extract the correct IDs, then call the utility functions directly to get detailed information.\n\n",
                    "attrs": {
                      "className": "output-area"
                    }
                  }
                ],
                "executionCount": 56
              }
            ]
          },
          "_security": {
            "sanitized": true,
            "sanitizedAt": "2025-06-30T19:40:34.619Z",
            "version": "1.0",
            "note": "All API keys and sensitive data have been automatically removed"
          }
        }
      }
    },
    "cells": [
      {
        "id": "9044a6d4-58e5-4b7a-905a-fe60777a9891",
        "type": "code",
        "content": "import micropip\nawait micropip.install([\"httpx\", \"pydantic\", \"bm25s\"])\n\nimport httpx\nfrom typing import Dict, List, Any, Optional, Tuple\nfrom pydantic import BaseModel\nimport bm25s\nfrom pathlib import Path\nimport tempfile\nimport micropip\nimport pickle\n\nclass TechDetail(BaseModel):\n    \"\"\"Details of a specific technology\"\"\"\n    id: str\n    name: str\n    original_id: str\n    description: str\n    documentation: str\n    category: Dict[str, Any]\n    provider_node_ids: List[str]\n    abbr: str\n\nclass NodeDetail(BaseModel):\n    \"\"\"Details of a specific node\"\"\"\n    id: str\n    name: str\n    original_id: str\n    description: str\n    documentation: str\n    country: Dict[str, Any]\n    offer_technology_ids: List[str]\n\nclass WebsitePageDetail(BaseModel):\n    \"\"\"Details of a Euro-BioImaging website page\"\"\"\n    id: str\n    url: str\n    title: str\n    description: str\n    documentation: str\n    headings: List[str]\n    page_type: str\n\nclass SearchResponse(BaseModel):\n    \"\"\"Structured search response\"\"\"\n    answer: str\n    relevant_technologies: List[str] = []\n    relevant_nodes: List[str] = []\n    relevant_pages: List[str] = []\n    summary: str = \"\"\n\n# Global data storage\ntech_data: List[Dict[str, Any]] = []\nnodes_data: List[Dict[str, Any]] = []\nwebsite_data: List[Dict[str, Any]] = []\nbm25_retriever = None\nbm25_metadata = None\n\nasync def load_eurobioimaging_data():\n    \"\"\"\n    Load Euro-BioImaging data from remote index file.\n    This function fetches the combined index from the remote URL and populates the global data structures.\n    \n    Returns:\n    - dict: Metadata about the loaded dataset including counts and creation info\n    \"\"\"\n    global tech_data, nodes_data, website_data, bm25_retriever, bm25_metadata\n    \n    base_url = \"https://aicell-lab.github.io/euro-bioimaging-finder\"\n    \n    try:\n        async with httpx.AsyncClient(timeout=30.0) as client:\n            # Load main index\n            response = await client.get(f\"{base_url}/eurobioimaging_index.json\")\n            response.raise_for_status()\n            combined_data = response.json()\n            \n            # Extract data from combined index\n            tech_data = combined_data.get('technologies', [])\n            nodes_data = combined_data.get('nodes', [])\n            website_data = combined_data.get('website_pages', [])\n            bm25_metadata = combined_data.get('bm25_metadata', [])\n            \n            # Download and load BM25 pickle file\n            bm25_response = await client.get(f\"{base_url}/eurobioimaging_bm25_index.pkl\")\n            bm25_response.raise_for_status()\n            \n            # Save to temp file and load\n            with tempfile.NamedTemporaryFile(suffix='.pkl', delete=False) as temp_file:\n                temp_file.write(bm25_response.content)\n                temp_file.flush()\n                \n                with open(temp_file.name, 'rb') as f:\n                    bm25_retriever = pickle.load(f)\n            \n            # Get metadata\n            metadata = combined_data.get('metadata', {})\n            dataset_info = {\n                'dataset_type': metadata.get('dataset_type', 'unknown'),\n                'created_at': metadata.get('created_at', 'unknown'),\n                'technologies_count': len(tech_data),\n                'nodes_count': len(nodes_data),\n                'website_pages_count': len(website_data),\n                'total_entries': len(tech_data) + len(nodes_data) + len(website_data),\n                'bm25_documents': len(bm25_metadata) if bm25_metadata else 0\n            }\n            \n            return dataset_info\n            \n    except Exception as e:\n        print(f\"Error loading data: {e}\")\n        tech_data = []\n        nodes_data = []\n        website_data = []\n        bm25_retriever = None\n        bm25_metadata = None\n        raise e\n\ndef read_tech_details(tech_id: str):\n    \"\"\"\n    Read details of a specific technology by ID.\n    \n    Parameters:\n    - tech_id (str): The technology ID\n    \n    Returns:\n    - Optional[TechDetail]: Technology details or None if not found\n    \"\"\"\n    for tech in tech_data:\n        if tech['id'] == tech_id:\n            return TechDetail(**tech)\n    raise Exception(f\"Technology with ID {tech_id} not found\")\n\ndef read_node_details(node_id: str):\n    \"\"\"\n    Read details of a specific node by ID.\n    \n    Parameters:\n    - node_id (str): The node ID\n    \n    Returns:\n    - Optional[NodeDetail]: Node details or None if not found\n    \"\"\"\n    for node in nodes_data:\n        if node['id'] == node_id:\n            return NodeDetail(**node)\n    raise Exception(f\"Node with ID {node_id} not found\")\n\ndef read_nodes_by_country(country_code: str):\n    \"\"\"\n    Read all nodes in a specific country by ISO country code.\n    \n    Parameters:\n    - country_code (str): ISO country code (e.g., 'PL', 'SE', 'DE')\n    \n    Returns:\n    - List[NodeDetail]: List of all nodes in the specified country\n    \"\"\"\n    country_nodes = []\n    for node in nodes_data:\n        node_country = node.get('country', {})\n        if node_country.get('iso_a2', '').upper() == country_code.upper():\n            try:\n                country_nodes.append(NodeDetail(**node))\n            except Exception as e:\n                print(f\"Warning: Could not parse node {node.get('name', 'Unknown')}: {e}\")\n    return country_nodes\n\ndef read_website_page_details(page_id: str):\n    \"\"\"\n    Read details of a specific website page by ID.\n    \n    Parameters:\n    - page_id (str): The website page ID\n    \n    Returns:\n    - Optional[WebsitePageDetail]: Website page details or None if not found\n    \"\"\"\n    for page in website_data:\n        if page['id'] == page_id:\n            return WebsitePageDetail(**page)\n    raise Exception(f\"Website page with ID {page_id} not found\")\n\ndef get_country_codes():\n    \"\"\"\n    Get mapping of country names to ISO codes from the data.\n    \n    Returns:\n    - Dict[str, str]: Mapping of country names to ISO codes\n    \"\"\"\n    country_mapping = {}\n    for node in nodes_data:\n        country = node.get('country', {})\n        country_name = country.get('name', '')\n        country_code = country.get('iso_a2', '')\n        if country_name and country_code:\n            country_mapping[country_name.lower()] = country_code.upper()\n    return country_mapping\n\ndef create_search_prompt():\n    \"\"\"Create the search prompt with all available data indexes\"\"\"\n    \n    def truncate_line(line: str, max_length: int = 256) -> str:\n        \"\"\"Truncate line to max_length, preserving the format\"\"\"\n        if len(line) <= max_length:\n            return line\n        return line[:max_length-3] + \"...\"\n    \n    # Create technology index with \"- id: name / description\" format\n    tech_index = []\n    for tech in tech_data:\n        name = tech.get('name', '')\n        description = tech.get('description', '').replace('\\n', ' ').strip()\n        line = f\"- {tech['id']}:{name}/{description}\"\n        tech_index.append(truncate_line(line))\n    \n    # Create nodes index with \"- id:name/description\" format, grouped by country\n    nodes_by_country = {}\n    country_codes_info = {}\n    for node in nodes_data:\n        country = node['country']['name']\n        country_code = node['country'].get('iso_a2', 'XX')\n        if country not in nodes_by_country:\n            nodes_by_country[country] = []\n            country_codes_info[country] = country_code\n        \n        name = node.get('name', '')\n        description = node.get('description', '').replace('\\n', ' ').strip()\n        line = f\"- {node['id']}:{name}/{description}\"\n        nodes_by_country[country].append(truncate_line(line))\n    \n    nodes_index = []\n    for country, country_nodes in sorted(nodes_by_country.items()):\n        country_code = country_codes_info[country]\n        nodes_index.append(f\"\\n**{country} ({country_code}):**\")\n        nodes_index.extend([f\"  {node}\" for node in country_nodes])\n    \n    # Create website pages index with \"- id: title / description\" format\n    website_index = []\n    for page in website_data:\n        title = page.get('title', '')\n        description = page.get('description', '').replace('\\n', ' ').strip()\n        line = f\"- {page['id']}:{title}/{description}\"\n        website_index.append(truncate_line(line))\n    \n    prompt = f\"\"\"\nHere is a list of all the available resources associated with their IDs.\n\n## Available General Website Pages:\n{chr(10).join(website_index)}\n\n## Available Technologies: \n{chr(10).join(tech_index)}\n\n## Available Nodes by Country (with ISO codes):\n{chr(10).join(nodes_index)}\n\n**IMPORTANT**: Each entry in the indexes above follows the format `- ID: Name / Description`\n\n- For **Technologies**: `- tech_id: Technology Name/Brief description`\n- For **Nodes**: `- node_id: Node Name/Brief description` \n- For **Website Pages**: `- page_id: Page Title/Brief description`\n\nFor any matched topics, you can call the utility functions to get more details by the ID.\n\n**To use the utility functions**: Extract the ID (the part after the dash and before the colon) and pass it to the appropriate function:\n- Use `tech_id` with `read_tech_details(tech_id)`\n- Use `node_id` with `read_node_details(node_id)` \n- Use `page_id` with `read_website_page_details(page_id)`\n\nThese utilities are available under the current execution context, and no need to use await to call them. For example:\n\n```python\n# Example: Get details of a specific technology\ntech_details = read_tech_details(\"02e4459a\")\nprint(f\"Technology: {{tech_details.name}}\")\nprint(f\"Description: {{tech_details.description}}\")\n```\n\nImprtantly, they are not under api.* namespace, so you can call them directly.\n\n\"\"\"\n\n    return prompt\n\ndef fulltext_search(query: str, k: int = 5) -> List[Dict[str, Any]]:\n    \"\"\"\n    Perform full-text search using BM25 index\n    \n    Parameters:\n    - query (str): The search query\n    - k (int): Number of results to return (default: 5)\n    \n    Returns:\n    - List[Dict]: List of matching documents with metadata\n    \"\"\"\n    if not bm25_retriever or not bm25_metadata:\n        raise Exception(\"Error: BM25 index not loaded\")\n    \n    # Tokenize query\n    query_tokens = bm25s.tokenize(query)\n    \n    # Get results\n    results, scores = bm25_retriever.retrieve(query_tokens, k=k)\n    \n    # Format results\n    search_results = []\n    for i in range(results.shape[1]):\n        doc_idx = results[0, i]\n        score = scores[0, i]\n        \n        # Get metadata for the document\n        metadata = bm25_metadata[doc_idx]\n        doc_type = metadata['type']\n        doc_id = metadata['id']\n        \n        # Get full details based on type\n        if doc_type == 'tech':\n            details = read_tech_details(doc_id)\n            if details:\n                search_results.append({\n                    'type': doc_type,\n                    'id': doc_id,\n                    'name': details.name,\n                    'description': details.description,\n                    'score': float(score),\n                    'documentation': details.documentation,\n                    'category': details.category,\n                    'provider_node_ids': details.provider_node_ids,\n                })\n        elif doc_type == 'node':\n            details = read_node_details(doc_id)\n            if details:\n                search_results.append({\n                    'type': doc_type,\n                    'id': doc_id,\n                    'name': details.name,\n                    'description': details.description,\n                    'score': float(score),\n                    'documentation': details.documentation,\n                    'country': details.country,\n                    'offer_technology_ids': details.offer_technology_ids,\n                })\n        elif doc_type == 'page':\n            details = read_website_page_details(doc_id)\n            if details:\n                search_results.append({\n                    'type': doc_type,\n                    'id': doc_id,\n                    'name': details.title,\n                    'description': details.description,\n                    'score': float(score),\n                    'url': details.url,\n                    'documentation': details.documentation,\n                    'headings': details.headings,\n                    'page_type': details.page_type,\n                })\n    \n    return search_results\n\n# Initialize data and create the search prompt\ndata_loaded = await load_eurobioimaging_data()\n\nif not data_loaded:\n    print(\"WARNING: \u274c Failed to load Euro-BioImaging data, none of the following functions will work properly.\")\n\nprint(\"\"\"\nYou are an AI assistant specialized in helping users discover imaging technologies, instruments, and services provided by the Euro-BioImaging network.\nYou have access to several utility functions for retrieving specific information about Euro-BioImaging facilities. Below are all the available resources in the Euro-BioImaging network:\n\"\"\")\n\n# Print the search context with all available data\nsearch_context = create_search_prompt()\nprint(search_context)\n\n# The printed text will be used for the LLM agent as prompt.\nprint(\"\"\"## \ud83d\udee0\ufe0f Available Utility Functions\n\n**IMPORTANT**: Call these functions directly - NO `await`, NO `api.` prefix, NO keyword arguments!\n\n### Detail Retrieval Functions\n- `read_tech_details(tech_id)` \u2192 `TechDetail(id, name, original_id, description, documentation, category, provider_node_ids, abbr)` or `None`\n- `read_node_details(node_id)` \u2192 `NodeDetail(id, name, original_id, description, documentation, country, offer_technology_ids)` or `None`  \n- `read_nodes_by_country(country_code)` \u2192 `List[NodeDetail(id, name, original_id, description, documentation, country, offer_technology_ids)]`\n- `read_website_page_details(page_id)` \u2192 `WebsitePageDetail(id, url, title, description, documentation, headings, page_type)` or `None`\nThe returned objects are pydantic models, so you can access the attributes directly. For example: tech_details.name, node_details.country['name'], etc.\n\n### Search Functions\n- `fulltext_search(query, k=5)` \u2192 `List[Dict]` (full-text search across all content types)\n- `get_country_codes()` \u2192 `Dict[str, str]` (country_name \u2192 ISO_code)\n\n\n## \u2705 Correct Function Call Examples\n\n```python\n# CORRECT: Get node details\nnode_details = read_node_details(\"48c78d41\")\nprint(f\"Node: {node_details.name}\")\nprint(f\"Country: {node_details.country['name']}\")\nprint(f\"Description: {node_details.description}\")\n\n# CORRECT: Get technology details  \ntech_details = read_tech_details(\"02e4459a\")\nprint(f\"Technology: {tech_details.name}\")\nprint(f\"Category: {tech_details.category['name']}\")\nprint(f\"Available at {len(tech_details.provider_node_ids)} nodes\")\n\n# CORRECT: Get all nodes in Germany\ngerman_nodes = read_nodes_by_country(\"DE\")\nfor node in german_nodes:\n    print(f\"Node: {node.name}\")\n    print(f\"Technologies: {len(node.offer_technology_ids)} available\")\n\n# CORRECT: Full-text search across all content\nresults = fulltext_search(\"super resolution microscopy\", k=5)\nfor result in results:\n    print(f\"Score: {result['score']:.2f} - Type: {result['type']} - Name: {result['name']}\")\n    print(f\"Description: {result['description']}\")\n```\n\n## \u274c WRONG Function Call Examples\n\n```python\n# WRONG: Don't use await\nnode_details = await read_node_details(\"48c78d41\")  # \u274c\n\n# WRONG: Don't use api prefix\nnode_details = api.read_node_details(\"48c78d41\")  # \u274c\n\n# WRONG: Don't use keyword arguments\nnode_details = read_node_details(node_id=\"48c78d41\")  # \u274c\n\n# WRONG: Don't combine await + api\nnode_details = await api.read_node_details(node_id=\"48c78d41\")  # \u274c\n```\n\n## \ud83e\udde0 How to Answer User Queries\n\nFollow this systematic approach:\n\n### 1. **Analyze the Query Type**\n- **Geographic queries** (e.g., \"facilities in Germany\"): Focus on specific countries/regions\n- **Technology queries** (e.g., \"super-resolution microscopy\"): Focus on specific techniques or instruments  \n- **General information** (e.g., \"how to access services\"): Focus on website pages and general guidance\n- **Listing queries** (e.g., \"all available nodes\"): Provide comprehensive listings\n\n### 2. **Select Relevant IDs**\nFrom the indexes above, identify the specific IDs you need by looking at the summaries:\n- **Technology IDs**: Look for relevant techniques in the technology list, extract the ID before the colon\n- **Node IDs**: Look for relevant facilities in the node list, extract the ID before the colon\n- **Country codes**: Use the ISO codes in parentheses (e.g., DE, SE, FR)\n- **Page IDs**: Look for relevant information pages, extract the ID before the colon\n\n**Example**: If you see `tech_super_res_microscopy: Super-Resolution Microscopy (available at 15 nodes)`, use `tech_super_res_microscopy` as the ID.\n\n### 3. **Retrieve Detailed Information**\nUse the utility functions systematically:\n\n**For Technology Queries:**\n```python\n# Example: \"Where can I find MINFLUX?\"\n# Step 1: Get the specific technology details\nminflux_details = read_tech_details(\"4bf1cfdd\")  # Extract ID from index\nprint(f\"Technology: {minflux_details.name}\")\n\n# Step 2: Get nodes where it's available (don't list all their technologies)\nfor node_id in minflux_details.provider_node_ids:\n    node_details = read_node_details(node_id)\n    print(f\"Available at: {node_details.name} in {node_details.country['name']}\")\n```\n\n**For Geographic Queries:**\n```python\n# Example: \"What imaging facilities are in Germany?\"\ncountry_nodes = read_nodes_by_country(\"DE\")  # Germany\nfor node in country_nodes:\n    print(f\"Node: {node.name}\")\n    print(f\"Description: {node.description}\")\n    print(f\"Technologies available: {len(node.offer_technology_ids)} total\")\n    # Only list technologies if specifically asked, don't retrieve all details\n```\n\n**For General Full-text Search:**\n```python\n# Use full-text search to find relevant content\nresults = fulltext_search(\"access services application\", k=5)\nfor result in results:\n    if result['type'] == 'page':\n        page_details = read_website_page_details(result['id'])\n        print(f\"Page: {page_details.title}\")\n        print(f\"URL: {page_details.url}\")\n        print(f\"Description: {page_details.description}\")\n```\n\n```python\n# Example: \"Find super-resolution microscopy techniques\"\nresults = fulltext_search(\"super resolution microscopy\", k=3)\nfor result in results:\n    if result['type'] == 'tech':\n        print(f\"Technology: {result['name']} (Score: {result['score']:.2f})\")\n        print(f\"Description: {result['description']}\")\n        # Get provider nodes if needed\n        tech_details = read_tech_details(result['id'])\n        for node_id in tech_details.provider_node_ids:\n            node_details = read_node_details(node_id)\n            print(f\"  Available at: {node_details.name} in {node_details.country['name']}\")\n```\n\n### 4. **Be Focused and Efficient**\n- Only retrieve information that directly answers the user's question\n- Don't list all technologies at a node unless specifically asked\n- Don't retrieve all details unless needed for the specific query\n- Answer the question, don't provide unnecessary comprehensive listings\n\n### 5. **Reason Across Results**\n- Integrate information from multiple search results if needed\n- Draw conclusions, extract availability details, instrument capabilities, node locations, and relevant contact information\n\n### 6. **Handle AI-Enhanced Content Transparently**\n- **Check for AI enhancement markers** in technology documentation:\n  - Look for \"## AI Generated Documentation\" sections\n  - Look for \"## References\" sections with sources\n- **When using AI-enhanced content**:\n  - Mention that information is AI-enhanced: \"Based on AI-enhanced documentation...\"\n  - Cite sources from References sections: \"According to sources including [source name](url)...\"\n\n### 7. **Respond Factually and Comprehensively**\n- Ensure your final reply contains all key findings and actionable information\n- Always include all relevant details in your final answer, the intermediate script output won't be seen by the user\n- Avoid vague summaries\u2014be precise and specific based on the returned context\n- **Be transparent about information sources** throughout your response\n\n## \ud83d\udccb Query Pattern Examples\n\n**Geographic Query**: \"What imaging facilities are available in Germany?\"\n1. Use `read_nodes_by_country(\"DE\")` to get all German nodes\n2. For each node, use `read_node_details()` to get full information\n3. For each technology at the nodes, use `read_tech_details()` to understand capabilities\n\n**Technology Query**: \"Where can I access super-resolution microscopy?\"\n1. Use `fulltext_search(\"super resolution microscopy\", k=3)` to find relevant technologies and nodes\n2. Filter results by type to focus on technologies and nodes\n3. Use `read_tech_details()` and `read_node_details()` to get detailed information\n\n**General Information**: \"How do I access Euro-BioImaging services?\"\n1. Use `fulltext_search(\"access services application procedures\", k=3)` to find relevant content\n2. Filter results for website pages that contain access information\n3. Use `read_website_page_details()` for each relevant page to get detailed information\n\n## \ud83c\udfaf Response Quality Guidelines\n0. When generating the thoughts, limit each thought to 5 words maximum.\n1. **Use the indexes above** to identify relevant resources by their summaries\n2. **Extract IDs correctly** (the part before the colon) from the index entries\n3. **Call functions directly** without await, api prefix, or keyword arguments\n4. **Be systematic** in retrieving details for all relevant items\n5. **Include geographic context** (country names and codes)\n6. **Provide comprehensive information** which corresponds to the user query, try to be helpful and comprehensive.\n7. Since we are targeting non-technical users, unless asked, you can generate and execute scripts, but no need to commit code during the final response.\n\nRemember: Scan the indexes for relevant entries, extract the correct IDs, then call the utility functions directly to get detailed information.\n\"\"\") \n",
        "executionState": "success",
        "role": "system",
        "metadata": {
          "collapsed": false,
          "trusted": true,
          "isNew": true,
          "isEditing": false,
          "isCodeVisible": false,
          "isOutputVisible": true,
          "parent": null,
          "userModified": true,
          "hasOutput": true
        },
        "output": [
          {
            "type": "stdout",
            "content": "\nYou are an AI assistant specialized in helping users discover imaging technologies, instruments, and services provided by the Euro-BioImaging network.\nYou have access to several utility functions for retrieving specific information about Euro-BioImaging facilities. Below are all the available resources in the Euro-BioImaging network:\n\n\nHere is a list of all the available resources associated with their IDs.\n\n## Available General Website Pages:\n- b5de18fa:Euro-BioImaging/Access imaging technologies, expert training, data services across 41 Nodes in Europe.\n- 49348cd7:Image data events - Euro-BioImaging/Events on image data management, FAIR principles, and innovative solutions for researchers.\n- 2624ded3:SME and Industry Access - Euro-BioImaging/Access 240+ imaging facilities, 120+ technologies, expert consultations, competitive pricing.\n- 405363bb:News - Euro-BioImaging/Updates on imaging projects, job openings, AI events, and new imaging techniques.\n- ea1e2fc2:Funding - Euro-BioImaging/Funding for researchers, including i4A, canSERV, AgroServ; application details available.\n- 43a17e65:FEBS Congress 2025 - Euro-BioImaging/49th FEBS Congress, Istanbul, July 5-9, 2025; poster sessions, bursary for early-career researchers.\n- 171032e0:Tech Exchange webinar for companies - Euro-BioImaging/Monthly Tech Exchange webinars for imaging tech; register for updates and presentations.\n- a7f92ac1:Our Team - Euro-BioImaging/Team roles, contact info, training management, legal services, imaging tools development.\n- 6013fa00:Conferences - Euro-BioImaging/Upcoming conferences: mmc 2025, FEBS, Immunology Congress, SPAOM 2025; contact for more info.\n- 8c85202b:How companies can engage with us - Euro-BioImaging/Access 120+ imaging technologies, expert consultations, industry board, and collaboration opportunities.\n- 8bc4f0d5:Mentoring - Euro-BioImaging/Mentoring Program: Apply for peer support in career development, data management, and soft skills.\n- 58f7e252:EU Project CANDLE starts building National Cancer Data Nodes - Euro-BioImaging/CANDLE project builds EU cancer data nodes, enhancing research and data sharing.\n- 8a985e6c:Data services - Euro-BioImaging/Image Data Services, IDA, FAIR support, technical assistance, community initiatives.\n- 5eaeed05:Our events - Euro-BioImaging/Events: All Hands Nodes Meeting, User Forum, Tech Exchange, image data events.\n- 141899a8:Cross-Node Job Shadowing - Euro-BioImaging/Job shadowing program details: application deadlines, funding, training plans, contact info.\n- cf5eaec8:Contact us - Euro-BioImaging/Contact info, virtual meetings, newsletter sign-up for bioimaging updates.\n- c0c28a84:Euro-BioImaging Training Courses - Euro-BioImaging/Training for Node staff: skills, financial support, Train-the-Trainer course details.\n- 1fe54112:Special Edition Virtual Pubs - Euro-BioImaging/Special Edition Virtual Pubs on imaging tech, applications in research, and collaboration opportunities.\n- 554ab121:ISCaM Annual Meeting - Euro-BioImaging/ISCaM2025: July 2-4, 2025, Brussels; focus on tumor metabolism, networking, and presentations.\n- 8da7c083:Community services - Euro-BioImaging/FAIR data services, technical support, training, tools, and community coordination.\n- 56d1794d:Training for Node Staff - Euro-BioImaging/Training for Node staff under EVOLVE project; focuses on skill development and service quality.\n- ec39fc98:User Forum - Euro-BioImaging/User Forum events on imaging in immunology, plant biology, and cardiovascular research.\n- 41a3855d:EU projects - Euro-BioImaging/Details on 12 EU projects enhancing imaging, AI, and data access in life sciences.\n- f59cac35:Upcoming events - Euro-BioImaging/Events: Training, meetings, virtual pubs on imaging, cancer metabolism, and more.\n- a0f8dc59:EVOLVE News - Euro-BioImaging/News on training, job openings, mentoring masterclasses, and Node participation calls.\n- 1d6a8109:Strategic Goals - Euro-BioImaging/Strategic goals for 2024-2028: imaging services, FAIR data, training, stakeholder engagement.\n- d86b29a7:Governance - Euro-BioImaging/Governance structure, 41 Nodes, 192 imaging facilities, contact for membership queries.\n- 0b3d4d4a:Sponsorship Programme - Euro-BioImaging/Sponsorship for events enhancing biomedical imaging; application link included.\n- d31aa4c2:Documents - Euro-BioImaging/Access annual reports, equality plan, statutes, strategic plan, and policies.\n- b6dde532:FAQ - Euro-BioImaging/Access imaging technologies, training, proposal submission, contact info for assistance.\n- 3d22f118:Who are we? - Euro-BioImaging/Access cutting-edge imaging services, training, and support across Europe.\n- 70d0fdd6:Our Node list per member state - Euro-BioImaging/41 renowned imaging nodes across Europe with diverse services and training opportunities.\n- ce0faa17:From our Nodes - Euro-BioImaging/Training in imaging tech, sample prep, data analysis; courses taught in English, remote options.\n- 7006b8fe:The Four Seasons of the Invisible - Euro-BioImaging/Imaging contest details: eligibility, submission rules, quarterly sessions, prizes up to \u20ac1000.\n- b2a39ac1:EVOLVE Job Shadowing series - Euro-BioImaging/Job shadowing insights, Node collaborations, imaging advancements, and unique experiences shared.\n- 9d522de2:Master\u2019s programmes - Euro-BioImaging/MSc programs in imaging, internships, contacts for Cell Biology, Imaging, and Biomedical Imaging.\n- bb43378b:Partners - Euro-BioImaging/Details on partner infrastructures, access to resources, and global collaboration contacts.\n- 71450ac0:User services - Euro-BioImaging/Image Data Analysis services, access steps, Node connections, contact info.\n- a0c9bd9e:Technologies - Euro-BioImaging/Access to advanced imaging tech: cryo-EM, light microscopy, multimodal imaging for research.\n- cad295ba:EVOLVE - Euro-BioImaging/Opportunities: job shadowing, training, mentoring; focus on Open Science data services.\n- 98dd78d0:Euro-BioImaging Industry Board members/Membership offers access to imaging facilities, networking, and funding insights.\n- f9b8978e:Scientific Ambassadors - Euro-BioImaging/Join as a Scientific Ambassador for training, networking, travel grants, and advocacy materials.\n- 352d7b66:How to access - Euro-BioImaging/Access procedures, expert consultations, proposal requests, and contact info for imaging services.\n- 3cb9f1e9:Technology validation at Euro-BioImaging Nodes/Validation services, 240+ imaging facilities, EP PerMed funding up to \u20ac80,000.\n- 794e897b:FAIR image data - Euro-BioImaging/FAIR data training, resources, 1-on-1 guidance, contact fairdata@eurobioimaging.eu.\n- 7cc0db67:AgroSERV\u2019s 4th call for access is open - Euro-BioImaging/Funding for agroecology projects; apply by Oct 15, 2025; contact agroservprojects@eurobioimaging.eu.\n- 5a24f1ad:New technologies - Euro-BioImaging/Details on showcasing, proof-of-concept, and new imaging technologies access.\n- bf0d07e1:Euro-BioImaging Industry Board activities/Tech Exchange webinars, Board meetings, industry events, and new member announcements.\n- 265320da:Global BioImaging - Euro-BioImaging/Global BioImaging offers international workshops, training, and support for imaging facilities.\n- fd91e441:Research infrastructures - Euro-BioImaging/Access to biobanks, imaging, ELIXIR, EU-OPENSCREEN, Instruct-ERIC services and collaborations.\n\n## Available Technologies: \n- 73094724:3D Correlative Light and Electron Microscopy (3D-CLEM)*/In 3D CLEM, 3D or volume EM methods are combined with 3D light microscopy techniques. Registration between the modalities has to be done in all 3 dimensions, making 3D CLEM a challenging...\n- f68070c5:4Pi microscopy/Dual-objective microscopy achieving 100nm resolution for live-cell imaging.\n- b015d920:Anisotropy/Polarization Microscopy (AM)/Biomolecular interactions and conformational changes, both in vivo and in vitro, can be followed by fluorescence polarization/anisotropy imaging, which uses polarized excitation and polarization sensiti...\n- 63775639:Array tomography (AT)/Many biological functions depend critically upon fine details of tissue\u2019s molecular architecture that have resisted exploration by existing imaging techniques. Array tomography (AT) encompasses electron microscopy modali...\n- a9f0fcad:Atomic Force Microscopy (AFM)*/Atomic Force Microscopy (AFM) is a technique allowing the characterization of sample morphology at nanoscale. Images are acquired by raster scanning a nanometric tip in gentle contact or intermittent contact wit...\n- eeee8c89:Brillouin Scattering Microscopy (BSM) */Non-invasive, label-free imaging of mechanical properties at sub-cellular resolution.\n- 89bab6f3:Challenges Framework/Multimodal imaging integration, advanced algorithms, 3D fusion, cancer diagnostics.\n- 53fc2771:Coherent Anti-Stokes Raman Scattering microscopy (CARS)*/Label-free, high-resolution vibrational imaging for live cells and tissues.\n- 6709f67e:Correlated Optical Coherence Tomography/PhotoAcoustic Tomography (OCT/PAT)/Multimodal imaging: OCT/PAT combines high-res structural and functional insights.\n- 8597af30:Correlative Array Tomography (CAT)/Many biological functions depend critically upon fine details of tissue\u2019s molecular architecture that have resisted exploration by existing imaging techniques. Array tomography (AT) encompasses light and ele...\n- 59bcd971:Correlative X-ray and EM (CXEM)*/In correlative X-ray and EM, X-ray imaging can be used to gain insights into the structure and position of the sample inside the resin block, as prepared for EM. This allows for more precise targeting of the s...\n- 593e3440:Cryo Correlative Light and Electron Microscopy (Cryo-CLEM)*/Cryo-CLEM combines cryo-fixation and cryo-fluorescence microscopy with subsequent cryo-FIB, cryo-TEM, cryo-SEM, or cryo-ET. Alternatively after cryo-fluorescence microscopy samples c...\n- a7128dd1:Cryo Electron Tomography (Cryo-ET)*/Cryo-electron tomography (cryoET) is a specialized transmission electron microscopy technique in which samples are tilted and imaged under cryogenic conditions, resulting in a series of 2D images that can b...\n- 4b452472:Cryo Focussed Ion beam (Cryo-FIB)*/Cryo-electron tomography of structures inside thick cells requires the preparation of thin lamella, which are thin enough to be used in cryoET. Cryo-FIB milling is the method of choice to prepare these lamel...\n- 904149e2:Cryo Scanning Electron Microscopy (Cryo-SEM)*/Cryo-SEM is an excellent technique for imaging of liquid and semi-liquid  materials surfaces, hydrated biological specimens (e.g. biofilms, extracellular  matrix, hyphae, etc.) in close-to native ...\n- cb003121:Cryo Transmission Electron Microscopy* (Cryo-TEM)/This is transmission electron microscopy performed under cryogenic conditions on cryo-preserved samples. It can be used to determine the structure of protein and viruses to atomic resolution.\n- 60f50c0f:Cryo fluorescence microscopy (CryoFM)/CryoFM enables high-resolution imaging of vitrified samples at sub-200nm.\n- 7cb8eeaf:Deconvolution widefield microscopy (DWM)/Deconvolution is a computational technique for improving the contrast and resolution of digital images. It includes a suite of methods that seek to remove or reverse the blurring present in microscopes...\n- df1896a3:EM tomography (ET)/EM tomography allows the gathering of 3D information from individual thick sections of samples, previously fixed for sectioning. \r In TEM tomography thick plastic sections (typically 200-300 nm) are placed on an EM grid and...\n- 3965a906:Elemental analysis (EDX)*/Energy-dispersive X-ray spectroscopy (EDX) is a form of elemental analysis which is performed in combination with electron microscopy. EDX has so far not been routinely used in the life sciences, but thanks to new ge...\n- 60335007:Elemental analysis Correlative Light and Electron Microscopy (EDX-CLEM)*/Light microscopy helps to identify features in ultrastructural maps, but does not have EM resolution, therefore light and electron microscopy are correlated and in EDX-C...\n- 3a4d793f:Expansion Microscopy (ExM)*/Expansion microscopy (ExM) is a super-resolution approach that achieves sub-diffraction information by physically expanding the specimen. This allows it to seamlessly obtain resolutions of ~50 nm (up to 10 nm) in f...\n- 1f3001ca:Feedback microscopy (FDBKM)*/Biological systems are inherently complex, and the response of even the more stable model can be highly heterogeneous. Therefore, many samples must be imaged to achieve statistically meaningful results. In microsc...\n- 5a688552:Fluorescence (cross)-correlation spectroscopy (FCS/FCCS)/Fluorescence correlation spectroscopy (FCS) is a correlation analysis of fluctuations in the fluorescence intensity. The analysis provides information on physical parameters of the fluo...\n- 0de0802c:Fluorescence Lifetime Imaging (FLIM)/Fluorescence-lifetime imaging microscopy (FLIM) is an imaging technique for producing an image based on differences in the fluorescence-lifetime rather than its intensity. By quantifying variations in the ...\n- 018d2770:Fluorescence Recovery after Photobleaching (FRAP)/Fluorescence recovery after photobleaching (FRAP) denotes an optical technique capable of quantifying the two dimensional lateral diffusion of a molecularly thin film containing fluorescently ...\n- e9910d1c:Fluorescence Resonance Energy Transfer (FRET)/Fluorescence resonance energy transfer (FRET) is a mechanism describing energy transfer between two light-sensitive molecules (chromophores). A donor chromophore, initially in its electronic excit...\n- eebba7a7:Focussed Ion beam SEM (FIB-SEM) /A full understanding of the fine organization of cells and tissues requires their high-resolution visualization in three dimensions (3D). Plastic embedded cells can be imaged with automated focused ion beam (F...\n- 745fa0d0:Fourier transform infrared imaging (FTIR)/Rapid, non-destructive molecular analysis; high sensitivity, versatile applications.\n- 04562797:Genetic encoded EM probes (GE probes)/Localising specific proteins of interest represents a challenge in electron microscopy, compared to fluorescence microscopy where the target of interest is normally visualised via fluorescent tags or prob...\n- 722bb380:High throughput microscopy/high content screening (HTM/HCS)/High-throughput microscopy has created new opportunities for studying biological phenomena in an unbiased manner. Using automated cell manipulations and microscopy platforms, it is p...\n- d6cec7b4:High-speed Imaging (HSI)*/High-speed imaging includes all imaging techniques capable of gathering data at very high frame rates. The commonly considered cut-off is an exposure time of 1/1000 sec or >250 frames per second. High-speed imaging a...\n- 4e5bcb9e:I don't know which technology/Real-time multi-modal imaging: MRI, CT, fluorescence, high-resolution cell dynamics.\n- 22875d0d:Image Analysis -bio (IA bio)*/AI-driven, scalable image analysis for complex biological data interpretation.\n- 31d30c68:Image Scanning microscopy (ISM)/Super-resolution imaging with 2x confocal resolution, SPAD detection, live-cell compatible.\n- 639a72d3:Image analysis - med (IA med)*/AI-driven medical imaging: automated detection, segmentation, real-time analysis.\n- a2a0f4a8:Imaging Flow Cytometry (IFC)*/Imaging Flow Cytometry combines the speed, sensitivity and strong statistical power of conventional flow cytometry with the detailed imagery, spatial information and functional insight of microscopy all in a sing...\n- f65a70b8:Imaging at Biosafety Level >1 (BSL>1)/Imaging at Biosafety Levels >1 is offered at several Euro-BioImaging Nodes. Several Nodes offer imaging at BSL2 and select facilities at BSL3 are also available. In these cases the imaging systems are pla...\n- a97f4fa4:Imaging for Plant Phenotyping (PHENO)*/Multi-sensor imaging: RGB, hyperspectral, thermal; high-throughput phenotyping.\n- 3f84bc36:Immuno-gold EM on resin sections (resin-EM)/Immuno-gold is a variant of immunohistochemistry where antibodies tagged with gold particles (of different sizes) are used to visualise the localisation of proteins of interest in EM samples. Due to...\n- e32e05f1:Immuno-gold EM on thawed cryo-sections (Tokuyasu-EM)/Immuno-gold is a variant of immunohistochemistry where antibodies tagged with gold particles (of different sizes) are used to visualise the localisation of proteins of interest in EM sample...\n- a673b6b7:Intravital Microscopy (IVM)/Intravital imaging covers a range of microscopy modalities used for the long term imaging of living animal models (e.g. zebrafish larvae, mice, rats), in various organs or tissues, or as a whole for smaller models....\n- de231b3c:Large scale EM (lsTEM)/In large scale EM, either scanning electron microscopy or transmission electron microscopy are performed on samples that have been sectioned. In particular the focus here is to acquire large datasets spanning big fields...\n- 019f553c:Laser scanning confocal microscopy (LSCM/CLSM)/Confocal laser scanning microscopy (CLSM) or laser scanning confocal [LSCM]), often colloquially referred to  simply as \u201cconfocal\u201d, is a technique for obtaining high resolution optical images wit...\n- d2871017:Lattice light-sheet (LLS)/Ultra-thin light sheet, isotropic 3D resolution, minimal phototoxicity, 4D imaging.\n- e7adfd19:Light-sheet mesoscopic imaging (SPIM/dSLSM)/Light sheet microscopy is a mesoscopic imaging technology that combines optical sectioning with multiple-view imaging to observe tissues and living organisms with impressive resolution. This method ...\n- b773e740:Long-term vertical-stage confocal/Airyscan microscopy/90 nm resolution, long-term live-cell imaging, enhanced signal detection.\n- 4707da44:MRI/MRS (< 7T)/\n- 6324bef6:MRI/MRS (>= 7T)/7T MRI/MRS: ultra-high resolution, dual-mode, advanced neuroscience applications.\n- 83b4baea:Macro Serial Blockface Fluorescence imaging* (S-BFI)/Serial block face imaging (SFBI) is a method used to generate 3-dimensional (3D) reconstruction of a sample via serial image acquisition, here on a microtome. The system can detect the endo...\n- 0d8de032:Magnetic Particle Imaging (MPI)*/Real-time, high-resolution imaging using superparamagnetic nanoparticles.\n- b5cb68ca:MagnetoEncephaloGraphy (MEG)/Non-invasive, high temporal resolution, direct neuronal activity mapping.\n- 4b561f4f:Mass spectrometry-based imaging - bio (MSI - bio)*/Spatially resolved analysis of metabolites, proteins, lipids, peptides, glycans and even drugs has become feasible with the development of mass spectrometry-based imaging strategies. Developm...\n- 9c814a85:Mass spectrometry-based imaging - med (MSI - med)*/High-resolution MSI for spatial molecular mapping in tissues, untargeted analysis.\n- afeaed8d:Micro X-ray Fluorescence Spectrometry (XRF)*/Micro-X-Ray Fluorescence Spectrometry (XRF) allows the qualitative analysis of the elemental composition of solid samples. The detected signal results from the emission of element-characteristic fl...\n- 0a49ed44:Micro-Particle Induced X-ray Emmission (\u00b5-PIXE)*/High-resolution (1\u00b5m), non-destructive elemental mapping for diverse samples.\n- b5ef918c:Microdissection (\u00b5Dis)*/Laser microdissection is a useful technique that enables the precise isolation of cells or tissue regions out of a tissue specimen, allowing the isolation of high-purity biomolecules. The technique can be used on fixed...\n- fc6e9ebb:Minimal Photon Fluxes Microscopy (MINFLUX)*/Sub-2nm resolution, minimal photon use, live-cell tracking, 3D imaging.\n- 3ba9fb09:Multiplexing imaging (MXI)*/Multiplexing is the ability to stain the same sample many times. Today we are limited to 7 stains on the same slide but researchers want to go further and to be able to use more than 50 dyes to map their samples. T...\n- a7c09ccd:Objective-coupled planar illumination (OCPI)/High-speed, low-phototoxicity 3D imaging of large biological samples.\n- 17dd34eb:Optical projection tomography (OPT)/Optical projection tomOptical projection tomography (OPT) is in many ways the optical equivalent of x-ray computed tomography (CT) or the medical CT scan. OPT differs in the way that it often uses ultraviol...\n- a9c43bba:PET/High-resolution metabolic imaging; oncology, neurology, cardiology applications.\n- 3a2f2c38:PET-MRI/Hybrid imaging: combines PET's metabolic data with MRI's high-resolution anatomy.\n- 0f1e5f18:PET/CT */Hybrid imaging combining metabolic PET with anatomical CT for precise diagnostics.\n- 413a548d:Phase Contrast Imaging (PCI)/High-resolution imaging of soft tissues via X-ray phase shifts, enhancing diagnostics.\n- 47c84335:Phosphorescence Lifetime imaging (PLIM)*/Phosphorescence Lifetime Imaging works on a similar principle as fluorescence lifetime imaging (FLIM), but rather makes use of the phosphorescence induced by the excitation rather than the fluorescence...\n- d54d34a2:PhotoAcoustic Imaging (PAI) - med/Non-invasive imaging combining optical and ultrasound for high-res tissue analysis.\n- f4eef350:Photoacoustic imaging (PAI - bio)*/Non-invasive imaging with sub-mm resolution, real-time vascular and tumor analysis.\n- b5333ef4:Photomanipulation (Pmanip)/Photomanipulation includes a variety of techniques in which lasers (or other light sources) are used to interact with the sample in a targeted fashion. This includes laser ablation to induce cellular injuries and me...\n- 3ef7ea02:Plant Phenotyping (PHENOPlant)*/High-throughput, multi-sensor phenotyping for crops, Arabidopsis, stress studies.\n- 4ba07d0c:Polarization microscopy (PM)/Polarization Microscopy or Polarized Light Microscopy involve the use of polarized light in illuminating the sample and make use of the samples optically anisotropic character to generate contrast.\n- fd0e8053:Population imaging (PI data)/Advanced imaging for large cohorts: AI analysis, biomarker tracking, multi-modal.\n- 1fe88685:Population imaging (PI)/Large-scale imaging of populations for early disease detection and prevention.\n- f6b01df1:Quantitative Phase Imaging (QPI)*/Label-free imaging of live cells with nanoscale resolution and quantitative analysis.\n- dcb85d5e:Raman Spectroscopy (RS)/Non-destructive molecular fingerprinting, high sensitivity, rapid analysis.\n- b51478b1:Random Illumination Microscopy (RIM)*/Speckled illumination, super-resolution, fast imaging of thick biological samples.\n- a42333c3:Reversible optical fluorescence transitions (RESOLFT)/Sub-100nm resolution, live cell imaging, reversible fluorescent switching.\n- 995a6055:STEM tomography (STEM)/Scanning transmission electron microscopy (STEM) is a type of transmission electron microscopy in which the focussed electron beam is rastered or scanned across the samples. \r \r In STEM tomography, similar to TEM tomogr...\n- c60b4a73:Scanning Electron Microscopy (SEM)/In Scanning Electron Microscopy, a focussed beam of accelerated electrons is scanned across the surface of the sample and the scanned and secondary electrons are used to generate the SEM image.\r SEM can be u...\n- d52b6d15:Second/Third Harmonic Generation (SHG/THG)/SHG is a label free technique to visualize specific structures e.g. fibrillar collagen, muscle myosin, and microtubules in vitro and in vivo. THG shows interfaces having local transitions of the refr...\n- c1a46958:Secondary Ion Mass Spectrometry with MeV ions (MeV-SIMS)*/High-resolution imaging of large biomolecules using MeV ions, low fragmentation.\n- c9ddc22b:Serial Blockface SEM (SBF-SEM)/A full understanding of the fine organization of cells and tissues requires their high-resolution visualization in three dimensions (3D). In this technique a miniaturized ultramicrotome, embedded in the chamber ...\n- d3d66a1d:Single Molecule localization microscopy (SMLM)/Achieves 20-50nm resolution, enabling detailed imaging of molecular dynamics.\n- 7add3aac:Single Particle Tracking (SPT)*/Real-time tracking of individual particles with nanometer precision in live cells.\n- 931ee18e:Single molecule FRET (smFRET)*/Single molecule FRET allows the measurement of distances and distance changes between two fluorescent molecules in a biomolecular complexes, down to the Angstrom and the microsecond timescales. smFRET measuremen...\n- 02c9e1e3:Spatial Transcriptomics (ST)*/High-resolution spatial gene expression mapping in tissues, enabling cell interaction insights.\n- 3cf0830c:Spinning disk confocal microscopy (SDCM)/Spinning disc confocal microscopy is one of the solutions for routine and high-performance fluorescence live-cell imaging applications. SDCM uses a series of moving pinholes on a disc to scan spots of ...\n- e480e528:Stimulated Raman Scattering (SRS)*/High-speed, label-free imaging with sub-10 nm resolution for live cells.\n- f1f735b6:Stimulated emission depletion microscopy (STED)/Sub-50nm resolution, live cell imaging, selective fluorophore deactivation\n- ff8ab803:Structured illumination microscopy* (SIM)/Spinning disc confocal microscopy is one of the solutions for routine and high-performance fluorescence live-cell imaging applications. SDCM uses a series of moving pinholes on a disc to scan spots of...\n- f45daf6b:Super-resolution radial fluctuations (SRRF)*/Sub-100nm resolution for live-cell imaging, low phototoxicity, accessible.\n- af33ff84:TEM of chemical fixed samples (TEM)/In transmission electron microscopy (TEM) the accelerated beam of electrons is transmitted through the sample and collected to form an image. To achieve this the specimen is usually sectioned into ultrathin...\n- 4ae7143c:TEM of cryo-immobilized samples (TEM cryo samples)*/In transmission electron microscopy (TEM) the accelerated beam of electrons is transmitted through the sample and collected to form an image. To achieve this the specimen is usually sectione...\n- ae6d3c51:TEM of immobilized particles (TEM neg stain)*/High-resolution TEM negative staining for biomolecules, viruses, and complexes.\n- b4d963a5:Terahertz Plant Imaging (THzI)*/Non-invasive THz imaging for plant hydration, quality assessment, high resolution.\n- f05d797c:Tissue Clearing (TC)*/The restitution of 3D images from samples becomes a major challenge for visualizing, exploring, analyzing and quantifying. The major problem with samples is their intrinsic composition which prevents correct observation....\n- 8399c5a7:Total internal reflection fluorescence microscopy (TIRF)/Total internal reflection fluorescence microscopy (TIRF)  is a microscopy technique with which a thin region of the cell, usually less than 200nm can be observed.  A TIRF microscope use...\n- 0534020c:Traction Force Microscopy (TFM)*/Traction Force Microscopy (TFM) has been extremely useful in the field of mechanobiology where it is applied to locally track the forces that cells exert on a particular substrate. Experiments can be performed...\n- 2fa1c4a2:Two-photon microscopy (2P)/Multiphoton microscopy - most commonly in the form of two-photon microscopy - is a fluorescence imaging technique that allows observation of living tissue up to about one millimeter in depth. It uses pulsed red-shif...\n- a6cee2e2:Voltage/pH/Ion Imaging */Real-time imaging of voltage, pH, and ions in live cells with high sensitivity.\n- c83c6c2b:ex-vivo micro-CT/High-resolution 3D imaging of excised tissues, sub-10\u00b5m resolution, vascular studies.\n- 4e2f1176:immunolabeling on immobilized particles (immunolocal)*/High-resolution immunolocalization via oriented antibody immobilization for diagnostics.\n- 59a33aed:in vivo optical imaging (OI)/Non-invasive, high-resolution imaging of live biological processes using light.\n- 3744dad8:intravital microscopy (IVM-med)/Real-time in vivo imaging with dual-mode confocal/two-photon, 100 fps.\n- c3302077:live-cell Correlative Light and Electron Microscopy (live-cell CLEM)/Cells are imaged live by light microscopy (e.g. wide field, confocal or light sheet). Following the light microscopy image acquisition, specific CLEM protocols enable the sc...\n- b4a6f749:micro-CT/High-resolution micro-CT: 100nm, 3D imaging, non-destructive, diverse applications.\n- d74face8:micro-MRI/MRS (<7 T)ex-vivo/High-resolution ex-vivo micro-MRI/MRS (<7 T) for detailed tissue analysis.\n- 4a91416e:micro-MRI/MRS (>= 7 T)ex-vivo/7T micro-MRI/MRS: 100\u00b5m resolution ex-vivo imaging for neuroanatomy and pathology.\n- fc3c255a:micro-MRI/MRS (Field < 7 T)/Cryogen-free micro-MRI/MRS < 7 T: high-resolution, multi-nuclear imaging for small animals.\n- 9c64e406:micro-MRI/MRS (Field >= 7 T)/7 T micro-MRI/MRS: sub-millimeter resolution, multi-nuclear imaging, advanced neurological diagnostics.\n- 4aa5d36d:micro-PET/High-resolution small-animal imaging: 1-2 mm, oncology, neurology, non-invasive.\n- c41fb0d1:micro-PET/CT/High-resolution micro-PET/CT: 1.4mm resolution, multimodal imaging for small animals.\n- 15ef9b0e:micro-PET/MRI/Hybrid imaging: simultaneous micro-PET/MRI, high-resolution, in vivo molecular imaging.\n- 36d4a2a7:micro-SPECT/Ultra-high-resolution micro-SPECT: 0.13 mm, dynamic imaging, multi-isotope capability.\n- 8fa56005:micro-SPECT-CT/High-res micro-SPECT-CT: 0.3mm, dynamic imaging, preclinical applications.\n- 2ce231cc:micro-US/29 MHz resolution, real-time imaging, prostate cancer diagnosis, biopsy guidance.\n- 0abb2c96:post-embed Correlative Light and Electron Microscopy (on-section CLEM)/Correlative Light and Electron Microscopy (CLEM) combines the advantages of both techniques, allowing scientists to spot cellular structures and processes of interest in w...\n- 90e98166:post-embedding CLEM (post-emb CLEM)/Correlative Light and Electron Microscopy (CLEM) combines the advantages of both techniques, allowing scientists to spot cellular structures and processes of interest in whole cell images with LM and then z...\n- 0dee2953:pre-embed Correlative Light and Electron Microscopy (pre-embed CLEM)/Correlative Light and Electron Microscopy (CLEM) combines the advantages of both techniques, allowing scientists to spot cellular structures and processes of interest in who...\n- 13e1b5d4:pre-embedding CLEM (pre-emb CLEM)/Correlative Light and Electron Microscopy (CLEM) combines the advantages of both techniques, allowing scientists to spot cellular structures and processes of interest in whole cell images with LM and then zoo...\n- 143e2504:pre-embedding immunolabelling (pre-embed IL)/In contrast to immuno-gold EM on sections, in pre-embedding immunolabeling, the sample is immunolabeled before the standard processing for EM takes place. This can offer the advantage of improved a...\n- d169e03b:serial section TEM (ssTEM)/ssTEM is performed on series of thin sections that are acquired by conventional ultramicrotomy, compared to the ribbons of sections in Array Tomography. The sections are collected on EM grids and imaged sequentially...\n\n## Available Nodes by Country (with ISO codes):\n\n**Austria (AT):**\n  - 2b34e271:Austrian BioImaging Node/CMI/Austria 8-site: cryo-EM, microCT, microPET, multimodal workflows, data analysis\n\n**Belgium (BE):**\n  - 0c8677f6:Flanders Bioimaging Imaging Node/Multi-site, multi-modality: molecular to clinical imaging, 9 facilities.\n\n**Bulgaria (BG):**\n  - 151b4761:Sofia BioImaging Node - Advanced Light Microscopy Node Sofia Bulgaria\u200b/Multimodal, high-res live-cell imaging, laser disruption, open access.\n\n**Czech Republic (CZ):**\n  - 638ca876:Advanced Light Microscopy and Medical Imaging Node Brno CZ/Brno CZ: 9.4T ultra-high field MR, multi-modal imaging, training programs.\n  - 90c8b0d6:Advanced Light and Electron Microscopy Node Prague CZ/Prague Node: Multi-modal, super-resolution, live imaging, training courses.\n  - e0395c6a:Center for Advanced Preclinical Imaging (CAPI)/CAPI: Multimodal preclinical imaging, in vivo research, contrast media expertise.\n\n**Denmark (DK):**\n  - 23f7a2fd:Danish BioImaging/Multi-site Danish Node: pre-clinical to cryo-EM, diverse applications, data analysis focus.\n\n**EMBL (EM):**\n  - b19711d3:Euro-BioImaging EMBL-Node/EMBL Node: state-of-the-art imaging, project planning, training, advanced methods.\n\n**Finland (FI):**\n  - 46ccfb38:Finnish Advanced Microscopy Node/Sub-20nm resolution, correlative workflows, advanced sample preparation.\n  - 3850f7eb:Finnish Biomedical Imaging Node/Multi-modal Node: PET, MRI, MEG, optical; targets cancer, neuroscience, metabolism.\n\n**France (FR):**\n  - fc1893d4:French BioImaging Node/30 facilities, 80 labs, bioimage informatics, advanced microscopy methods.\n\n**Hungary (HU):**\n  - ca2e3748:Cellular Imaging Hungary/Multi-modal node: LSCM, ISIDORe, infectious disease focus, pandemic readiness.\n  - cf8f008b:Medical and Preclinical Imaging Hungary/Multi-modal Node: functional imaging, PET/CT, microCT, unique M3 concept.\n\n**Israel (IL):**\n  - 9beefd47:Israel BioImaging/Cross-modality imaging: single-molecule to clinical, advanced analysis.\n\n**Italy (IT):**\n  - 522e8aaa:Advanced Light Microscopy Italian Node/Italy's multi-modal node: 5 sites, advanced imaging, diverse applications.\n  - 6319df36:Digital Imaging Multimodal Platform Neuromed \u2013  DIMP NEUROMED/Integrated multimodal platform for neuroscience, preclinical to clinical imaging.\n  - d2be2f9c:Molecular Imaging Italian Node/Italy 8-site: multi-modal, in vivo imaging, extensive tracer repository, advanced applications.\n  - d14abc55:Phase Contrast Imaging Flagship Node Trieste/Trieste: High-intensity phase contrast, soft tissue imaging, synchrotron source.\n\n**Netherlands (NL):**\n  - f68673b1:Challenges Framework Flagship Node/Open-source platform: algorithm evaluation, cloud collaboration, data repository\n  - d039b533:Correlative Light Microscopy Dutch Flagship Node/Dutch CLEM consortium: live-cell correlation, open access, multi-lab expertise.\n  - 4278635d:Dutch High Field Imaging Hub/Ultra-high field MRI, 7T+, precision neuroimaging, multi-site collaboration.\n  - 4f1ca4db:Erasmus MC OIC - Advanced Light Microscopy Rotterdam Node/Quantitative live cell imaging, FRAP, FRET, FCS, high resolution.\n  - 9c8d648e:Facility of Multimodal Imaging - AMMI Maastricht/Multimodal imaging: light/electron microscopy, mass spectrometry, non-invasive bioimaging.\n  - 6f0ef2b7:High Throughput Microscopy Dutch Flagship Node/NL flagship: high-throughput, live cell, advanced imaging, multi-site expertise.\n  - 84334573:Population Imaging Flagship Node Rotterdam/Epidemiological studies, imaging biomarkers, risk assessment, Rotterdam Node\n  - 706cb740:Preclinical Imaging Centre (PRIME) - Molecular Imaging Dutch Node/Dual-site, multimodal small animal imaging; unique genetic models, multiphoton.\n  - c4b25263:The Van Leeuwenhoek Center for Advanced Microscopy (LCAM) - Functional Imaging Flagship Node Amsterdam/Advanced live cell imaging, FRET, FCCS, FLIM, custom fluorophores.\n  - 66b1f7ec:Wageningen Imaging and Spectroscopy Hub (WISH) - ALM and Molecular Imaging Node Wageningen/Ultrafast fluorescence, in vivo photosynthesis, single-cell chloroplast imaging.\n\n**Norway (NO):**\n  - 3e52fd14:NORMOLIM, Norwegian Molecular Imaging Infrastructure/Norwegian in vivo imaging: disease models, transgenic systems, clinical translation.\n  - a44edc42:NorMIC Oslo - Advanced Light Microscopy Node Oslo/Live imaging, sub-cellular dynamics, incubators for CO2 control.\n\n**Poland (PL):**\n  - fcf6bac6:Advanced Light Microscopy Node Poland/Multi-modal imaging: super-resolution, CLEM, high-throughput, training.\n\n**Portugal (PT):**\n  - 6e382796:Brain Imaging Network (BIN)/Portugal Node: PET/MR, neuroimaging focus, multimodal expertise, radiotracer development.\n  - e5f30cac:Portuguese Platform of BioImaging (PPBI)/Multi-sited Euro-BioImaging Node: advanced light/electron microscopy, live cell imaging, high throughput.\n\n**Slovenia (SI):**\n  - 2103118f:SiMBION Node/Slovenian consortium: 15 centers, bioimaging access, training, TNA support.\n\n**Spain (ES):**\n  - e532f9cb:Barcelona Live and Intravital Node/Live-cell and in vivo imaging, multi-modal techniques, advanced fluorescence.\n  - 1fa342de:Barcelona Mesoscopic Imaging Node/Barcelona Node: LSFM, 50\u00b5m-5cm, live imaging, multiview, organ resolution.\n  - 161021f6:Barcelona Super-resolution Light and Nanoscopy Node/Multi-site: super-resolution, bioimage analysis, custom training, complex datasets.\n  - 6d068cfb:Population Imaging Valencia/AI-driven biomarkers, predictive models, structured image repositories.\n\n**Sweden (SE):**\n  - f1099f78:Swedish National Microscopy Infrastructure (NMI)/Swedish multi-site: super-resolution, intravital, live imaging, 500+ users.\n\n**United Kingdom (GB):**\n  - 09122290:The UK Node/UK multi-site: super-resolution, correlative, high-content imaging, open-access.\n\n**Unknown (UN):**\n  - 64543c53:No Node preference/Node selection assistance, tailored tech guidance, project optimization.\n\n**IMPORTANT**: Each entry in the indexes above follows the format `- ID: Name / Description`\n\n- For **Technologies**: `- tech_id: Technology Name/Brief description`\n- For **Nodes**: `- node_id: Node Name/Brief description` \n- For **Website Pages**: `- page_id: Page Title/Brief description`\n\nFor any matched topics, you can call the utility functions to get more details by the ID.\n\n**To use the utility functions**: Extract the ID (the part after the dash and before the colon) and pass it to the appropriate function:\n- Use `tech_id` with `read_tech_details(tech_id)`\n- Use `node_id` with `read_node_details(node_id)` \n- Use `page_id` with `read_website_page_details(page_id)`\n\nThese utilities are available under the current execution context, and no need to use await to call them. For example:\n\n```python\n# Example: Get details of a specific technology\ntech_details = read_tech_details(\"02e4459a\")\nprint(f\"Technology: {tech_details.name}\")\nprint(f\"Description: {tech_details.description}\")\n```\n\nImprtantly, they are not under api.* namespace, so you can call them directly.\n\n\n## \ud83d\udee0\ufe0f Available Utility Functions\n\n**IMPORTANT**: Call these functions directly - NO `await`, NO `api.` prefix, NO keyword arguments!\n\n### Detail Retrieval Functions\n- `read_tech_details(tech_id)` \u2192 `TechDetail(id, name, original_id, description, documentation, category, provider_node_ids, abbr)` or `None`\n- `read_node_details(node_id)` \u2192 `NodeDetail(id, name, original_id, description, documentation, country, offer_technology_ids)` or `None`  \n- `read_nodes_by_country(country_code)` \u2192 `List[NodeDetail(id, name, original_id, description, documentation, country, offer_technology_ids)]`\n- `read_website_page_details(page_id)` \u2192 `WebsitePageDetail(id, url, title, description, documentation, headings, page_type)` or `None`\nThe returned objects are pydantic models, so you can access the attributes directly. For example: tech_details.name, node_details.country['name'], etc.\n\n### Search Functions\n- `fulltext_search(query, k=5)` \u2192 `List[Dict]` (full-text search across all content types)\n- `get_country_codes()` \u2192 `Dict[str, str]` (country_name \u2192 ISO_code)\n\n\n## \u2705 Correct Function Call Examples\n\n```python\n# CORRECT: Get node details\nnode_details = read_node_details(\"48c78d41\")\nprint(f\"Node: {node_details.name}\")\nprint(f\"Country: {node_details.country['name']}\")\nprint(f\"Description: {node_details.description}\")\n\n# CORRECT: Get technology details  \ntech_details = read_tech_details(\"02e4459a\")\nprint(f\"Technology: {tech_details.name}\")\nprint(f\"Category: {tech_details.category['name']}\")\nprint(f\"Available at {len(tech_details.provider_node_ids)} nodes\")\n\n# CORRECT: Get all nodes in Germany\ngerman_nodes = read_nodes_by_country(\"DE\")\nfor node in german_nodes:\n    print(f\"Node: {node.name}\")\n    print(f\"Technologies: {len(node.offer_technology_ids)} available\")\n\n# CORRECT: Full-text search across all content\nresults = fulltext_search(\"super resolution microscopy\", k=5)\nfor result in results:\n    print(f\"Score: {result['score']:.2f} - Type: {result['type']} - Name: {result['name']}\")\n    print(f\"Description: {result['description']}\")\n```\n\n## \u274c WRONG Function Call Examples\n\n```python\n# WRONG: Don't use await\nnode_details = await read_node_details(\"48c78d41\")  # \u274c\n\n# WRONG: Don't use api prefix\nnode_details = api.read_node_details(\"48c78d41\")  # \u274c\n\n# WRONG: Don't use keyword arguments\nnode_details = read_node_details(node_id=\"48c78d41\")  # \u274c\n\n# WRONG: Don't combine await + api\nnode_details = await api.read_node_details(node_id=\"48c78d41\")  # \u274c\n```\n\n## \ud83e\udde0 How to Answer User Queries\n\nFollow this systematic approach:\n\n### 1. **Analyze the Query Type**\n- **Geographic queries** (e.g., \"facilities in Germany\"): Focus on specific countries/regions\n- **Technology queries** (e.g., \"super-resolution microscopy\"): Focus on specific techniques or instruments  \n- **General information** (e.g., \"how to access services\"): Focus on website pages and general guidance\n- **Listing queries** (e.g., \"all available nodes\"): Provide comprehensive listings\n\n### 2. **Select Relevant IDs**\nFrom the indexes above, identify the specific IDs you need by looking at the summaries:\n- **Technology IDs**: Look for relevant techniques in the technology list, extract the ID before the colon\n- **Node IDs**: Look for relevant facilities in the node list, extract the ID before the colon\n- **Country codes**: Use the ISO codes in parentheses (e.g., DE, SE, FR)\n- **Page IDs**: Look for relevant information pages, extract the ID before the colon\n\n**Example**: If you see `tech_super_res_microscopy: Super-Resolution Microscopy (available at 15 nodes)`, use `tech_super_res_microscopy` as the ID.\n\n### 3. **Retrieve Detailed Information**\nUse the utility functions systematically:\n\n**For Technology Queries:**\n```python\n# Example: \"Where can I find MINFLUX?\"\n# Step 1: Get the specific technology details\nminflux_details = read_tech_details(\"4bf1cfdd\")  # Extract ID from index\nprint(f\"Technology: {minflux_details.name}\")\n\n# Step 2: Get nodes where it's available (don't list all their technologies)\nfor node_id in minflux_details.provider_node_ids:\n    node_details = read_node_details(node_id)\n    print(f\"Available at: {node_details.name} in {node_details.country['name']}\")\n```\n\n**For Geographic Queries:**\n```python\n# Example: \"What imaging facilities are in Germany?\"\ncountry_nodes = read_nodes_by_country(\"DE\")  # Germany\nfor node in country_nodes:\n    print(f\"Node: {node.name}\")\n    print(f\"Description: {node.description}\")\n    print(f\"Technologies available: {len(node.offer_technology_ids)} total\")\n    # Only list technologies if specifically asked, don't retrieve all details\n```\n\n**For General Full-text Search:**\n```python\n# Use full-text search to find relevant content\nresults = fulltext_search(\"access services application\", k=5)\nfor result in results:\n    if result['type'] == 'page':\n        page_details = read_website_page_details(result['id'])\n        print(f\"Page: {page_details.title}\")\n        print(f\"URL: {page_details.url}\")\n        print(f\"Description: {page_details.description}\")\n```\n\n```python\n# Example: \"Find super-resolution microscopy techniques\"\nresults = fulltext_search(\"super resolution microscopy\", k=3)\nfor result in results:\n    if result['type'] == 'tech':\n        print(f\"Technology: {result['name']} (Score: {result['score']:.2f})\")\n        print(f\"Description: {result['description']}\")\n        # Get provider nodes if needed\n        tech_details = read_tech_details(result['id'])\n        for node_id in tech_details.provider_node_ids:\n            node_details = read_node_details(node_id)\n            print(f\"  Available at: {node_details.name} in {node_details.country['name']}\")\n```\n\n### 4. **Be Focused and Efficient**\n- Only retrieve information that directly answers the user's question\n- Don't list all technologies at a node unless specifically asked\n- Don't retrieve all details unless needed for the specific query\n- Answer the question, don't provide unnecessary comprehensive listings\n\n### 5. **Reason Across Results**\n- Integrate information from multiple search results if needed\n- Draw conclusions, extract availability details, instrument capabilities, node locations, and relevant contact information\n\n### 6. **Handle AI-Enhanced Content Transparently**\n- **Check for AI enhancement markers** in technology documentation:\n  - Look for \"## AI Generated Documentation\" sections\n  - Look for \"## References\" sections with sources\n- **When using AI-enhanced content**:\n  - Mention that information is AI-enhanced: \"Based on AI-enhanced documentation...\"\n  - Cite sources from References sections: \"According to sources including [source name](url)...\"\n\n### 7. **Respond Factually and Comprehensively**\n- Ensure your final reply contains all key findings and actionable information\n- Always include all relevant details in your final answer, the intermediate script output won't be seen by the user\n- Avoid vague summaries\u2014be precise and specific based on the returned context\n- **Be transparent about information sources** throughout your response\n\n## \ud83d\udccb Query Pattern Examples\n\n**Geographic Query**: \"What imaging facilities are available in Germany?\"\n1. Use `read_nodes_by_country(\"DE\")` to get all German nodes\n2. For each node, use `read_node_details()` to get full information\n3. For each technology at the nodes, use `read_tech_details()` to understand capabilities\n\n**Technology Query**: \"Where can I access super-resolution microscopy?\"\n1. Use `fulltext_search(\"super resolution microscopy\", k=3)` to find relevant technologies and nodes\n2. Filter results by type to focus on technologies and nodes\n3. Use `read_tech_details()` and `read_node_details()` to get detailed information\n\n**General Information**: \"How do I access Euro-BioImaging services?\"\n1. Use `fulltext_search(\"access services application procedures\", k=3)` to find relevant content\n2. Filter results for website pages that contain access information\n3. Use `read_website_page_details()` for each relevant page to get detailed information\n\n## \ud83c\udfaf Response Quality Guidelines\n0. When generating the thoughts, limit each thought to 5 words maximum.\n1. **Use the indexes above** to identify relevant resources by their summaries\n2. **Extract IDs correctly** (the part before the colon) from the index entries\n3. **Call functions directly** without await, api prefix, or keyword arguments\n4. **Be systematic** in retrieving details for all relevant items\n5. **Include geographic context** (country names and codes)\n6. **Provide comprehensive information** which corresponds to the user query, try to be helpful and comprehensive.\n7. Since we are targeting non-technical users, unless asked, you can generate and execute scripts, but no need to commit code during the final response.\n\nRemember: Scan the indexes for relevant entries, extract the correct IDs, then call the utility functions directly to get detailed information.\n\n",
            "attrs": {
              "className": "output-area"
            }
          }
        ],
        "executionCount": 57
      }
    ]
  },
  "_security": {
    "sanitized": true,
    "sanitizedAt": "2025-07-10T14:27:33.564Z",
    "version": "1.0",
    "note": "All API keys and sensitive data have been automatically removed"
  }
}